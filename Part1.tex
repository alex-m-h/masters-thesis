\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xcolor}
\usepackage{csquotes}
\usepackage{enumerate}
\usepackage{faktor}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{showlabels}

\usepackage{biblatex}
\addbibresource{bibliography.bib}
% \bibliography{bibliography}
% \bibliographystyle{ieeetr}

\numberwithin{equation}{subsection}

\newtheorem{lemma}{Lemma}[section]
\numberwithin{lemma}{subsection}
\newtheorem{corollary}[lemma]{Corollary}
\newtheorem{proposition}[lemma]{Proposition}
\newtheorem{theorem}[lemma]{Theorem}

\theoremstyle{definition}
\newtheorem{assumption}[lemma]{Assumption}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{example}[lemma]{Example}
\newtheorem{remark}[lemma]{Remark}
\newtheorem{problem}[lemma]{Problem}

\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\diver}{div}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\Id}{Id}
\DeclareMathOperator{\Ima}{im}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\vol}{vol}

\newcommand{\aop}{\mathscr{A}}
\newcommand{\alternating}[2]{ {\text{Alt}^{#1}\,#2} }
\newcommand{\integers}{\mathbb{Z}}
\newcommand{\smoothcompforms}[2]{C_0^\infty \Lambda^{#1}(#2)}
\newcommand{\lpcoho}{H^k_{p,dR}}
\newcommand{\naturalnum}{\mathbb{N}}
\newcommand{\norm}[2]{\lVert #1 \rVert_{#2}}
\newcommand{\omegabar}{\overline{\Omega}}
\newcommand{\rational}{\mathbb{Q}}
\newcommand{\real}{\mathbb{R}}
\newcommand{\rop}{\mathscr{R}} % short for R operator


\begin{document}

\section{Introduction}
Our goal is to study the homogeneous magnetostatic problem on the exterior 
domain of a triangulated torus. That means 
that for the unbounded domain  $\Omega \subseteq \real^3$ we have
$\real^3 \setminus \Omega$ is a triangulated torus. We also need a 
piecewise straight (i.e. triangulated) closed curve around the torus.
%%% TBD: Picture
{\color{red} (TBD: Define the "triangulated torus" more rigorous)}

Let $B$ be a magnetic field on the domain $\Omega$.
We the have the following boundary value problem:

\begin{align}
    \curl \, B &= 0, \\ 
    \diver \, B  &= 0 \text{ in } \Omega \\
    B \cdot n &= 0 \text{ on } \partial \Omega \text{ and }\\
    \int_\gamma B \cdot dl &= C_0
\end{align}
where $n$ is the outward normal vector field on $\partial \Omega$ and 
$C_0 \in \real$. We want to prove existence and uniqueness of 
solutions. In order to do so we will need to introduce Sobolev spaces of 
differential forms and basics from
simplicial topology {\color{red} among other things...}

\section{Differential forms}


\subsection{Alternating maps} \label{sec:alternating_maps}

For the introduction of alternating maps we follow
the short section in Arnold's book
\cite[Sec. 6.1.]{arnold} combine it 
with material from \cite[Sec.\,V.1]{topology_and_geometry}.
However, more arguments and additional details are provided especially  
in Sec.\,\ref{sec:scalar_and_vector_proxies} about scalar and vector proxies.

\begin{definition}[Alternating $k$-linear form]
    Let $V$ be a real vector space with $\text{dim}\,V = n$.
    We call map $\omega: V^k \rightarrow \real$ 
    \textit{$k$-linear form} if it is linear in every argument.
    % \begin{align*}
    %     \omega: \underbrace{V \times V \times ... \times V}_{k \text{ times}}
    %     \rightarrow \real
    % \end{align*}
    We call a $k$-linear form 
    \textit{alternating} if the sign switches when two arguments are exchanged 
    i.e.
    \begin{align*}
        \omega(v_1,...,v_i,...,v_j,...,v_k)
        = - \omega(v_1,...,v_j,...,v_i,...,v_k), \text{ for } 1\leq i < j \leq k,
        \quad v_1,...,v_k \in V.
    \end{align*}
    We denote the space $k$-linear forms on $V$ as $\alternating{k}{V}$.
    For the special case $k=0$ we define $\alternating{0}{V} \vcentcolon= \real$.
\end{definition}

Let $\mathcal{S}_k$ be the set of all permutations 
$\{ 1, 2, ..., k\} \rightarrow \{ 1, 2, ..., k \}$. A 
permutation that only exchanges two numbers is called transposition 
and denoted by $(i,j)$ for the transposition that exchanges $(i,j)$ with 
$i \neq j$. Every permutation can be written as the composition of 
transpositions. This decomposition into transpositions is not unique.
Take a permutation $\pi \in \mathcal{S}_k$ and decompose it into transpositions
\begin{align*}
    \pi = \tau_p \circ \tau_{p-1} \circ ... \circ \tau_1.
\end{align*}
The sign $\sgn(\pi)$ of a permutation 
$\pi: \{ 1,2,...,n\} \rightarrow \{ 1,2, ..., n\}$ is equal to $(-1)^p$.
Even though the decomposition is not unique the parity of the number of
transpositions is always the same and hence the sign is well-defined.
For example, the permutation $(1,2,3,4) \mapsto (2,3,1,4)$ 
can be built by performing the transpositions $(1,2)$ and $(1,3)$ so 
$\sgn(\pi) = (-1)^2 = 1$. 

Going back to alternating forms, this also means for any permutation 
$\pi: \{1,2,...,k\} \rightarrow \{1,2,...,k\}$ and 
$\omega \in \alternating{k}{V}$
\begin{align*}
    \omega(v_{\pi(1)},v_{\pi(2)},...,v_{\pi(k)})
    = \sgn(\pi)\, \omega(v_1, v_2,..., v_k).
\end{align*}

\begin{definition}[Wedge product]
    For $\omega \in 
    \alternating{k}{V}$, $\mu \in 
    \alternating{l}{V}$ we define the wedge product $\omega \wedge \mu \in 
    \alternating{k+l}{V}$ 
    \begin{align*}
        (\omega \wedge \mu) (v_1,...,v_k,v_{k+1},...,v_{k+l}) =
        \sum\limits_\pi
        \text{sgn}(\pi) \omega(v_{\pi(1)},...,v_{\pi(k)}) 
        \nu(v_{\pi(k+1)},...,v_{\pi(k+l)})
    \end{align*}
    where we sum over all permutations 
    $\pi: \{1,...,k+l\} \rightarrow \{1,...,k+l\}$ 
    s.t. $\pi(1) < ... < \pi(k)$ and $\pi(k+1) < ... < \pi(k+l)$.        
\end{definition}

Let us mention some important properties of the wedge product. It is 
associative, but not commutative. For $\omega \in 
\alternating{k}{V}$, $\mu \in 
\alternating{l}{V}$ we have 
\begin{align}
    \omega \wedge \mu = (-1)^{kl} \mu \wedge \omega. \label{eq:commutativity_wedge_product}
\end{align}
Recalling the definition of the sign of a permutation $\pi \in \mathcal{S}_k$ 
we get for linear forms $\omega_1, \omega_2, ..., \omega_k \in V'$
\begin{align*}
    \omega_{\pi(1)} \wedge \omega_{\pi(2)} \wedge ... \wedge \omega_{\pi(k)}
    = \sgn(\pi) \, \omega_1 \wedge \omega_2 \wedge ... \wedge \omega_k
\end{align*}
and if a linear form appears twice then the expression is zero.

There is a useful formula for computing the wedge product of linear forms.
We denote the dual space of $V$ as $V'$.
For  $\omega_1,...,\omega_k \in \alternating{1}{V} = V'$
, $k \leq n$ we have the formula (\cite[p.260]{topology_and_geometry})
\begin{align}
    \omega_1 \wedge ... \wedge \omega_k (v_1,...,v_k)
    = \det (\omega_s(v_t))_{1\leq s,t \leq n}. 
    \label{eq:wedge_product_of_one_forms}
\end{align}
This formula can be easily proven by induction using the definition of the 
wedge product and the determinant.

Let $\{ b_i\}_{i=1}^n$ be any basis of $V$ and $\{ b^i\}_{i=1}^n$ the 
correspoding dual basis i.e. 
$b^i \in V'$, $b^i(b_j) = \delta_{ij}$ for $i,j = 1,2,..., n$. Then 
\begin{align*}
    \{b^{i_1} \wedge b^{i_2} \wedge ... \wedge b^{i_k} | \, 
    1 \leq i_1 < ... < i_k \leq n \}
\end{align*}
is a basis of $\alternating{k}{V}$. In particular, 
$\dim\, \alternating{k}{V} = \binom{n}{k}$.

Assume now that we are given an inner product on $V$, 
$\langle \cdot, \cdot \rangle_V$ where we will usually leave out the 
subscript if it is clear what space we mean.
Recall the Riesz isomorphism $\Phi: V \rightarrow V'$ defined by
\begin{align*}
    \Phi v (w) = \langle v, w \rangle.
\end{align*}
Then we obtain an inner 
product on the dual space $V'$ by using the Riesz isomorphism $\Phi$ 
\begin{align*}
    \langle \Phi v, \Phi w \rangle_{V'} \vcentcolon= \langle v, w \rangle_V
\end{align*}
which makes the Riesz isomorphism to an isometry.

Now we can define an inner product on $\alternating{k}{V}$ by defining
\begin{align*}
    \langle b^{i_1} \wedge b^{i_2} \wedge... \wedge b^{i_k}, 
    b^{j_1} \wedge... \wedge b^{j_k} \rangle_{\alternating{k}{V}} 
    \vcentcolon= \det  ( \langle b^{i_k}, b^{i_l} \rangle_V )_
    {1\leq k,l \leq n} 
\end{align*}
which is then extended to all of $\alternating{k}{V}$ by linearity. 
We denote with $\lvert \cdot \rvert _\alternating{k}{V}$ the induced norm.
For an orthonormal basis 
$u_1$, ..., $u_n$ the corresponding basis 
$u^{i_1} \wedge v^{i_2} \wedge ... \wedge u^{i_k}$, 
$1\leq i_1 < ... < i_k \leq n$ is an orthonormal basis of $\alternating{k}{V}$.


Next, we want to introduce the \textit{pullback} as a natural linear
mapping between spaces of alternating forms. 
Let $V$ and $W$ be finite-dimensional real
vector spaces with ordered bases $(b_i)_{i=1}^n$ and $(c_j)_{j=1}^m$ 
respectively. We write a basis in standard brackets $(\cdot)$ if the basis is 
ordered. Let $L \in \mathcal{L}(V,W)$ where $\mathcal{L}(V,W)$ is the 
space of linear mappings from $V$ to $W$. For $\omega \in \alternating{k}{W}$
we define the pullback $L^* \omega \in \alternating{k}{V}$ via 
\begin{align*}
    (L^* \omega)(v_1,...,v_k) = \omega(L\,v_1,...,L\,v_k).
\end{align*}
It is then easy to see that 
$L^*$ is a linear mapping from $\alternating{k}{W}$ to 
$\alternating{k}{V}$. 

It is obvious from the definitions of the wedge product and 
the pullback that we have 
\begin{align*}
    L^*(\omega \wedge \nu) = L^*\omega \wedge L^* \nu \quad \forall 
        \omega \in \alternating{k}{W}, \; \nu \in \alternating{l}{W}.
\end{align*}

\begin{proposition}
    Let $A \in \real^{m\times n}$ be the matrix representation of $L$ in the 
    above bases i.e.
    $L\,b_i = \sum_{j=1}^m A_{ji} c_j$. Then we get the basis representation 
    of the pullback 
    \begin{align}
        L^* (c^{j_1} \wedge c^{j_2} \wedge ... \wedge c^{j_k})
        = \sum\limits_{1 \leq i_1 < ... < i_k \leq n} 
            \det A_{(j_1,...,j_k),(i_1,...,i_k)} \,
            b^{i_1} \wedge b^{i_2} \wedge ... \wedge b^{i_k}
        \label{eq:basis_representation_pullback}
    \end{align}
    where $A_{(j_1,...,j_k),(i_1,...,i_k)}$ is the matrix we get 
    by choosing the rows $j_1,...,j_k$  and the columns $i_1$, ... , $i_k$. 
\end{proposition}
\begin{proof}
    Because $\{ b^{i_1}\wedge b^{i_2}\wedge ... \wedge b^{i_k} 
    \mid 1 \leq i_1 < ... < i_k  \leq n \}$ and 
    $\{ c^{j_1}\wedge c^{j_2}\wedge ... \wedge c^{j_k} 
    \mid 1 \leq j_1 < ... < j_k  \leq m \}$ are bases for $\alternating{k}{V}$ 
    and $\alternating{k}{W}$ respectively, we can find $\lambda_{i_1 ... i_k}$ s.t.
    \begin{align}
        L^* (c^{j_1} \wedge c^{j_2} \wedge ... \wedge c^{j_k})
        = \sum\limits_{1 \leq i_1 < ... < i_k \leq n} 
        \lambda_{i_1 ... i_k} b^{i_1} \wedge b^{i_2} \wedge ... \wedge b^{i_k}
        \label{eq:basis_representation_pullback_unspecified_coefficents}
    \end{align}

    Now recall the formula for the wedge product of $1$-forms 
    $\nu_i \in \alternating{1}{V} = V'$
    \begin{align*}
        \nu_1 \wedge ... \wedge \nu_k (v_1,...,v_k) = 
        \det \big( \nu_s(v_t) \big)_{1 \leq s,t \leq n}.
    \end{align*}
    Fix now $1 \leq l_1 < ... <  l_k \leq n$. Then we get from this formula
    $b^{i_1} \wedge b^{i_2} \wedge ... \wedge b^{i_k} ( b_{l_1},...,b_{l_k}) = 1$ 
    iif. $(i_1,...,i_k) = (l_1,...,l_k)$. Here it is important to remember that 
    these indices are ordered. Plugging this in 
    (\ref{eq:basis_representation_pullback_unspecified_coefficents}) gives us 
    \begin{align*}
        \lambda_{i_1 ... i_k}  &= 
            L^* (c^{j_1} \wedge c^{j_2} \wedge ... \wedge c^{j_k})
            (b_{l_1},...,b_{l_k})
        \\ &= c^{j_1} \wedge c^{j_2} \wedge ... \wedge c^{j_k} 
            (L\,b_{l_1},...,L\,b_{l_k})
        \\ &= \det \big( c^{j_s}(\sum_{r_t = 1}^m A_{r_t,l_t}c_{r_t}) 
            \big)_{1 \leq s,t \leq k}
        \\ &= \det \big( \sum_{r_t = 1}^m A_{r_t,l_t} \delta_{j_s,r_t}
            \big)_{1 \leq s,t \leq k}
        \\ &= \det \big( A_{j_s,l_t} \big)_{1 \leq s,t \leq k}
        \\ &= \det A_{(j_1,...,j_k),(i_1,...,i_k)}.
    \end{align*}
\end{proof}


We want to emphasize the special case of the pullback of a $n$-linear map 
with $m = n$. So take $\omega \in \alternating{n}{W}$. Then we know that 
dim$\,\alternating{n}{W} = {n\choose n} = 1$ and so
$\omega = \lambda\, c^1 \wedge ... \wedge c^n$ for some $\lambda \in \real$. 
Then there only remains one summand in (\ref{eq:basis_representation_pullback}) 
and we obtain for this special case
\begin{align}
    L^* \omega = \lambda \, \det A \, b^1 \wedge ... \wedge b^n
    \label{eq:pullback_alternating_nlinear_map}
\end{align}

We want to examine $\alternating{n}{V}$ a bit closer. 
$\alternating{n}{V}$ is one-dimensional and so we can choose a basis by fixing 
a specific non-zero element. We want to choose one specific element 
called the \textit{volume form} which will play a crucial role 
when we define integration on a manifold in Sec. \ref{}. We also need it to 
define the Hodge star operator below.

The choice of this volume form will depend on the orientation. 
We say that two bases of $V$ 
have the same orientation if the change of basis has positive determinant. 
That divides the bases into two classes with different orientation.
We choose one of these classes and call these bases positively
oriented. In $\real^n$, the convention is to define the class as 
positively oriented which includes the standard orthonormal basis.

\begin{definition}[Volume form]
    Let $(b_i )_{i=1}^n$ be any positively oriented
    basis. Let $G$ be the Gramian matrix i.e. $G_{ij} = \langle b_i, b_j \rangle$ 
    which is always a symmetric positive definite matrix.
    Then we define the \textit{volume form}
    \begin{align*}
        \vol \vcentcolon= \sqrt{\det G} \, b^1 \wedge b^2 \wedge ... \wedge b^n.
    \end{align*}
\end{definition}

We have the following defining property of the volume form.

\begin{proposition}
    For any ordered
    orthonormal basis $(u_i)_{i=1}^n$ we have 
    \begin{align*}
        \vol (u_1,\,u_2,...,\,u_n) = (-1)^s.
    \end{align*}
    with $s=0$ if $(u_1,...,u_n)$ has the same orientation as $(b_i)_{i=1}^n$ 
    and $s=1$ otherwise. 
\end{proposition}
\begin{proof}
    Let us define the matrix $B \in \real^{n\times n}$, $B_{k,i} = \langle b_i, u_k
    \rangle_V$ which is just the change of basis matrix from $( b_i )_{i=1}^n$ 
    to $( u_i )_{i=1}^n$. 
    Then using basic linear algebra we get
    $ G = B^\top B$ and 
    $\sqrt{\det G} = (-1)^s \det B$. Let now $\Psi$ be the linear map with 
    $\Psi b_i = u_i$. In the basis $( b_i )_{i=1}^n$ this has the matrix 
    representation $B^{-1}$ and so by using 
    (\ref{eq:pullback_alternating_nlinear_map}) we get
    \begin{align*}
        \vol (u_1,\,u_2,...,\,u_n) &= \sqrt{ \det G} \, b^1 \wedge ... \wedge b^n 
        ( \Psi b_1,..., \Psi b_n )
        \\ &= (-1)^s \det B \, \Psi^* (b^1 \wedge ... \wedge b^n )( b_1,..., b_n) 
        \\ &= (-1)^s \det B \, \det B^{-1} \, (b^1 \wedge ... \wedge b^n )( b_1,..., b_n)
        = (-1)^s.
    \end{align*}
\end{proof}
This property also defines the volume form uniquely so it is independent of the 
chosen basis. It only depends on the orientation.
It also shows that $\vol$ is non-zero and thus 
\begin{align*}
    \alternating{n}{V} = \text{span} \{ \vol \}.
\end{align*}

Note that if we choose $\{ b_i \}_{i}$ to be an orthonormal basis to begin 
with the Gramian matrix is just the identity and 
$\vol = b^1 \wedge ... \wedge b^n$. Especially in the case of $\real^n$ if 
we denote the standard dual basis by $\{ dx^i \}_{i=1}^n$ then 
\begin{align*}
    \vol = dx^1 \wedge ... \wedge dx^n.
\end{align*}

We will from now on assume that we fixed a orientation on $V$ and with it 
the volume form vol. 
Using the resulting volume form on $V$
we can now define the \textit{Hodge star operator} with the following 
proposition.
\begin{proposition}
    There exists a isomorphism $\star: \alternating{k}{V} 
    \rightarrow \alternating{n-k}{V}$ s.t. 
    \begin{align}
        \omega \wedge \mu = \langle \star \omega, \mu \rangle_{\alternating{n-k}{V}}
        \vol \quad \forall \mu \in \alternating{n-k}{V}.
        \label{eq:hodge_star_definition}            
    \end{align}
    We call this isomorphism the \textit{Hodge star operator}.
\end{proposition}
\begin{proof}
    Let denote with $\vol'$ the dual basis element of $\vol$ i.e.
    $\vol'(\vol) = 1$. Let us fix $\omega \in \alternating{k}{V}$. 
    Then we can define the following linear form on $
    \alternating{n-k}{V}$
    \begin{align*}
        \mu \mapsto \vol' (\omega \wedge \mu).
    \end{align*}
    Then we define
    $\star \omega$ as the Riesz representative of this linear form that means we 
    have $\vol'(\omega \wedge \mu) = 
    \langle \star \omega, \mu \rangle_{\alternating{k}{V}}$ for all 
    $\mu \in \alternating{n-k}{V}$ which implies (\ref{eq:hodge_star_definition}).
    Checking linearity is trivial and will be omitted.

    It is also clear from the uniqueness of the Riesz representative that 
    the $\star\omega$ is uniquely determined by the above condition and 
    thus $\star$ is injective. Since $\dim \alternating{k}{V} = 
    \binom{n}{k} = \binom{n}{n-k} = \dim \alternating{n-k}{V}$ the injecivity 
    implies surjectivity and $\star$ is an isomorphism.
\end{proof}

Let us collect some important properties of the Hodge star operator 
without proof.
\begin{proposition}\label{prop:properties_hodge_star}
    Let $(u_i)_{i=1}^n$ be an ordered orthonormal basis of $V$. Let 
    $\{ i_1, ..., i_n \} = \{ 1, ..., n\}$, $i_1 < i_2 < ... < i_k$ and 
    $i_{k+1} < ... < i_n$.
    \begin{align}
        \star (u^{i_1} \wedge u^{i_2} \wedge ... \wedge u^{i_k})
        = \sgn(i_1,i_2,...,i_n) u^{i_{k+1}} \wedge ... \wedge u^{i_{n}}
        \label{eq:hodge_star_orthonormal_basis}
    \end{align}
    where $\sgn(i_1,i_2,...,i_n)$ 
    is the sign of the permutation $j \mapsto i_j$. In particular, 
    $\star$ is an isometry since it maps orthonormal bases to orthonormal 
    bases. Furthermore,
    \begin{enumerate}[(i)]
        \item $\star \star \omega = (-1)^{k(n-k)} \omega \quad \forall \omega 
            \in \alternating{k}{V}$
        \item $\omega \wedge \star \nu = \langle \omega, \nu \rangle
            _{\alternating{k}{V}}  \, \vol \quad \forall \omega, \nu \in \alternating{k}{V}$.     
    \end{enumerate}
\end{proposition}
\begin{proof}
    Take $u^{j_{k+1}} \wedge ... \wedge u^{j_n}$ with 
    $1 \leq j_{k+1} < ... < j_n \leq n$. Then 
    \begin{align*}
        &\langle \sgn(i_1,i_2,...,i_n) \, u^{i_{k+1}} \wedge ... \wedge u^{i_{n}},
            u^{j_{k+1}} \wedge ... \wedge u^{j_{n}} \rangle_{\alternating{n-k}{V}}
        \\ &= \sgn(i_1,i_2,...,i_n) \det \big( \langle u^{i_s}, u^{j_t} \rangle \big)_{k+1 \leq s,t \leq n}
        \\ &= \sgn(i_1,i_2,...,i_n) \det \big( \delta_{i_s,j_t} \big)_{k+1 \leq s,t \leq n}.
    \end{align*}
    In the last step we used the fact that $u^i$ are orthonormal since $u_i$ 
    are. Now observe due to the ordering that 
    $\det \big( \delta_{i_s,j_t} \big)_{k+1 \leq s,t \leq n}$ is one i.i.f.
    $i_s = j_s$ for $s = k+1,...,n$ an is zero otherwise.

    For the wedge product we get
    \begin{align*}
        u^{i_1} \wedge ... \wedge u^{i_{k}} \wedge u^{j_{k+1}} \wedge ... 
            \wedge u^{j_n}
        =   \begin{cases}
                \sgn(i_1, ..., i_n)\, \vol, & \text{if $(i_{k+1},...,i_n) = (j_{k+1},...,j_n)$} \\
                0,  & \text{otherwise.}
            \end{cases}.
    \end{align*}
    Comparing both expressions we just proved
    \begin{align*}
        u^{i_1} \wedge ... \wedge u^{i_{k}} \wedge u^{j_{k+1}} \wedge ... \wedge u^{j_n}
        = \langle \sgn(i_1,i_2,...,i_n) u^{i_{k+1}} \wedge ... \wedge u^{i_{n}},
            u^{j_{k+1}} \wedge ... \wedge u^{j_{n}} \rangle_{\alternating{n-k}{V}} \vol
    \end{align*}
    and thus by linearity since the $u^{j_{k+1}} \wedge ... 
    \wedge u^{j_n}$ form a basis of $\alternating{n-k}{V}$ we get , 
    $\star (u^{i_1} \wedge ... \wedge u^{i_{k}}) = 
    \sgn(i_1,i_2,...,i_n) u^{i_{k+1}} \wedge ... \wedge u^{i_{n}}$ as claimed.
    We see from this that $\star$ maps the orthonormal basis to an orthonormal
    basis and is thus an isometry.

    The other two claims follow from that easily. For any $\omega \in 
    \alternating{k}{V}$, $\mu \in \alternating{n-k}{V}$
    \begin{align*}
        \langle \star \star \omega , \mu \rangle_{\alternating{k}{V}}\vol
        &= \star \omega \wedge \mu
        = (-1)^{k(n-k)} \mu \wedge \star \omega 
        \\ &= (-1)^{k(n-k)} \langle \star \mu , \star \omega \rangle_{\alternating{n-k}{V}} \vol
        \\ &= \langle (-1)^{k(n-k)} \omega , \mu \rangle_{\alternating{k}{V}} \vol.
    \end{align*}
    Then the first claim follows since $\mu \in \alternating{k}{V}$ was
    arbitrary.

    For the second claim, take $\omega, \nu \in \alternating{k}{V}$, then
    \begin{align*}
        \omega \wedge \star \nu = \langle \star \nu , \star \omega \rangle _{\alternating{n-k}{V}} \vol
        = \langle \omega , \nu \rangle _{\alternating{k}{V}} \vol.
    \end{align*}
\end{proof}
In particular in $\real^3$, we have 
$\star\star = \text{Id}$ i.e. $\star$ is self-inverse. Notice also 
that we always have $\star 1 = \vol$.

Let us quickly derive the expression in any basis 
for the Hodge star applied to linear 
forms which we will need later. Let $\omega = \sum_i \omega_i b^i \in 
\alternating{1}{V} = V'$. Let us denote $g^{ij} = \langle b^i, b^j \rangle$ 
and $G_{ij} = \langle b_i, b_j \rangle$ again the Gramian matrix.
Then we claim
\begin{align}
    \star \omega = \sqrt{\det G} \sum_{i,j=1}^n \omega_i (-1)^{j-1} 
        g^{ij} b^1 \wedge
        b^2 \wedge ... \wedge \widehat{b^j}\wedge ... \wedge b^n 
        \label{eq:hodge_star_one_forms}
\end{align}
where $\widehat{b^j}$ means that this term is left. The proof is very 
simple in this case. Let $\nu$ denote the expression on the right hand side.
For any $1 \leq l \leq n$ we get
\begin{align*}
    \nu \wedge b^l &= \left( \sqrt{\det G} \sum_{i,j=1}^n \omega_i (-1)^{j-1} g^{ij} b^1 \wedge
        b^2 \wedge ... \wedge \widehat{b^j} \wedge ... \wedge b^n\right) \wedge b^l 
    \\ &= \sqrt{\det G} \sum_{j=1}^n \langle b^j,\sum_{i=1}^n \omega_i  b^i\rangle
        (-1)^{j-1}  b^1 \wedge
        b^2 \wedge ... \wedge \widehat{b^j} \wedge ... \wedge b^n \wedge b^l
    \\ &= \sqrt{\det G} \langle b^l,\omega \rangle
        (-1)^{(l-1)}(-1)^{(n-l)}  b^1 \wedge
        b^2 \wedge ... \wedge b^l  \wedge ... \wedge b^n 
    \\ &= \langle (-1)^{n-1}\omega, b^l \rangle \vol.
\end{align*}
where the inner product is always in the corresponding space of alternating forms.
In the second step, we used that if $j\neq l$ then one basis element must 
appear twice in the wedge product which is then zero. If $j=l$ then 
$\sgn (1,2, ..., \hat{l},...,n,l) = (-1)^{n-l}$ because we need $(n-l)$
transpostions to bring the indices into order. So we proved 
$(-1)^{n-1}\omega = \star \nu$ and thus $\star \omega = (-1)^{n-1} \star\star\nu = \nu$.

Then by linearity we obtain (\ref{eq:hodge_star_definition}) and thus 
the given expression is indeed equal to $\star b^i$ as claimed.


\subsection{Scalar and Vector proxies} \label{sec:scalar_and_vector_proxies}
Now we want to relate alternating maps to elements of the 
vector space $V$ itself or to scalars. Let us start with the easiest 
case. $\alternating{0}{V}$ are already scalars by definition. Now we can use 
the Hodge star operator which is an isometry 
$\star: \alternating{0}{V} \rightarrow \alternating{n}{V}$ with
$\star c = c \vol$. 
We call the real number that is associated with an element of 
$\alternating{n}{V}$ \textit{scalar proxy} i.e. the scalar proxy of 
$c \in \real$ is just $c \vol \in \alternating{n}{V}$.

Next, we will move on to $\alternating{1}{V}$ and $\alternating{n-1}{V}$. 
Let $\Phi: V \rightarrow V'$ denote the Riesz isomorphism which is an isometry.
Because $V' = \alternating{1}{V}$ this gives us the correspondence of 
vectors and linear forms. Now we can once again use the Hodge star and obtain 
the isometry $\star \Phi: V \rightarrow \alternating{n-1}{V}$. We call 
the vectors associated with an alternating $1$- or $(n-1)$-linear map 
\textit{vector proxy}.

These way to identfy alternating maps with scalars and vectors gives us the 
ability to look at the notions defined above in the context of scalars 
and vectors.

Let us look at the wedge product. We have for $v,w \in V$
\begin{align*}
    \Phi v \wedge \star \Phi w = \langle \Phi v , \Phi w \rangle_{V'} \vol
    = \langle v , w \rangle_{V} \vol
\end{align*}
which means that the wedge product of a linear from and an alternating $(n-1)$-
linear map corresponds in proxies to the inner product.

Note that for $n=2$ the situation 
is slightly ambiguous, see \cite[p.67]{arnold}. But this case will not be
relevant in this thesis. % TBD: Are you sure?

In the case of $V= \real^3$ with the standard basis
vectors $e_1$, $e_2$ and $e_3$. Denote the resulting elements 
of the dual basis with $e^1$, $e^2$ and $e^3$ respectively. 
Take $v = v_1 e_1 + v_2 e_2 + v_3 e_3 \in \real^3$ 
and recall that for a orthonormal basis the Riesz isomorphism maps basis 
elements to their dual basis elements i.e. $\Phi e_i = e^i$. Hence, 
we get $\Phi v = v_1 e^1 + v_2 e^2 + v_3 e^3$. Take another $w \in \real^3$.
Then using the $e^i \wedge e^j = - e^j \wedge e^i$ we get 
\begin{align}
    \Phi v \wedge \Phi w = \star \Phi (v \times w). 
    \label{eq:cross_product_as_wedge_product}
\end{align}
That means in $3D$ in terms of vector proxies, the wedge product 
of two linear forms corresponds to the cross product. Note that 
(\ref{eq:cross_product_as_wedge_product}) is formulated without using a 
specific basis and can therefore be computed using any basis i.e. 
if we have $v = \tilde{v}_1 b_1 + \tilde{v}_2 b_2 + \tilde{v}_3 b_3$ 
and analogous for $w$ we could still calculate the cross product directly as 
\begin{align*}
    v \times w = \Phi^{-1} \star \big(\Phi v \wedge \Phi w \big).
\end{align*}
One has to take care though because if the basis is not orthonormal 
the Riesz isomorphism does not map basis elements $b_i$ to their respective 
dual basis elements $b^i$. We have 
\begin{align*}
    \Phi b_i = \sum_{i=1}^{n} \langle b_j, b_i \rangle b^j
\end{align*}
i.e. it has the gramian matrix $G$ as basis representation. 
This is easy to 
see. Let $\Phi b_i = \sum_j \lambda_j b^j$. Then
\begin{align*}
    \lambda_j = \Phi b_i (b_j) = \langle b_i, b_j \rangle.
\end{align*}
As derived above, the Hodge star is not as trivial to compute either.

This illustrates the idea of a coordinate free description which is a important
notion in differential geometry (see \cite{}). 

Similarly, we want to explore the pullback in terms of vector proxies as well. 
These will be important in the next section when we talk about the pullback 
of differential forms and apply these to the tranformation of integrals.
In order to avoid complicated computations we will stick to orthonormal bases.
Let $\{ b_i \}_{i=1}^n$ be an ONB of $V$ and 
$\{ c_j \}_{j=1}^m$ be an ONB of $W$. Let $L : V \rightarrow W$ 
again be a linear map and $A$ be the basis representation of it w.r.t. 
the two bases given i.e. $L b_i = \sum_j A_{ji} c_j$. 
Then we get the pullback of linear forms in terms 
of vector proxies 
as $\Phi_V^{-1} L^* \Phi_W : W \rightarrow V$. Recall 
formula (\ref{eq:pullback_alternating_nlinear_map}) which 
gives us for the pullback of one forms 
\begin{align}
    L^* c^j = \sum_{i=1}^n A_{j,i} b^i \label{eq:pullback_linear_forms}
\end{align}
so the matrix representation w.r.t. the given dual bases is $A^\top$.
Then since we have $\Phi_V b_i = b^i$ and analogous for $c^j$
the matrix representation of the Riesz isomorphism is just the identity.
In total, the basis representation of $\Phi_V^{-1} L^* \Phi_W$ is then also 
$A^\top$.

For $m=n$ let us look at the pullback of alternating $(n-1)$-linear maps.
In terms of vector proxies this can then be expressed as 
$\Phi_V^{-1} \star^{-1} L^* \star \Phi_W$. Note that we used the same symbol 
$\star$, but it is once applied in $W$ and then the inverse in $V$. It 
can be shown with the same ideas and (\ref{eq:hodge_star_orthonormal_basis})
that the matrix representation is the adjugate matrix 
$\text{ad}(A)$ defined as 
\begin{align*}
    \text{ad}(A)_{ij} = (-1)^{i+j} \det A_{-j,-i}
\end{align*} 
where $A_{-j,-i}$ is the matrix without the $j$-th row and $i$-th column.
If $A$ is invertible then $(\det A)\,A^{-1} =  \text{ad}(A)$. 

The pullback of $n$-linear forms in terms of vector proxies is 
$\star^{-1} L^* \star$. Again n the case of $n=m$ and an 
orthonormal basis we get for $c \in \real$
\begin{align*}
    \star^{-1} L^* \star c = \star^{-1} L^* c \vol 
    = \star^{-1} c\,\det L \,\vol = c\,\det L.
\end{align*}

\subsection{Differential geometry}\label{sec:differential_geometry}

Before we define differential forms, let us start by revising some basics
from differential geometry. We follow the approach from 
\cite[Sec. II]{topology_and_geometry} for the most part. 

\subsubsection{Manifolds}

In order to formulate the definition of a manifold, let us recall the 
definition of a topological space.
\begin{definition}[Topological space]
    A topological space is a set $X$ together with collection of subsets of 
    $X$ denoted by $\mathcal{T}$ s.t.
    \begin{itemize}
        \item $U,V \in \mathcal{T} \Rightarrow U \cap V \in \mathcal{T}$
        \item for $\{ U_i \in \mathcal{T} \mid i \in \mathcal{I} \}$
            for any index set $\mathcal{I}$, 
            $\bigcup_{i\in \mathcal{I}} U_i \in \mathcal{T}$ and
        \item $\emptyset, X \in \mathcal{T}$.
    \end{itemize}
    The sets contained in $\mathcal{T}$ are called \textit{open}.
\end{definition}
For example, a metric space together with its usual open sets is a topological
space. Another well known example of topologies which do not arise from a metric
are the weak and weak-$\star$ topology on infinite dimensional spaces
(see \cite[Ch.\,3]{brezis}).

\begin{definition}[Second countable topological space]
    Let $(X,\mathcal{T})$ be a topological space. Then we call 
    $\mathcal{B}\subseteq \mathcal{T}$ a basis for the topology of $X$ if 
    every open set (i.e. every set in $\mathcal{T})$ is a union of sets 
    in $\mathcal{B}$. If a topological space has a countable basis it is called
    \textit{second countable}.
\end{definition}
$\real^n$ is an example of a second countable topological space. Consider 
the countable set of balls $\{ B_r(x) \mid r \in \rational, x \in \rational^n\}$
where $ B_r(x)$ are the balls with center $x$ and radius $r$.
Then it is trivial to show that any open set in $\real^n$ is a union of 
of these balls. Hence, $\real^n$ is second countable.

\begin{definition}[Hausdorff] space
    Let $(X, \mathcal{T})$ be a topological space. We call $(X, \mathcal{T})$
    \textit{Hausdorff} if we can separate any two different points of $X$
    with disjoint neighborhoods. That means for any $x,y \in X$, 
    $x\neq y$ there are $U_x, U_y \in \mathcal{T}$ s.t. 
    $x \in U_x$, $y \in U_y$ and $U_x \cap U_y = \emptyset$.
\end{definition}

\begin{example}
    Let $(X,d)$ be a metric space and take 
    $x,y \in X$, $x\neq y$. Then for the distance 
    $\delta \vcentcolon= d(x,y) > 0$ we can choose the open balls around $x$ and 
    $y$ with radius 
    $\delta/2$, denoted by $B_{\delta/2}(x)$ and $B_{\delta/2}(y)$. These are 
    open and obviously disjoint. Therefore any metric space is Hausdorff. 
\end{example}

\begin{definition}[Manifold]
    A $n$-dimensional $C^\alpha$ manifold with boundary, $\alpha \in \naturalnum$, 
    is a second countable Hausdorff 
    space $M$ with an open cover $\{ U_i \} _{i\in I}$
    and a collection of maps called \textit{charts} $\phi_i$, $i\in I$ for 
    some index set $I$ s.t.
    \begin{itemize}
        \item $\phi_i: U_i \rightarrow V_i \subseteq \real_- \times \real^{n-1}$
            are homeomorphisms
        \item for two charts $\phi_i$, $\phi_j$ the 
            \textit{change of coordinates} or 
            \textit{chart transition} $\phi_j \circ \phi_i^{-1}: 
            \phi_i(U_i \cap U_j) \rightarrow \phi_j(U_i \cap U_j)$ 
            is a $C^\alpha$ diffeomorphism. If $\alpha=0$ it is a homeomorphism.
    \end{itemize}
    When we write $(U_i, \phi_i)$ we mean the chart $\phi_i$ has domain $U_i$.
\end{definition}
The charts provide us with \textit{local coordinates} $x_k: U_i \rightarrow \real^n$,
$k = 1, ..., n$ with $\mathbf{x}(p) = (x_1(p),...,x_n(p))^\top = \phi(p) \in \real^n$.

Let us take a look at some examples. First, take any open domain 
$\Omega \subseteq \real^n$. Then we can take the identity as a chart.
Since $\real^n$ with the standard topology is Hausdorff and second coundable
the same reasoning applies to open subdomains. Hence, $\Omega$ is a 
$n$-dimensional $C^\infty$ manifold. 

\begin{proposition}
    Every manifold has a countable atlas. 
\end{proposition}
\begin{proof}
    Take any atlas $\{(U_i, \phi_i) \}_{i \in I}$. Because the manifold is 
    second countable there exists a countable basis of the topology 
    $\mathcal{B} = \{ B_0, B_1, ... \}$. Every basis of a topological is 
    a open cover which is easily checked. Define 
    $\mathcal{A} = \{ k \in \naturalnum \mid B_k \subseteq U_i \text{ for some 
    $i \in I$} \}$. Then for every $k \in \mathcal{A}$ choose 
    $i_k \in I$ s.t. $B_k \subseteq U_{i_k}$. Then ${U_{i_k}}_{k\in \mathcal{A}}$ 
    is an open cover and thus $\{ (U_{i_k}, \phi_{i_k}) \}_{k \in \mathcal{A}}$
    is countable atlas.
\end{proof}
Due to this proposition we will from now on assume that all the chosen atlas
is countable.
Note that here the second countability is essential. Some authors do not 
require this in the defintion of a manifold and then this proposition might fail.
Another important property is the existence of a partition of unity on $M$ 
assuming $M$ is smooth which we will not prove.

\begin{theorem}[Partition of unity]
    Let $M$ be a smooth (i.e. $C^\infty$) manifold with atlas 
    $\{U_i, \phi_i)\}_{i=0}^N$, $N \leq \infty$. Then there exists a smooth
    partition of unity subordinate to the open cover $\{U_i\}_{i=0}^N$.
    That means there exists a family of non-negative smooth functions $\{ \chi_i \}_{i=0}^N$
    s.t. $\supp \chi_i \subseteq U_i$ and $\sum_{i=0}^N \chi_i(p) = 1$ 
    for every $p \in M$.
\end{theorem}
These partitions of unity are typically used to extend a construction that 
is done locally to the entire manifold as we will see later.

Let us denote $\real_- \vcentcolon= \{ x \in \real \mid x \leq 0 \}$. 
Let us for the following equip $\real_- \times \real^{n-1} \subseteq \real^n$ with the 
subspace topology i.e. we call a set $V \subseteq \real_- \times \real^{n-1}$ 
open i.i.f. there exists an open set $V' \subseteq \real^n$ s.t. 
$V = V' \cap \real_- \times \real^{n-1}$. This means e.g. that 
$B_1(0) \cap \real_- \times \real^{n-1}$ is open which is not an open set 
in the standard topology of $\real^n$.
\begin{definition}[Manifold with boundary]
    We call $M$ a \textit{manifold with boundary} if the charts $\phi_i$, 
    $i\in I$ are homeomorphism from $M$ into $\real_- \times \real^{n-1}$ 
    endowed with the subspace topology. The \textit{boundary} 
    $\partial M$ are the points that get mapped to ${0} \times \real^{n-1}$ 
    by the charts i.e. $\partial M = \bigcup_{i\in I} \phi_i^{-1}({0} \times \real^{n-1})$.
\end{definition}

We should note the relationship between the boundary in the usual topological sense 
and the above definition of a boundary. Let $\Omega \subseteq \real^n$ be 
an open $C^1$ domain. Then $\partial \Omega$ in the usual topological sense 
is $\overline{\Omega} \setminus \partial \Omega$. However, if we see $\Omega$ 
as a manifold then the boundary $\partial \Omega$ is empty. If we look 
$\overline{\Omega}$ as a manifold with boundary, then the two notions agree.

Another important difference, is that in the case of manifold $\partial \partial M = \emptyset$,
but for the general topological boundary that is not the case. If we have e.g. a single 
point $\{ x \} \subseteq \real^n$ then $\partial \{x \} = \{ x \}$.

From now on we want to investigate certain structures on a manifold 
that require some regularity to be defined. Therefore, 
we will assume $\alpha > 0$ i.e. our manifolds are 
differentiable.

\begin{remark}
    There is also the concept of Lipschitzian manifolds. Then using Rademachers 
    theorem some of the structures that are introduced below can be extended 
    with some care. See \cite{lipschitz_manifolds} for a detailed discussion.
\end{remark}

\begin{definition}[Orientation of a manifold]
    We call an atlas \textit{oriented} if the Jacobian of the coordinate
    changes has positive determinant. A manifold that can be equipped with 
    an oriented atlas is called \textit{orientable}.
\end{definition}

The next important concept we will recall are tangent spaces. 
It should be noted that there are different definitions of tangent space, but
these lead to isomorphic notions 
(see e.g. \cite[Sec.\,1.B]{riemannian_geometry}).

\begin{definition}
    Let $M, N$ be an $n$- and $m$-dimensional manifold with or without boundary 
    and a function $F: M \rightarrow N$. Take $p \in M$ and let $(\phi, U)$ 
    and $(\psi,V)$ be charts at $p$ and $F(p)$ with local 
    coordinates $\{x_i\}_{i=1}^n$ and $\{y_j\}_{j=1}^m$ respectively. 
    Then we call the function 
    \begin{align*}
        \bar{F} (x_1,...,x_n) = \psi \circ F \circ \phi^{-1}(x_1,...,x_n)        
    \end{align*}
    \textit{$F$ expressed in local coordinates} which depends
    on the chosen local coordinates.
\end{definition}

For a point $p \in M$ and a neighorhood $U \subseteq M$ of $p$ and 
a $V \subseteq N$ a neighborhood of $F(p)$ with local coordinate charts 
$(\phi, U)$ and $(\psi, V)$  and resulting local coordinates 
$\{x_i\}_{i=1}^m$ and $\{ y_j\}_{j=1}^n$ respectively and assume 
$M$ and $N$ to be at least $C^1$. We call a function 
$F: U \rightarrow N$ differentiable at $p$ if the expression in local coordinates
is differentiable i.e. if 
$\psi \circ f \circ \phi^{-1}$ is differentiable
at $\phi(p)$.
We define its Jacobian $DF(p) \vcentcolon= D(\psi \circ F \circ \phi^{-1})(\phi(p))$ 
and we denote 
\begin{align}
    \frac{\partial F_j}{\partial x_i}(p) 
    = \frac{\partial (y_j \circ F \circ \phi^{-1})}{\partial x_i} (\phi(p))
    \label{eq:derivative_on_manifold} 
\end{align}

This definition of differentiabilty is independent of the chart. 
Let $(\tilde{U},\tilde{\phi})$ with $p \in \tilde{U}$ be 
another chart and analogous $(\tilde{V},\tilde{\psi})$ be local coordinate 
at $F(p)$.
Then 
\begin{align*}
    \tilde{\psi} \circ F \circ \tilde{\phi}^{-1} 
    = \tilde{\psi} \circ \psi^{-1} \circ \psi \circ F \circ \phi^{-1} \circ \phi \circ \tilde{\phi}^{-1}
\end{align*}
and since the chart transitions are at least $C^1$-diffeomorphisms by definition
$\tilde{\psi} \circ F \circ \tilde{\phi}^{-1} $ is differentiable as well.
It is important to notice though, that the values of the Jacobian 
and the derivatives depend on the chosen representation.

These type of definitions via local charts on a manifold are frequent in
differential geometry. This is a proper definition if it is independent of the 
chosen chart. Because we do not want to bother with the technicalities of 
differential geometry too much we will very often leave out these types of
proofs.  

\begin{definition}[Tangent space]
    Let $I \subseteq \real$ be an interval containing $0$ and 
    $\gamma: I \rightarrow M$ be a differentiable curve with $\gamma(0) = p \in M$.
    If $0$ is on the boundary of $I$ then we mean the one sided derivative.
    Let $f:M \rightarrow \real$ be a differentiable function. Let
    $(\phi,U)$ be a local chart.
    We define the the directional derivative 
    $D_\gamma(f) \vcentcolon= \frac{d}{dt} f(\gamma(t)) |_{t=0}$.
    We call the functional $D_\gamma: C^1(U) \rightarrow \real$ 
    a \textit{tangent vector}. 
    The real vector space of all tangent vectors at $p$ is called the 
    \textit{tangent space} and denoted by $T_p M$    
\end{definition}
This begs the question why $T_p M$ is actually a vector space. Let $(U,\phi)$ 
again be a local chart at $p$.
We can 
express a tangent vector $D_\gamma$ in local coordinates by 
\begin{align}
    D_\gamma(f) &=  \frac{d}{dt} f(\gamma(t)) \big|_{t=0}
    =  \frac{d}{dt} (f \circ \phi^{-1} \circ \phi)  (\gamma(t)) \big|_{t=0}
    \\ &= \sum\limits_{i=1}^k \frac{\partial (f \circ \phi^{-1})}{\partial x_i} 
        (\phi(p))
        \, (x_i\circ \gamma)'(0)
    = (\sum\limits_{i=1}^k v_i  \frac{\partial}{\partial x_i}\Big|_p )(f).
\end{align}
Thus we can express 
\begin{align*}
    D_\gamma = \sum\limits_{i=1}^k 
    (x_i \circ \gamma)' (0) \, \frac{\partial}{\partial x_i}\bigg|_p.
\end{align*}
We will now leave out the reference to $p$ in the partial derivative.
For the other direction take $\mathbf{v} = (v_1, v_2, ..., v_n)^\top \in \real^n$. 
We now want to find a differentiable curve $\gamma$ s.t. $\gamma(0) = p$ 
and $D_\gamma = \sum_{i=1}^n v_i \frac{\partial}{\partial x_i}$.
For that define $\gamma \vcentcolon= \phi^{-1} (\phi(p) + \mathbf{v}t)$.
Then
\begin{align*}
    D_\gamma = \sum_{i=1}^n (x_i\circ \gamma)'(0) \frac{\partial}{\partial x_i}
    = \sum_{i=1}^n (x_i(p) + v_i t)'(0) \frac{\partial}{\partial x_i}
    = \sum_{i=1}^n v_i \frac{\partial}{\partial x_i}.
\end{align*}
So we have shown 
\begin{align*}
    T_p M = \text{span}\, 
        \bigg\{ \frac{\partial}{\partial x_i}\bigg|_p \bigg\}_{i=1}^n.
\end{align*}

In order to show that this is a basis we have to prove linear independence.
Assume we have $\sum_{i=1}^n \lambda_i \, \partial/\partial x_i|_p = 0$
Then because $x_j \circ \phi^{-1} (x) = x_j$ for $x \in \phi(U)$ and 
$1 \leq j \leq n$. Note $x_j$ denote here the variable of 
$\real^n$ and the local coordinate $x_j:U \rightarrow \real$. Of course, 
this is a slight abuse of notation, but this a standard convention in 
differental geometry.
Then we have 
\begin{align*}
    0 = \left( \sum\limits_{i=1}^n \lambda_i \frac{\partial}{\partial x_i}
        \right) (x_j)
    = \sum\limits_{i=1}^n \lambda_i \frac{\partial x_j}{\partial x_i}(\phi(p))
    = \lambda_j
\end{align*}
so $\frac{\partial}{\partial x_i}$ are
linearly independent and thus a basis of $T_p M$. 

Now that we introduced tangent spaces we will define the most important 
mapping between them.
\begin{definition}[Differential]
    Let $M, N$ be an $n$ and $m$ dimensional manifold respectively. 
    Take $p \in M$ and let $F:M \rightarrow N$ be differentiable at $p$. 
    Then we define the differential of $F$ at point $p$,
    \begin{align*}
        F_{*,p}: T_p M \rightarrow T_{F(p)} N, D_\gamma \mapsto D_{F\circ \gamma}.
    \end{align*}
\end{definition}

\begin{proposition}
    Let $\{x_i\}_{i=1}^m$ and $\{y_j\}_{j=1}^n$ be local coordinates at 
    $p$ and $F(p)$ and let $\frac{\partial}{\partial x_i}|_p$ and 
    $\frac{\partial}{\partial y_j}|_{F(p)}$ be the resulting bases for the 
    tangent spaces at $T_p M$ and $T_{F(p)} N$ respectively. Then 
    the resulting matrix representation of the differential 
    $F_{*,p}:T_p M \rightarrow 
    T_{F(p)}N$ is the Jacobian as defined above so
    \begin{align*}
        F_{*,p} \bigg( \frac{\partial}{\partial x_i}|_p \bigg)
        = \sum_{j=1}^m \frac{\partial F_j}{\partial x_i}(p)\,
            \frac{\partial}{\partial y_j}|_{F(p)}. 
    \end{align*}
\end{proposition}
\begin{proof}
    We will omitt the reference to the points of the partial derivatives.
    We choose $\gamma = \phi^{-1}(\phi(p) + e_i t)$. Then 
    $D_\gamma = \frac{\partial}{\partial x_i}$ and by applying the chain 
    rule and applying the above definitions, we compute
    \begin{align*}
        F_{*}(\frac{\partial}{\partial x_i})(f)
        &= D_{F\circ \gamma}(f)
        = \frac{d}{dt} (f(F \circ \gamma(t) ) )|_{t=0} 
        \\ &= \frac{d}{dt} (f \circ \psi^{-1} \circ \psi   
            \circ F \circ \phi^{-1} \circ \phi \circ \gamma(t)  )|_{t=0}
        \\ &= \sum_{j=1}^n \sum_{i=1}^m \frac{\partial f \circ \psi^{-1}}{\partial y_j}
            (\psi(F(p)))  \frac{\partial (\psi \circ F \circ \phi^{-1})_j}{\partial x_i}
            (\phi(p))  (x_i \circ \gamma)'(0)
        \\ &= \sum_{j=1}^n \frac{\partial F_j}{\partial x_i}(p) 
            \frac{\partial f}{\partial y_j}(F(p))
        = \left( \sum_{j=1}^n \frac{\partial F_j}{\partial x_i}(p) 
            \frac{\partial}{\partial y_j} \right) (f).
    \end{align*} 
\end{proof}

For everything we did above we fixed one certain chart $(U,\phi)$ at $p$.
Now the question arises what happens when we choose a different chart 
$(\tilde{U}, \tilde{\phi})$ instead.
Going through the same steps we end up with the basis 
$\{ \frac{\partial}{\partial y_j} \}_{j=1}^n$ 
which are the derivatives w.r.t. the chart 
$(\tilde{U}, \tilde{\phi})$. This is also a basis of the tangent space $T_p M$. 
Let us compute the change of basis.
Using the chain rule 
we can easily compute that 
\begin{align*}
    \frac{\partial (f \circ \phi^{-1})}{\partial x_i} (\phi(p))
    =\sum_{j=1}^n \frac{\partial (f \circ \tilde{\phi}^{-1})}{\partial y_j} (\tilde{\phi}(p))
        \frac{\partial (\tilde{\phi} \circ \phi^{-1})_j}{\partial x_i}(\phi(p)) 
\end{align*}
and we recognize that the change of basis matrix is the Jacobian of 
the chart transition $D(\psi \circ \phi^{-1})(\phi(p))$.

A \textit{vector field} $X$ maps every point $p$ to a tangent vector 
in the corresponding tangent space i.e. by using local coordinates
\begin{align*}
    X(p) = \sum_{i=1}^n X_i(p) \frac{\partial}{\partial x_i}
\end{align*}
with $X_i(p) \in \real$. The regularity of a vector field is defined via the
regularity of its coefficent e.g. a vector field is differentiable if 
all its coefficents are. We must be careful though since we require higher 
regularity of the manifold for this to be well-defined. 
Assume $X$ is differentiable i.e. $X_i$ are differentiable. 
Let $(\tilde{U}, \tilde{\phi})$ 
be another local chart.
From the 
change of basis of the tangent space we know that 
\begin{align*}
    X(p) = \sum_{i=1}^n X_i(p) \frac{\partial}{\partial x_i}
    = \sum_{i,j=1}^n X_i(p) \frac{\partial (\tilde{\phi} \circ \phi)_j}{\partial x_i}(\phi(p))
        \frac{\partial}{\partial y_j}
\end{align*}
and we see the coefficents w.r.t. to the new basis are 
$\tilde{X}_j = \sum_{i=1}^n X_i(p) \frac{\partial (\tilde{\phi} \circ \phi)_j}{\partial x_i}(\phi(p))$.
So we need $\frac{\partial (\tilde{\phi} \circ \phi)_j}{\partial x_i}$ to be 
differentiable as well which means that we want the manifold to be at least $C^2$.

We should briefly mention the question of orientation of the tangent spaces.
Recall that we partitioned the bases of a finite-dimensional real vector 
in two orientations. We say that two bases have the same 
orientation if the change of basis matrix has positive determinant.
We want to choose an orientation on the tangent spaces consistently which 
will be crucial when defining the volume form below.

Assume the manifold $M$ is orientable and we have chosen an oriented atlas.
For any tangent space $T_p$ with local coordinates $x_i$ near $p$, 
we define the resulting basis $\frac{\partial}{\partial x_i}$ as positively
oriented which fixes the orientation of the vector space. We have to show 
that this is well-defined. But this is clear since if we take a different 
chart at $p$ from the oriented atlas resulting in different local coordinates 
$\frac{\partial}{\partial y_j}$
we know that the change of 
basis is the Jacobian of the chart transition. But the Jacobian of the 
chart transition has positive determinant by definition and so the basis 
$\frac{\partial}{\partial y_j}$ is positively oriented as well.

\subsection{Differential forms}\label{sec:differential_forms}
Now that we introduced the necessary objects from differential geometry, 
we can finally define differential forms.
\begin{definition}[Differential forms]
    A differential $k$-form $\omega$ maps any point $p \in M$ to a 
    alternating $k$-linear form $\omega_p \in \alternating{k}{T_p M}$.
    We denote the space of differential $k$-forms on $M$ as $\Lambda^k M$.
\end{definition}

Let $T_p^* M$ be the dual space of $T_p M$ which is usually called 
\textit{cotangent space}.
As before let us choose a local chart $\phi: U \rightarrow \real^n$ with 
$p \in U$ and define $\frac{\partial}{\partial x_i}|_p$ as before. 
Denote the corresponding
dual basis as $dx^i$, $i = 1,...,n$ i.e. 
$dx^i(\frac{\partial}{\partial x_j}) = \delta_{ij}$. 
From the consideration about
alternating maps from section \ref{sec:alternating_maps} we can now write any 
$\omega \in \Lambda^k M$ with 
\begin{align*}
    \omega_p = \sum\limits_{1\leq i_1 < ... < i_k \leq n} 
        a_{i_1,...,i_k}(p) dx^{i_1} \wedge dx^{i_2} \wedge ... \wedge dx^{i_k}
\end{align*}
with $a_{i_1,...,i_k}(p) \in \real$. The regularity of differential forms 
is then defined via the regularity of these coefficents i.e. we call 
a differential form smooth if all the $a_{i_1,...,i_k}$ are smooth 
and we call a differential form differentiable if all the $a_{i_1,...,i_k}$
are differentiable and so on. These definition of regularity again require 
the manifold to be sufficiently regular as well.

We denote the space $C^\infty \Lambda^k M$ the 
space of smooth differential $k$-forms and analogous for other regularity.
$\smoothcompforms{k}{M}$ are the smooth differential forms
with compact support contained in $M$ i.e. 
$\supp \omega = \overline{\{ p \in M \mid \omega_p \neq 0  \}} 
\subseteq M \setminus \partial M$ where the closure is w.r.t. 
the topology on $M$.

In order to define the Hodge star and an inner product on differential forms
we need that 
$T_p M$ is an inner product space.
A Riemannian metric gives us at every point $p \in M$ 
a symmetric, positive definite bilinear form 
$g_p: T_p M \times T_p M \rightarrow \real$. 
\begin{definition}[Riemannian metric]
    A Riemannian metric $g$ maps every point $p\in M$ to 
    a symmetric, positive definite bilinear form $g_p: T_p \times T_p \rightarrow \real$.
    After choosing local coordinates $x_i$ we frequently denote 
    $g_{p,ij} = g_p(\frac{\partial}{\partial x_i}, \frac{\partial}{\partial x_j})$.
    We also require that for $C^\alpha$ vector fields $X$ and $Y$ the map 
    $g(X,Y)$ is also $C^\alpha$. 

    Manifolds on which a Riemannian metric can be defined are called 
    \textit{Riemannian manifolds}.
\end{definition}
From now on, we will leave out the reference to the point $p$ where appropriate.
The Riemannian metric provides us with the 
inner product on every tangent space $T_p M$. 
We will from now on assume that $M$ is an oriented Riemannian manifold of sufficient 
regularity and denote the Riemannian metric by $g$.
%TBD: Lipschitz
Let $p \in M$ and $T_p M$ be the tangent space at the point $p$. 
Due to our assumptions on $M$, this is an oriented inner product space of 
dimension $n$ and we can apply 
all of the constructions from the previous chapter. 
We will define the volume form, vector and scalar proxies and finally pullbacks
of differential forms.

Let us fix a point $p$ and a chart $\phi$ 
at this point with local coordinates denoted by $x_i$, $i=1,...,n$. 
First, we have to check that we choose a orientation on $T_p M$ as explained 
above.

The resulting gramian matrix is
$(G_p)_{ij} = g_p(\frac{\partial}{\partial x_i},\frac{\partial}{\partial x_j})$.
So we have a volume form vol on $M$ 
\begin{align*}
    \vol_p = \sqrt{\det G_p} dx^1 \wedge ... \wedge dx^n.
\end{align*}
The volume form then depends on the chosen orientation, but not on the 
chosen local coordinates.

% Let $\{(U_i,\phi_i)\}_{i=1}^\infty$ be an oriented atlas of $M$.
% For $p \in U_i$ we can define using local coordinates
% \begin{align*}
%     g_{kl}^{(i)}(p) \vcentcolon= g_p(\frac{\partial}{\partial x^{(i)}_k}\bigg|_p, 
%         \frac{\partial}{\partial x^{(i)}_l}\bigg|_p) 
% \end{align*}
% where we use the superscript $^{(i)}$ to mean the local coordinates for 
% chart $\phi_i$.
% Then we define the matrix $G^{(i)} \vcentcolon= 
% (g_{kl}^{(i)})_{k,l} \in \real^{n \times n}$ which is just the resulting Gramian 
% matrix. 
% Then we obtain the volume form 
% \begin{align*}
%     \text{vol}_p = \det G^{(i)} 
%     dx_{(i)}^1 \wedge dx_{(i)}^2 \wedge dx_{(i)}^n
% \end{align*}
% where $dx_{(i)}^k$ are the dual basis corresponding to 
% $\partial/\partial x^{(i)}_k$ the local coordinates 
% of chart $\phi_i$. 

% We know that this works if we choose any positively oriented basis. 
% Because our manifold is orientable and we chose a oriented atlas 
% $(U_i,\phi_i)$ we get that if we choose a different chart $(U_j,\phi_j)$ 
% then the 
% corresponding basis of the tangent space
% $\{ \partial / \partial x^{(j)}_k \}_k$ is also positively oriented because
% the change of basis matrix $D(\phi_j \circ \phi_i^{-1})(\phi(p))$ has positive
% determinant.

Now that we have a volume we can define the Hodge star operator
$\star: \Lambda^k(M) \rightarrow \Lambda^{n-k}(M)$ 
simply by applying it 
pointwise i.e. $(\star \omega)_p = \star \omega_p$. 
We follow the analogous idea to define the wedge product
$\wedge: \Lambda^k M \times \Lambda^l M \rightarrow \Lambda^{k+l} M$ via
\begin{align*}
    (\omega \wedge \nu )_p = \omega_p \wedge \nu_p. 
\end{align*} 

Recall from Prop.\,\ref{prop:properties_hodge_star} that we then have for $\omega, \nu \in \Lambda^k M$ and 
$\mu \in \Lambda^{n-k} M$
\begin{align*}
    g_p(\omega_p, \mu_p) &= \langle \star \omega_p, \mu_p \rangle _{\alternating{n-k}{T_p M}} \vol_p
    \\ \star \star \omega &= (-1)^{k(n-k)} \omega
    \\ \omega_p \wedge \star \nu_p &= \langle \omega_p, \nu_p \rangle _{\alternating{k}{T_p M}}.
\end{align*}
In order for 
the Hodge star to be well-defined the assumption of an orientation on our 
manifold is crucial. 

We want to apply two important concepts from the previous section about 
alternating maps -- vector proxies and pullbacks -- to differential forms.
The following is based on \cite[Ch.\,6]{arnold}, 
but many details have been
added and additional examples are given.
Recall, that for a real $n$-dimensional vector space $V$ we had two 
ways to identify a vector $v\in V$ with an alternating map. Either as a 
linear form $\Phi v$ where $\Phi$ is the Riesz isomorphism or as a 
$(n-1)$-linear alternating map $\star \Phi v$. 

A vector field $X$ maps every point $p \in M$ to a tangent vector 
$X(p) \in T_p M$. We can now identfy every vector field with a $1$-form or 
a $(n-1)$-form. $p \mapsto \Phi_{T_p M} X(p)$ defines a $1$-form and  
$p \mapsto \star \Phi_{T_p M} X(p)$ gives us a $(n-1)$-form. In differential 
geometry, the usual notation is
$\Phi_{T_p M} X(p) = X^\flat(p)$. The inverse of $^\flat$ is $^\sharp$ i.e. 
$X = (X^\flat)^\sharp$.
The isomorphisms $^\flat$ and $^\sharp$ 
are fittingly called \textit{musical isomorphisms}. 
With these musical isomorphisms we can identify $X$ with the $1$-form 
$X^\flat$ or the $(n-1)$-form $\star X^\flat$. Vice versa, we find 
for $\omega \in \Lambda^1 M$ the \textit{vector proxy} $\omega ^\sharp$ and for 
and $(n-1)$-form $\nu \in \Lambda^{n-1} M$ we get $(\star^{-1} \nu)^\sharp$.

Denote with $dx^i$, $i=1, ..., n$ the dual basis of 
$\frac{\partial}{\partial x_i}$.
If the basis of the tangent space $\frac{\partial}{\partial x_i}$ are 
orthonormal then we have $(\frac{\partial}{\partial x_i})^\flat = dx^i$ 
because the Riesz isomorphism maps basis elements to their dual basis elements
in this case.

Next, let us have a look at how we can extend pullbacks to differential forms.
Recall again, that a linear map $L: V \rightarrow W$ with an 
$n$-dimensional real vector space $V$ and an 
$m$-dimensional real vector space $W$ we define its pullback 
$L^*: \alternating{k}{W} \rightarrow \alternating{k}{V}$ via 
\begin{align*}
    L^*\omega (v_1, ..., v_k) = \omega (Lv_1, ..., L v_k).
\end{align*} 
We wish to do the analogous thing with differential forms. 

\begin{definition}
    For $\omega \in \Lambda^k N$ and a differentiable map $F:M \rightarrow N$ 
    we define the pullback $F^*\omega$ as
    \begin{align*}
        (F^*\omega)_p = (F_{*,p})^* \omega_{F(p)}
    \end{align*}
    or written differently for all $v_1,...,v_k \in T_p M$
    \begin{align*}
        (F^*\omega)_p (v_1,...,v_k) = \omega_{F(p)}(F_{*,p} v_1, ..., F_{*,p} v_k).
    \end{align*}
\end{definition}
Now we can use the vector proxies and connect it to what we have done 
for alternating maps above. 

\begin{proposition}
    So let $X$ be a vector field on $N$. Take $p \in M$ and local coordinates
    $x_i$ at $p$ and $y_j$ at $F(p)$. We assume that the bases
    $\{ \frac{\partial}{\partial x_i} \}_{i=1}^n$ and 
    $\{ \frac{\partial}{\partial y_j} \}_{j=1}^m$ of $T_p M$ and $T_{F(p)} N$ 
    are orthonormal w.r.t. the Riemannian metrics
    on $M$ and $N$ respectively. 
    Then we can write $X = \sum_{j=1}^m X_i \frac{\partial}{\partial x_i}$
    and denote $\mathbf{X} = (X_1,..., X_n)^\top$.
    Then we obtain for the pullback in terms of
    vector proxies of $1$-forms
    \begin{align*}
        (F^* X^\flat)^\sharp 
        = \sum_{j=1}^n (DF(p)^\top \mathbf{X})_j \frac{\partial}{\partial y_j}.
    \end{align*}

    If we assume $m=n$ additionally, then 
    \begin{align*}
        (\star^{-1} F^* \star X^\flat)^\sharp 
        = \sum_{j=1}^n (\text{ad}(DF(p)) \mathbf{X})_j \frac{\partial}{\partial y_j}
    \end{align*}
    where $\text{ad}(DF(p))$ is the adjugate matrix of $DF(p)$.
\end{proposition}
\begin{proof}
    The resulting follows essentially immediately from applying the 
    corresponding results for alternating maps. Using the definition of 
    the $^\flat$ and $^\sharp$
    \begin{align*}
        (F^* X^\flat)^\sharp(p)
        = \Phi^{-1}_{T_p M} F_{*,p}^* \Phi_{T_{F(p)}N} X(p)
        = \sum_{j=1}^n (DF(p)^\top \mathbf{X})_j \frac{\partial}{\partial y_j}
    \end{align*}
    where we used in the last step the matrix representation of vector proxies 
    of $1$-linear forms from (\ref{eq:pullback_linear_forms}). The analogous reasoning works 
    for vector proxies of $(n-1)$-forms i.e. the second claim.
\end{proof}

Let $\hat{\Omega} = M$ and $\Omega = N$ be domains of $\real^n$ and assume 
$F$ is a diffeomorphism. Then we 
can identify a vector field $\sum_{i=1}^m X_i \frac{\partial}{\partial x_i}$
with $\mathbf{X} = (X_1,...,X_n)^\top$. We then can interpret $\mathbf{X}$ 
either as a vector proxy of a $1$- or $(n-1)$-form and obtain the pullbacks
\begin{align*}
    \mathcal{P}^1_F \mathbf{X}(\hat{x}) &\vcentcolon= DF(\hat{x}) \mathbf{X}(F(\hat{x})) \text{ and}
    \\ \mathcal{P}^{n-1}_F \mathbf{X}(\hat{x}) &\vcentcolon= (\det DF(\hat{x}))\,
        DF(\hat{x})^{-1} \mathbf{X}(F(\hat{x}))
\end{align*}
where we used the fact that $F$ is a diffeomorphism hence its Jacobian 
is invertible and then $\text{ad}(DF(\hat{x})) = (\det DF(\hat{x}))\,
(\hat{x})^{-1} \mathbf{X}(F(\hat{x}))$.
This is widely known as the Piola transformation \cite[Def.\,9.8]{ern_guermond}.

Now let us move on to scalar proxies. So let $\rho: N \rightarrow \real$ be 
just a scalar field i.e. a $0$-form. In this case, we 
have the simple expression for the pullback $F^* \rho = \rho \circ F$. 

But $\rho$ could also be the scalar proxy of the $n$-form 
$\star \rho = \rho \vol_N$ (we assume once again 
as above
$n=m$ and that our basis of the tangent spaces are orthonormal w.r.t. the 
Riemannian metric). Then in scalar proxies we obtain the pullback
\begin{align*}
    (\mathcal{P}_F^n \rho )(p) 
    &= (\star ^{-1}F^* \star \rho)_p
    = \star ^{-1} (F^* \star \rho)_p
    = \star ^{-1} (F_{*,p})^* (\star \rho)_{F(p)}
    \\ &= \star ^{-1} (F_{*,p})^* \rho(F(p)) dy^1 \wedge ... \wedge dy^n
    \\ &= \star ^{-1} \rho(F(p)) \det DF(p) \, dx^1 \wedge ... \wedge dx^n
    \\ &=  (\rho \circ F) (\det DF) \star^{-1}\vol_M
    = (\rho \circ F)(p) \det DF(p).
\end{align*}
This is strikingly similar to the integrand in the standard transformation 
of integrals formula which will become crucial in the next section
where we talk about the
integration of differential forms. The next part of this section will be 
concerned with introducing a derivative for differential forms

\begin{definition}[Exterior derivative]
    Let $\omega \in C^1\Lambda^k (M)$ be given in local coordinates as
    \begin{align*}
        \omega_p = \sum\limits_{1\leq i_1 < ... < i_k \leq n} 
            a_{i_1,...,i_k}(p) dx^{i_1} \wedge dx^{i_2} \wedge ... \wedge dx^{i_k}
    \end{align*}
    Then we define the exterior derivative $d: \Lambda^{k}(M) \rightarrow 
    \Lambda^{k+1}(M)$. By
    \begin{align*}
        (d\omega)_p = \sum\limits_{1\leq i_1 < ... < i_k \leq n} \sum\limits_{i=1}^n
        \frac{\partial a_{i_1,...,i_k}}{\partial x_i}(p) 
        dx^i \wedge dx^{i_1} \wedge dx^{i_2} \wedge ... \wedge dx^{i_k}
    \end{align*}
    We remind of that the derivative of $a_{i_1,...,i_k}$ is meant w.r.t. 
    to local coordinates as defined at (\ref{eq:derivative_on_manifold}).
\end{definition}
It can be shown that $d\omega$ is independent of the chosen coordinates. 
Let us mention some important properties of the exterior derivative. 
At first, we have $d\circ d = 0$ which will be important later on 
when we talk about cochain complexes in Section \ref{}. 

The relation to the wedge product is described by a Leibniz-type formula. 
Let $\omega \in C^1 \Lambda^k M$ and $\nu \in C^1 \Lambda^l M$. Then
\begin{align}
    d (\omega \wedge \nu) = d\omega \wedge \nu + (-1)^l \omega \wedge d\nu.
    \label{eq:leibniz_formula}
\end{align}

The exterior derivative commutes with pullback i.e. 
for manifolds $M$ and $N$ a differentiable mapping $F:M \rightarrow N$ 
and $\omega \in \Lambda^k N$ we have $dF^* \omega = F^* d\omega$. 
In terms of proxies this is related to very interesting results as we will 
see later. 


Let us investigate the exterior derivative in the case when 
$M = \Omega \subseteq \real^n$ is an open subdomain. It turns out that by using 
scalar and vector proxies as introduced above we can identify the exterior 
derivative with well-known differential operators. We will use standard 
Euclidian coordinates meaning that our tangent basis $\frac{\partial}{\partial x_i}$
is orthonormal. 

Let us start with a differentiable function $f: \Omega \rightarrow \real$ i.e. 
$f$ is a $0$-form. Then
\begin{align*}
    (df)^\sharp = \left( \sum_{i=1}^n \frac{\partial f}{\partial x_i} dx^i 
        \right)^\sharp
    = \sum_{i=1}^n \frac{\partial f}{\partial x_i} \frac{\partial}{\partial x_i}
\end{align*}
which we identify with the gradient $\nabla f$. In other words, 
the exterior derivative is just the gradient in vector proxies.

Let $\mathbf{X}$ be a differentiable vector field on $\Omega$ 
with components $X_i$. This corresponds to the vector field 
$X = \sum_i X_i \frac{\partial}{\partial x_i}$. Let us view
$X$ as the vector proxy 
of an $(n-1)$-form. Then 
\begin{align*}
    \star^{-1} d\star X^\flat &= \star^{-1} d\star \sum_{i=1}^n X_i dx^i
    = \star^{-1} d \sum_{i=1}^n X_i (-1)^{i-1} 
        dx^1 \wedge ... \wedge \widehat{dx^i} 
        \wedge ... 
        \wedge dx^n
    \\ &= \star^{-1} \sum_{i=1}^n \frac{\partial X_i}{\partial x_i} (-1)^{i-1} 
        dx^i \wedge 
        dx^1 \wedge ... \wedge \widehat{dx^i} \wedge ... \wedge dx^n
    \\ &= \star^{-1} \sum_{i=1}^n \frac{\partial X_i}{\partial x_i} 
        (-1)^{2(i-1)} \vol
    = \sum_{i=1}^n \frac{\partial X_i}{\partial x_i}
    = \diver \mathbf{X}.
\end{align*}
The hat symbol used for
$\widehat{dx^i}$ means that this term is left out. 

In the case $n=3$ if we identify $\mathbf{X}$ with a $1$-form then 
we obtain using similiar computations
that $(\star d X^\flat)^\sharp$ corresponds to  $\mathbf{\curl} \,\mathbf{X}$.
So in $3$D we can identify all the exterior derivatives with known differential
operators and thereby putting them into a more general framework.

A very nice conclusion can be seen directly from the above computations. The 
expressions on the left hand side does not use any coordinates. Hence, 
we can use any coordinate system we want and can then compute e.g. the 
divergence in any coordinates we need. Note however that the computations are
more cumbersome when the bases are not orthonormal.

Let us give an application of this fact. This example is not taken from the 
references. We will derive the divergence for arbitrary coordinates. 
So let $\mathbf{X}: \Omega \rightarrow \real^n$ be a differentiable vector field. By 
identifying this with the vector field $\sum_i X_i \frac{\partial}{\partial x_i}
$ we computed above that 
\begin{align*}
    \diver \mathbf{X} \vol = d \star X^\flat.
\end{align*}
Now let us express $\mathbf{X}$ using different coordinates. 
Let $\phi: \Omega \rightarrow \hat{\Omega}$ be a diffeomorphism. 
This defines our local coordinates. Then the expression of $\mathbf{X}$ is
these curvilinear coordinates is
\begin{align*}
    \mathbf{X} = \sum_{j=1}^n \tilde{X}_j 
        \frac{\partial \phi^{-1}}{\partial y_j}.
\end{align*}
In terms of differential geometry, this corresponds to the representation of the vector field 
$X = \sum_j \tilde{X}_j \frac{\partial}{\partial y_j}$. 
Let $\tilde{\mathbf{X}} = (\tilde{X}_1, \tilde{X}_2, ..., \tilde{X}_n)^\top$ 
and 
\begin{align*}
    G_{kl} = g(\frac{\partial}{\partial y_k}, \frac{\partial}{\partial y_l})
        = \frac{\partial \phi^{-1}}{\partial y_k} \cdot 
            \frac{\partial \phi^{-1}}{\partial y_l}
\end{align*}
Then we compute use the expression of the Hodge star operator 
for one forms (\ref{eq:hodge_star_one_forms}) to compute
\begin{align*}
    (\diver \mathbf{X}) \vol 
    &= d \star X^\flat 
    = d \star \sum_{j=1}^n (G \tilde{\mathbf{X}})_j dy^j 
    \\ &= d \sum_{j=1}^n \sum_{k=1}^n (G \tilde{X})_j 
        \sqrt{ \det G} g^{jk} (-1)^{k-1} dy^1 \wedge dy^2 \wedge ... \wedge 
        \widehat{dy^k} \wedge ... \wedge dy^n 
    \\ &= \sum_{k=1}^n \frac{\partial
        (\sqrt{ \det G} \sum_{j=1}^n g^{jk} (G \tilde{X})_j )}
        {\partial y_k} (-1)^{k-1} dy^k \wedge dy^1 \wedge dy^2 \wedge ... \wedge 
        \widehat{dy^k} \wedge ... \wedge dy^n 
    \\ &= \sum_{k=1}^n \frac{\partial (\sqrt{ \det G}  \tilde{\mathbf{X}})_k }
        {\partial y_k} (-1)^{2(k-1)} dy^1 \wedge dy^2 \wedge ... \wedge 
        dy^k \wedge ... \wedge dy^n
    \\ &= \left[ \frac{1}{\sqrt{ \det G}} \sum_{k=1}^n 
        \frac{\partial (\sqrt{ \det G}  \tilde{\mathbf{X}})_k }{\partial y_k}
        \right] \vol
\end{align*}
and we find the well-known expression for the divergence in general coordinates
\begin{align*}
    \diver \mathbf{X} = \frac{1}{\sqrt{ |\det G|}} \sum_{k=1}^n 
        \frac{\partial (\sqrt{ |\det G|} \, \tilde{X}_k )}{\partial y_k}.
\end{align*}
% TBD: Some stuff I used here was not introduced before

As mentioned above let us investigate the consequences of the 
commutativity of the exterior derivative and the pullback in terms 
of vector and scalar proxies.
Let $F: \widehat{\Omega} \rightarrow \Omega$ be a diffeomorphism with 
$\widehat{\Omega}, \Omega \in \real^n$. Let us again consider Euclidian 
coordinates on the domain and codomain. Then observe
\begin{align*}
    & (\diver \mathbf{X})(F(\hat{x}))  \det DF(\hat{x}) \widehat{\vol}_{\hat{x}} 
    = ( F^* (\diver \mathbf{X}))_{\hat{x}} \wedge (F^* \vol)_{\hat{x}}
    \\ &= \left( F^* \big( \diver \mathbf{X} \wedge \vol \big) \right)_{\hat{x}}
    =  \left( F^* \big( \diver \mathbf{X} \vol \big) \right)_{\hat{x}}
    \\ &= \left( F^* d \star X^\flat  \right)_{\hat{x}}
    = \left( d F^* \star X^\flat  \right)_{\hat{x}}.
\end{align*}
and then 
\begin{align*}
    d F^* \star X^\flat = d \star \star^{-1} F^* \star X\flat 
    = d \star \hat{X}^\flat = \widehat{\diver} \mathbf{\widehat{X}}
\end{align*}
by defining 
\begin{align*}
    ( \star^{-1} F^* \star X^\flat)^\sharp 
    =\vcentcolon \hat{X} = \sum_i \mathbf{\hat{X}}_i(\hat{x})  
     \frac{\partial}{\partial \hat{x_i}}
\end{align*}
which we identify with the vector field
\begin{align*}
    \mathbf{\widehat{X}}(\hat{x}) 
    = (\widehat{X}_1(\hat{x}), \widehat{X}_2(\hat{x})
        , ..., \widehat{X}_n(\hat{x}) )^\top
\end{align*}
We then know from Sec.\,\ref{sec:alternating_maps} and because we assume
that we use orthonormal coordinates that 
\begin{align*}
    \hat{X}(\hat{x}) 
    &= ( \star^{-1} F^* \star X\flat)^\sharp (\hat{x})
    = \sum_{i,j=1}^n \text{ad}(DF(\hat{x}))_{ij} X_j(F(x)) 
        \frac{\partial}{\partial \hat{x}_i}
    \\ &= \sum_{i,j=1}^n \det DF(\hat{x}) \big( DF(\hat{x})^{-1}\big)_{ij} X_j(F(x)) 
        \frac{\partial}{\partial \hat{x}_i}
\end{align*}
and so we identify this with the vector field
\begin{align*}
    \mathbf{\widehat{X}} = \det DF(\hat{x}) DF(\hat {x})^{-1} \mathbf{X}.
\end{align*}
To summarize the situation in 3D,
\begin{proposition}
    Let $F: \hat{\Omega} \rightarrow \Omega$ be a diffeomorphism, 
    $\rho \in C^1(\Omega)$ and $\mathbf{X} \in C^1(\Omega, \real^3)$.
    In scalar and vector proxies for 3D, we obtain the following expressions for 
    pullbacks
    \begin{align*}
        (\mathcal{P}^0_F \rho)(\hat{x}) &= \rho(F(\hat{x}))
        \\ (\mathcal{P}^1_F \mathbf{X})(\hat{x}) &= DF(\hat{x})^\top \mathbf{X}(F(\hat{x}))
        \\ (\mathcal{P}^2_F \mathbf{X})(\hat{x}) &= \det DF(\hat{x}) DF(\hat{x})^{-1} \mathbf{X}(F(\hat{x}))
        \\ (\mathcal{P}^3_F \rho)(\hat{x}) &= \det DF(\hat{x}) \rho(F(\hat{x}))
    \end{align*}
    and then the commuting properties
    \begin{align*}
        \widehat{\grad} \mathcal{P}^0_F \rho &= \mathcal{P}^1_F (\grad \rho)
        \\ \widehat{\mathbf{\curl}} \mathcal{P}^1_F \mathbf{X} &= \mathcal{P}^2_F (\curl \mathbf{X})
        \\ \widehat{\diver} \mathcal{P}^2_F \mathbf{X} &= \mathcal{P}^3_F (\diver \mathbf{X}).
    \end{align*}
\end{proposition}
We proved the last statement and the other two can be proven analogously. 
These commuting properties are useful for applications in finite elements
(see e.g. \cite[Sec.\,14.3]{ern_guermond}).

% If the manifold is oriented and we have thus a Hodge star operator.
% Then we define the \textit{codifferential operator}
% $\delta \vcentcolon= (-1)^{n(k-1)+1} \star d \star$ which is then 
% an operator $\Lambda^{k}(M) \rightarrow 
% \Lambda^{k-1}(M)$.


% The exterior derivative and the codifferential both require the differential 
% form to be differentiable. Later we will extend this in weak sense so 
% classical differentiabilty is no longer required (see \ref{}).


\subsection{Integration of differential forms}

% In order to rigorously define Sobolev spaces we have to define $L^p$-spaces 
% of differential forms first. But before we can do that we should have a look
% how integration of a function can be defined on a smooth orientable 
% Riemannian manifold $M$. 

Throughout this chapter we assume that $M$ is an orientable Riemannian 
manifold of dimension $n$. We assume that we have chosen a 
countable atlas $\{ (U_i, \phi_i) \}_{i=1}^N$ with $N \leq \infty$. 
Before we can talk about integration of differential forms let us first 
investigate the integration of functions on a manifold.

\subsubsection{Integration of functions on a manifold}

We want to define integration in the framework of usual measure and integration
theory which means defining it as a Lebesgue integral w.r.t. a measure on $M$
which we have to define first along with a $\sigma$-algebra on $M$. 

It is well known that
the borel $\sigma$-algebra $\mathcal{B}$ on $\real^n$ is generated
by all open sets. This idea can be applied to any topological space $X$ by 
defining the borel $\sigma$-algebra $\mathcal{B}(X)$ as the $\sigma$-algebra 
generated by all open sets as well. So we can simply use the topology on $M$ to define 
our $\sigma$-algebra $\mathcal{B}(M)$. Because we know that all our 
charts $\phi_i: U_i \rightarrow \real^n$ are homeomorphisms it is very 
straightforward to show that a set $E \in \mathcal{B}(M)$ i.i.f.
$\phi_i(E \cap U_i) \subseteq \real^n$ is Borel-measurable. 

Now, we need to define a measure on the manifold. 
The following motivation is taken from \cite[3.H.2]{gallot_hulin_lafontaine}.
In Euclidian space $\real^n$ we use the standard Lebesgue measure that gives 
vvolume one to the unit cube. If we now take any vectors $v_1, v_2, ..., v_n 
\in \real^n$ then the parallelepiped spanned by these vectors has 
volume $\det (v_1 \mid v_2 \mid \dots \mid v_n) 
= \sqrt{ \det \big( \langle v_i , v_j \rangle \big)_{1\leq i,j \leq n} }$ where 
we used the standard inner product on $\real^n$. 

If we now extend this idea to Riemannian manifolds then we are interested 
in the parallelepiped spanned by the tangent vectors $\frac{\partial}{\partial x_i}$
in the tangent space $T_p M$ with $p \in M$.
which would then be $ \sqrt{\det \big( g_p(\frac{\partial}{\partial x_i}, 
\frac{\partial}{\partial x_j}) \big)_{1\leq i,j \leq n} } = 
\sqrt{ \det G_p }$. Then we define for $E \subseteq U$ where $U$ is 
the domain a chart $\phi: U \rightarrow \real^n$ the measure 
\begin{align*}
    V(E) \vcentcolon= \int_{\phi(E)} \sqrt{ \det G_{\phi^{-1}(x)}} dx 
\end{align*} 
which we will now extend globally to the whole manifold. 
Let $\{ \chi_i \}_{i=1}^N$, $N \leq \infty$, be the partition of unity 
subordinate to the open cover given by the atlas $\{U_i\}_{i = 0}^N$ . Then we define the 
\textit{Riemannian measure} for any $E \in \mathcal{B}(M)$
\begin{align*}
    V(E) \vcentcolon= \sum\limits_{i=1}^\infty \int_{\phi_i(U_i \cap E)}
        \chi_i(\phi_i^{-1}(x)) \sqrt{\det G^{(i)}(\phi_i^{-1}(x))} dx 
        \in [0,\infty]
\end{align*}
It can be shown that it is independent of the chosen oriented atlas 
using the transformation behaviour of $G^{(i)}$. But the orientation is 
crucial for it to be well-defined. 

\begin{proposition}
    The Riemannian measure is independent of the chosen partition of unity and atlas if it is 
    oriented the same.
\end{proposition}
\begin{proof}
    Let $\{(V_j, \psi_j)\}_{j=0}^\infty$ 
    be a different atlas with the same orientation and 
    $\{\rho_j\}_{j=0}^\infty$ be the partition of unity subordinate to it.
    \begin{align}
        &\sum_{j=0}^\infty \int_{\psi_j(E\cap V_j)} \rho_j(\psi_j^{-1}(y))
            \sqrt{\det G^{(j)}_{\psi^{-1}(y)}} \, dy \nonumber
        \\ &= \sum_{i,j=0}^\infty \int_{\psi_j(E\cap V_j \cap U_i)} \chi_i(\psi_j^{-1}(y)) \rho_j(\psi_j^{-1}(y))
            \sqrt{\det G^{(j)}_{\psi_j^{-1}(y)}} \, dy \nonumber
        \\ &= \sum_{i,j=0}^\infty \int_{\phi_i(E\cap V_j \cap U_i)} \chi_i(\phi_i^{-1}(x)) \rho_j(\phi_i^{-1}(x))
            \sqrt{\det G^{(j)}_{\phi_i^{-1}(x)}} \, \det D(\psi_j \circ \phi^{-1}_i)(\phi_i(x)) \, dx \label{eq:double_sum_riemannian_measure}
    \end{align}
    where we used the fact that the $\chi_i$ sum up to one for the first 
    equality and a simple tranformation of integral in the second equality
    using the chart transition $\phi_i^{-1}\circ \psi_j$. Since all summands 
    are non-negative we can change the order of summation as we like. Then using the 
    change of basis for the tangent space derived in Sec.\,\ref{sec:differential_geometry}
    we get for $p \in U_i \cap V_j$
    \begin{align*}
        (G^{(j)}_p)_{kl} &= g_p(\frac{\partial}{\partial y_k}, \frac{\partial}{\partial y_l})
        \\ &= \sum_{r,s=0}^n \frac{\partial(\phi_i \circ \psi_j^{-1})_r}{\partial y_k}(\psi(p))
            \, \frac{\partial(\phi_i \circ \psi_j^{-1})_s}{\partial y_k}(\psi(p))
            \, g_p(\frac{\partial}{\partial x_r}, \frac{\partial}{\partial x_s})
        \\ &= \bigg( D(\phi_i \circ \psi_j^{-1})(\psi(p))^\top G^{(i)}_p D(\phi_i \circ \psi_j^{-1})(\psi(p))\bigg)_{kl}
    \end{align*}
    and thus 
    \begin{align*}
        \det G^{(j)}_{\phi^{-1}(x)} 
        &= \det G^{(i)}_{\phi_i^{-1}(x)} \,
            \bigg(\det D\big(\phi_i \circ \psi_j^{-1}\big)\big(\psi(\phi^{-1}(x))\big)\bigg)^2
        \\ &= \det G^{(i)}_{\phi_i^{-1}(x)} \,
            \left( \det D(\psi_j \circ \phi_i^{-1})(x)^{-1}\right)^2.
    \end{align*}
    Plugging this into (\ref{eq:double_sum_riemannian_measure}) the determinant 
    of the chart transition cancels out because $\det D(\psi_j \circ \phi_i^{-1})(x)^{-1} > 0$.
    We can integrate over $\phi_i(E \cap U_i)$ 
    instead of $\phi_i(E \cap V_j \cap U_i)$ without changing the integral 
    because $\supp \rho_j \subseteq V_j$.
    \begin{align*}
        &\sum_{i=0}^\infty \int_{\phi_i(E \cap U_i)} \chi_i(\phi_i^{-1}(x))\sum_{j=0}^\infty \rho_j(\phi_i^{-1}(x))
            \sqrt{\det G^{(i)}_{\phi_i^{-1}(x)}} \, dx
        \\ &= \sum_{i=0}^\infty \int_{\phi_i(E \cap U_i)} \chi_i(\phi_i^{-1}(x))
            \sum_{j=0}^\infty \rho_j(\phi_i^{-1}(x)) \sqrt{\det G^{(i)}_{\phi_i^{-1}(x)}} \, dx
        \\ &= V(E).
    \end{align*}
\end{proof}


Now that we have the measure space $(M, \, \mathcal{B}(M), \, V)$
we can define integration in the usual Lebesgue way.
It is easily shown that a function $f: M \rightarrow \real$ is measurable 
i.i.f. $f \circ \phi_i^{-1}$ is measurable for every chart $\phi_i$. 
It is then simply an application of the definition of Lebesgue integration to
show that for any measurable $f \geq 0$ we can express the integration as
\begin{align*}
    \int_M f \, dV = \sum\limits_{i=1}^\infty \int_{\phi_i(U_i)} 
        \chi_i(\phi_i^{-1}(x)) f(\phi_i^{-1}(x)) 
        \sqrt{\det G^{(i)}(\phi_i^{-1}(x))} dx.
\end{align*}
By introducing the integral as a Lebesgue integral w.r.t. the Riemannian 
measure we inherit the theoretical framework of Lebesgue integration. 
For example, we know that the the spaces $L^p(M,V)$ for $1\leq p < \infty$
, i.e. the $p$-integrable 
real-valued functions w.r.t. the Riemannian measure, are Banach spaces.

\subsubsection{Integration of differential forms}\label{sec:integration_differential_forms}

Once again, we should first ask ourselfs what a measurable differential form 
should be. We know that we can express our differential form locally 
for $p \in U_i$ using the local coordinates as 
\begin{align*}
    \omega_p = \sum\limits_{1\leq i_1 < ... < i_k \leq n} 
        a_{i_1,...,i_k}(p) dx^{i_1} \wedge dx^{i_2} \wedge ... \wedge dx^{i_k}.
\end{align*}
In the spirit of the the definition of differentiability 
in Sec.\,\ref{} we call a $\omega \in \Lambda^k (M)$
measurable if for every chart $\phi_i$ the coefficent functions of the 
differential form expressed in local coordinates 
are measurable. This notion is once again independent of the chosen 
coordinates.

Next, we will define integration of an $n$-form over an $n$ dimensional 
manifold. At first, we do so for an open set $U \subseteq \real^n$.
This is the simplest example of an $n$-dimensional manifold where 
we only have one chart which is the identify and the local coordinates are 
just our standard coordinates which we denote by $z_i$, $i=1,...,n$ and the 
resulting basis of the tangent space $\frac{\partial}{\partial z_i}$. 
Let $\omega$ be a measurable 
$n$-form on $U$ so we can 
write 
\begin{align*}
    \omega_z = f(z)\, dz_1 \wedge dz_2 \wedge ... \wedge dz_n
\end{align*}
for $z \in U$ with $f:U \rightarrow \real$ being Borel-measurable. 
We can now simply define 
\begin{align*}
    \int_U \omega = \int_U f(z) \, dz_1 dz_2 ... dz_n.
\end{align*}

With this definition at hand we can now extend this definition to 
the manifold $M$. As it is often done in 
differential geometry we will work locally first and then extend this 
construction globally by using a partition of unity.

Let $(U,\phi)$ be a chart on $M$ and assume $\supp \omega \subseteq U$. 
Then $(\phi^{-1})^* \omega$
is a $n$-form on $\phi(U) \subseteq \real^n$ and 
we can apply our prior definition. So now we just define 
\begin{align*}
    \int_M \omega \vcentcolon= \int_{\phi(U)} (\phi^{-1})^* \omega.
\end{align*}
% Once again, it can be shown that this definition does not depend on the chart if 
% we choose it from the atlas corresponding to the orientation of the manifold. 

Now let us move on to the global definition. Let $\{(U_i,\phi_i)\}_{i=1}^\infty$
be an oriented atlas and let $\{ \chi_i \}_{i=1}^\infty$ be a partition 
of unity subordinate to it. 
Then $\supp \chi_i \omega \subseteq U_i$ 
and we define 
\begin{align*}
    \int_M \omega \vcentcolon= \sum_{i=1}^\infty \int_M \chi_i \omega.
\end{align*} 
% This definition is also independent of the chosen chart and partition of 
% unity. We will omit the proof. 

We will now have a look how the integration of functions and of 
differential forms are related to each other. 
For the chart $(\phi_i, U_i)$ we denote the local coordinates as 
$x^{(i)}_k$, $k=1,...,n$ and the basis of $1$-forms as $dx_{(i)}^k$.
We know that for $p \in U_i$ we can write the volume form as
\begin{align*}
    \vol_p = \sqrt{ \det G^{(i)}(p)} \,
        dx_{(i)}^1 \wedge dx_{(i)}^2 \wedge ... \wedge dx_{(i)}^n.
\end{align*}
where $G^(i)_{kl} = g(\frac{\partial}{\partial x^{(i)}_k},\frac{\partial}{\partial x^{(i)}_l} )$.

Because $(\phi_i^{-1})^* dx_{(i)}^k = dz^k$ -- which follows directly from the 
definition -- and the pullback commutes with the wedge product we have
\begin{align*}
    \big( (\phi_i^{-1})^* \vol)_z =  
        \sqrt{ \det G^{(i)}(\phi_i^{-1}(z))} \,
        dz^1 \wedge dz^2 \wedge ... \wedge dz^n.
\end{align*}
That means for a $n$-form $f \vol$ we can write the integral as
\begin{align*}
    \int_M f \vol = \sum_{i=1}^\infty \int_{\phi_i(U_i)} 
    \chi_i(\phi_i^{-1}(z)) f(\phi_i^{-1}(z))
        \sqrt{ \det G^{(i)}(\phi_i^{-1}(z))} dz^1 dz^2 ... dz^n
\end{align*} 
and we see 
\begin{align*}
    \int_M f dV = \int_M f \vol
\end{align*}
with the two different notions of integration. This also proves that 
the integral of differential $n$-forms is independent of the chosen 
coordinates as long as the orientation is respected. So we see that the
the two definitions are essentially equivalent.
The big advantage of considering these two
approaches is that we know the integration of 
differential forms is within the framework of Lebesgue integration. 
It is then also 
clear how integrability for $n$-forms should be defined. We call an 
$n$-form $f \vol$ integrable if $f$ is integrable w.r.t. the Riemannian measure.

\subsubsection{Stokes' theorem and integration by parts} 

One of the most important results about the integration of differential forms
is Stokes' theorem which we will state in this section. From it, we will 
obtain a integration by parts formula.

But before we do so we have to check how to define the restriction of a
differential form to a submanifold $N \subseteq M$. 
We do that with the inclusion $\iota: N \hookrightarrow M$. Then for a 
smooth differential form $\omega \in C^\infty \Lambda^k (M)$ we define 
the restriction just via the pullback of the inclusion operator i.e. 
$\iota^* \omega \in C^\infty \Lambda^k(N)$. 

For a $k$-dimensional submanifold $N$ we then denote the integration of an 
$k$-form $\omega$ as
\begin{align*}
    \int_N \iota^*\omega =\vcentcolon \int_N \omega.
\end{align*} 

\begin{example}
    Let us investigate the integral of a $1$-form over a curve. 
    Let $\gamma: (0,1) \rightarrow \Omega$ be a smooth curve in the domain $\Omega 
    \subseteq \real^n$. Denote $\Gamma = \gamma((0,1))$ and assume that 
    $\gamma' \neq 0$ and $\gamma: (0,1) \rightarrow \Gamma$ is bijective.
    That means especially that $\Gamma$ does not intersect itself.
    Then $\Gamma$ is a manifold with boundary and the chart is $\gamma^{-1}$.
    Then let us calculate the Jacobian of the inclusion $\iota$ using the 
    definition from (\ref{eq:derivative_on_manifold}). 
    Since it is the most convenient, we take the 
    identity as chart on $\Omega$. Take $\gamma(t) \in \Gamma$. Then
    \begin{align*}
        D\iota(p)_{i,1} = D(\Id \circ \iota \circ \gamma)_{i,1}(t)
        = \frac{\partial \gamma_i}{\partial t}(t)
        = \gamma'(t).
    \end{align*} 
    This is then the matrix representation of the differential $\iota_*$ at 
    $\gamma(t)$.
    Now take a at least continuous $1$-form $\omega = \sum_{i=1}^n \omega_i dz^i$ 
    on $\Omega$. Then we know from the matrix representation of the 
    pullback derived in Sec.\,\ref{sec:differential_forms} that 
    \begin{align*}
        \iota^*\omega (t) = \sum_{i=1}^n \gamma'_i(t) \, \omega_i(\gamma(t)) \,dt
    \end{align*}
    and so
    \begin{align*}
        \int_\Gamma \omega = \int_0^1\sum_{i=1}^n \gamma'_i(t) \, \omega_i(\gamma(t)) \,dt.
    \end{align*}
    Let us now look at this in terms of vector proxies. Take a vector field 
    $X = \sum_{i=1}^n X_i \frac{\partial}{\partial z_i}$ on $\Omega$.
    Because we are using Euclidian coordinates we get
    \begin{align*}
        X^\flat = \sum_{i=1}^n X_i dz^i
    \end{align*}
    and thus by denoting $\mathbf{X} = (X_1, X_2, ..., X_n)$ we get
    \begin{align*}
        \int_\Gamma X^\flat = \int_\Gamma \mathbf{X}\cdot dl
    \end{align*}
    where the right hand side is the notation for the standard curve integral 
    in $\real^n$. So we can conclude that, interpreted in vector proxies for 
    a domain of $\real^n$, the integral of a $1$-form corresponds to the usual 
    curve integral.
\end{example}

\begin{theorem}[Stokes]
    Let $M$ be a smooth oriented manifold with boundary 
    $\partial M$. Let $\omega$ be 
    a smooth compactly supported $(n-1)$-form. Then we have 
    \begin{align*}
        \int_M d\omega = \int_{\partial M} \omega.
    \end{align*}
\end{theorem}
This theorem gives us a relation of the boundary and the exterior derivative 
which will be crucial in the topological context of differential forms 
which we will investigate in Sec.\,\ref{sec:de_rhams_theorem}. 

We can also derive a form of the integration by parts formula from it. 
Let $\omega \in C_0^1 \Lambda^k (M)$ and $\mu \in C_0^1 \Lambda^{n-k-1}(M)$. 
Then $\omega \wedge \mu \in C^1 \Lambda^{n-1} (M)$. Recall the 
Leibniz rule for the exterior derivative 
\begin{align*}
    d(\omega \wedge \mu) = d\omega \wedge \mu + (-1)^k \omega \wedge d\mu. 
\end{align*}
By integrating both sides over $M$ and applying Stokes' theorem we obtain
\begin{align*}
    \int_{\partial M} \omega \wedge \mu 
    = \int_M d\omega \wedge \mu + (-1)^k \int_M \omega \wedge d\mu.
\end{align*}
By using vector and scalar proxies as in Sec.\,\ref{sec:differential_forms}
we this can be used to prove the well-known formula
\begin{align*}
    \int_\Omega u\,\diver \mathbf{F} \, dx 
    =  - \int_\Omega \grad u \cdot \mathbf{F} \, dx + 
        \int_{\partial \Omega } u \, \mathbf{F}\cdot \mathbf{n} \, ds
\end{align*}
where $\mathbf{n}$ is the unit normal, assuming $\Omega$ is a bounded Lipschitz domain
and $\mathbf{F}$ and $u$ are continuously differentiable 
or 
\begin{align*}
    \int_\Omega \mathbf{v} \cdot \mathbf{\curl} \mathbf{F} \, dx
    = \int_\Omega \mathbf{\curl} \mathbf{v} \cdot \ \mathbf{F} \, dx
        - \int_{\partial \Omega } (\mathbf{v} \times \mathbf{F})\cdot \mathbf{n} \, ds
\end{align*}
assuming $\mathbf{v}$ is a continuously differentiable vector field.
% The integration by parts motivates the definition of another differential
% operator. Let $\omega \in C^1 \Lambda^k (M)$ be integrable. 
% We define the \textit{codifferential operator} or simply 
% codifferential 
% \begin{align*}
%     \delta \omega \vcentcolon= 
%     (-1)^{n(k-1)+1} \star d \star \omega \in C^0 \Lambda^{k-1} M.
% \end{align*}
% By using the Leibniz rule and Prop.\,\ref{prop:properties_hodge_star} we compute for $\omega \in 
% C_0^1 \Lambda^k (M), \nu \in C_0^1 \Lambda^{k+1} (M)$ i.e. continuously
% differentiable and compactly supported
% \begin{align*}
%     d(\omega \wedge \star \nu) 
%     &= d\omega \wedge \star \nu + 
%         (-1)^k \omega \wedge d \star \nu 
%     \\ &= d\omega \wedge \star \nu + (-1)^k (-1)^{(n-k)k} 
%         \omega \wedge \star \star d \star \nu 
%     \\ &= d\omega \wedge \star \nu + (-1)^k (-1)^{(n-k)k} (-1)^{nk + 1}
%         \omega \wedge \star \delta \nu 
%     \\ &= d\omega \wedge \star \nu -
%         \omega \wedge \star \delta \nu.
% \end{align*}
% In the last step, we used 
% \begin{align*}
%     (-1)^k (-1)^{(n-k)k} (-1)^{nk + 1} 
%     = (-1)^{2kn - k(k-1)+1} = -1
% \end{align*}
% because $2kn - k(k-1)$ is always even. 
% Now we once again integrate on both sides
% \begin{align*}
%     \int_M \langle d\omega_p , \nu_p \rangle_{\alternating{k+1}{T_p M}} \,\vol_p
%     &= \int_M d\omega \wedge \star \nu 
%     = \int_M \omega \wedge \star \delta \nu  
%         + \int_{\partial M} \omega \wedge \star \nu
%     \\ &= \int_M \langle \omega_p , \delta \nu_p \rangle
%         _{\alternating{k}{T_p M}} \, \vol
%         + \int_{\partial M} \langle \omega , \delta \nu 
%         \rangle_{\alternating{k}{T_p \partial M}} \, \vol_{\partial M}.
% \end{align*}
% Some clarification on the notation used. In the first integral we integrate 
% the $n$-form $p \mapsto 
% \langle d\omega_p , \nu_p \rangle_{\alternating{k+1}{T_p M}} \, \vol_p$
% with the inner product of alternating maps introduced in 
% Sec.\,\ref{sec:alternating_maps} and analogous in the last line. 
% From now on, we will leave out the reference to the space of the inner product
% when it is clear from the context.

% This integration by parts will be used in the next section to extend the 
% exterior derivative in the weak sense in analogy to the usual introduction 
% of the weak derivative.


\section{Singular homology}\label{sec:singular_homology}

The curve integral constraint from the magnetostatic problem is very topological % TBD: Reference
in nature and strongly related to the topology of the domain. 
In order to deal with this constraint and obtain the desired existence and
uniqueness we require some tools from algebraic topology which we will introduce 
in this section. 
This material is taken from
\cite{topology_and_geometry} where a lot more details and results can be found.

\subsection{Homology groups}

Denote with $\real^\infty$ the vector space of all real-valued sequences. Let 
$e_i \in \real^\infty$ for $i \in \naturalnum$ denote the sequences that 
that are zero for every index 
unequal to $i$ and $1$ for the index $i$. Note that in this thesis 
the natural numbers start at zero. Then we define the standard $k$-simplex 
$\Delta_k$ as
\begin{align*}
    \Delta_k \vcentcolon= \Big\{ \sum\limits_{i=1}^k  \lambda_i e_i \mid 
    \sum\limits_{i=0}^k \lambda_i = 1 , \; 0\leq \lambda_i \leq 1\Big\}
    = \text{conv} \{e_0,\,...,\, e_k\}.
\end{align*}
where $\text{conv}$ is the usual convex combination. 

\begin{definition}[$k$-simplex]
Let $X$ be a topological space. Then a \textit{singular $k$-simplex} is a continuous 
map $\sigma_k: \Delta_k \rightarrow X$. We will frequently leave out the term 'singular'
and refer to them just as $k$-simplices.
\end{definition}

As the term 'singular' implies these simplices can be degenerated. For example, $\sigma_k$ could 
just be constant for any $k$, so the object in the topological space corresponding to the 
$k$-simplex is just a point.

We can now introduce a algebraic structure by looking at finite formal sums of the form 
\begin{align*}
    \sum_{\text{$\sigma$ $k$-simplex }} n_\sigma \sigma.
\end{align*}
These formal sums form an abelian group which we refer to as the 
\textit{singular $k$-chain group} $C_k(X)$. 

We will now introduce an important homomorphism between these groups called the \textit{boundary}.
\begin{definition}
    Let $v_0, ... , v_k \in \real^n$. 
    We define \textit{affine singular $k$-simplex} as a special singular $k$-simplex denoted by
    \begin{align*}
        [v_0,...,v_k]: \Delta_k \rightarrow \real^n, \, 
        \sum\limits_{i = 0}^k \lambda_i e_i \mapsto \sum\limits_{i = 0}^k \lambda_i v_i.
    \end{align*}
\end{definition}
As in the general case, the image can be a degenerated simplex in $\real^n$ since the 
$v_i$ are not assumed to be affine independent. 

We call the affine singular simplex 
$[e_0,...,\hat{e}_i,...,e_k]: \Delta_{k-1} \rightarrow \Delta_k$ the $i$-th face map. 
The $\hat{ }$ means this vertex is left out. Here we tacitly used the 
natural inclusion $\real^{k+1} \subseteq \real^\infty$ so we have 
$\Delta_k \subseteq \real^{k+1}$. But this is just a way of representation.

With the face map we can now define the boundary operator.
\begin{definition}
    For a singular $k$-simplex $\sigma: \Delta_k \rightarrow X$ we define its $i$-th face 
    $\sigma^{(i)} \vcentcolon= \sigma \circ F_i^k$ which is a $(k-1)$-simplex. 
    We then define the \textit{boundary} of $\sigma$ as 
    $\partial_k \sigma \vcentcolon= \sum_{i=0}^k (-1)^i \sigma^{(i)}$. We extend this 
    to a homomorphism between the chain groups
    \begin{align*}
        \partial_k: C_k(X) \rightarrow C_{k-1}(X), 
        \sum_\sigma n_\sigma \sigma \mapsto \sum_\sigma n_\sigma \partial_k \sigma.
    \end{align*}
    In the case of $k=0$, we set $\partial_0 = 0$.
\end{definition}
We will frequently leave out the subscript and just write $\partial$ for the boundary 
if it is clear from the context.

A straightforward computation (cf. \cite[Lemma 1.6]{topology_and_geometry}) shows the 
important property 
\begin{align*}
    \partial_k \circ \partial_{k+1} = 0.
\end{align*}
This property implies that $\ker \partial_{k-1} \subseteq \Ima \partial_k$ is 
a subgroup. We call a chain $c \in C_k(X)$ \textit{$k$-cycle} if $\partial_k c = 0$ and 
we call it \textit{$k$-boundary} if $c \in \Ima \partial_{k+1}$. 
Denote the group of $k$-cycles as $Z_k(X)$ and the $k$-boundaries as $B_k(X)$.
Since we are in the abelian setting this motivates us to define 
the resulting factor groups.
\begin{definition}[Homology groups]
    We define the \textit{$k$-th homology group} of the topological space $X$ as
    \begin{align*}
        H_k(X) \vcentcolon= \faktor{Z_k(X)}{B_k(X)}.
    \end{align*} 
\end{definition}
We denote the elements of the homology groups i.e. the equivalence classes of a 
$k$-cycle $c$ as $[c] \in H_k(X)$.

If the $k$-th homology groups is finitely generated then we 
call the rank i.e. the number of generators the \textit{$k$-th Betti number}. 
These Betti numbers are fundamental properties of the topological space. 
For example, the zeroth Betti number corresponds to the number of 
path-components of the space. In 3 dimensions, the first Betti number of 
a compact domain
corresponds to the number of "holes", the second Betti number to 
number of enclosed "voids" in the domain. E.g. a filled torus 
has the zeroth Betti number one, the first Betti number also equal to one
and the second equal to zero which can be proven using the Meyer-Vietoris sequence
(see \cite[Sec.\,IV.18]{topology_and_geometry}). We will not go into this in further
since we do not want to focus too much on algebraic topology.

This construction can be put in an abstract algebraic framework in the following 
way. We call a collection of abelian groups $C_i$, $i\in \integers$ a graded group.                                                   
Together with a collection of homomorphims $\partial_i: C_i \rightarrow C_{i-1}$ 
called \textit{differentials}
s.t. $\partial_{i-1} \circ \partial_i$ this is called a \textit{chain complex} which 
we will denote by $C_*$. 

\begin{example}
    If we set $C_k(X) = {0}$ for $k < 0$ this gives us a chain complex together with 
    the boundary operator. 
\end{example}

Completely analogous to above, we can define the homology groups 
\begin{align*}
    H_k(C_*) \vcentcolon= \faktor{\ker \partial_k}{\Ima \partial_{k+1}}.
\end{align*}

\begin{definition}[Chain map]
    Let $A_*$ and $B_*$ be chain complexes. With a slight abuse of notation
    let us denote the differentials of 
    both chain complexes just by $\partial$.
    Then a \textit{chain map} $f: A^* \rightarrow B^*$ is a collection 
    of homomorphisms $f_i: A_i \rightarrow B_i$ s.t. 
    $f_{i-1} \circ \partial = \partial \circ f_i$.
\end{definition}
{\color{red} Include commuting diagram.} We will most times leave out the 
indices if it is clear what we mean.
The crucial property of these chain maps is that they induce homomorphisms of
the homology groups denoted as
\begin{align*}
    [f_i]: H_i(A_*) \rightarrow H_i(B_*), \, [f_i]([a]) = [f_i([a])]
\end{align*}


Let $\{ C^i \}_{i\in \naturalnum}$ be a collection of abelian groups
and homomorphisms $\partial^i: C^i \rightarrow C^{i+1}$ with 
$\partial^{i+1} \circ \partial^i = 0$ called \textit{codifferentials}. 
Then we call this sequence a 
\textit{cochain complex}. The only difference to chain complexes
is that the index 
increases when applying the codifferential. Hence, they are 
basically the same from an algebraic point of view.
By convention, 
we use superindices for anything that is related to cochain complexes.

We define \textit{cochain maps} completely analogous to chain maps 
i.e. cochain maps commute with the codifferential.

The main motivation for cochain complexes comes from the 
\textit{singular cochain complexes} which we will define in the next 
section.

\begin{example}[De Rham complex]
    Smooth differential forms provide us with another very important example. 
    Let $M$ be a smooth manifold.
    We will use the the notation introduced in 
    Sec.\,\ref{sec:differential_forms}. Then the smooth 
    differential forms $C^\infty \Lambda^k (M)$ together 
    with the exterior derivative give us a cochain complex which we call 
    \textit{de Rham complex}. Note that we have slightly more structure here
    since the $C^\infty \Lambda^k (M)$ are vector spaces and the exterior
    derivative a linear map i.e. a vector space homomorphism.
\end{example}
It turns out that the de Rham complex is closely related with the 
singular cochain complex. This relation will be investigated later in 
Sec.\,\ref{sec:de_rhams_theorem}. %TBD: Example Hilbert complex

\subsection{Cohomology groups}

Let $G$ be any abelian group and $X$ be a topological space as before. 
Then we define the group 
of \textit{$k$-cochains} $C^k(X;G)$ by
\begin{align*}
    C^k(X;G) \vcentcolon= \text{Hom}(C_k(X),\,G)
\end{align*}
i.e. the group of all homomorphisms from $k$-chains $C_k(X)$ to $G$. 
We generally use the superindex $^k$ if something is related to 
cochains and the subindex $_k$ if it is related to chains. 
Just as for chains we now introduce a homomorphism between the groups of cochains
which transforms this into a cochain complex.
\begin{definition}[Coboundary ]
    We define the operator $\partial^k: C^k(X;G) \rightarrow C^{k+1}(X;G)$ via
    \begin{align*}
        (\partial^k f) (c) \vcentcolon= f(\partial_{k+1} c).
    \end{align*}
    for a $(k+1)$-chain $c$.
    We call a cochain $f \in C^k(K;G)$ \textit{closed} if $\partial^k f = 0$ 
    and we call $f$
    \textit{exact} if there is a $g \in C^{k-1}(K;G)$ s.t. $f = \partial^{k-1} g$.
    As for the boundary map we will frequently leave away the superscript if
    the context is clear.
\end{definition}
From the definition it is obvious that $\partial^{k+1} \circ \partial^{k} = 0$ 
and thus we have indeed a cochain complex which we call \textit{singular cochain 
complex}. If there is no confusion with the general notion of cochain complex
we will leave away the term 'singular'.
\begin{definition}[Cochain cohomology]
    Denote the closed $k$-cochains as $Z^k(X;G)$ and the 
    exact ones with $B^k(X;G)$. 
    We then define the \textit{cochain cohomology groups}
    $H^k(X;G)$ as
    \begin{align*}
        H^k(X;G) \vcentcolon= \faktor{Z^k(X;G)}{B^k(X;G)}.
    \end{align*}
\end{definition}
Note that in the case of $G = \real$ this becomes a vector space.

Now of course there is the question how the homology and cohomology groups 
are related to each other. This question is answered by the
\textit{universal coefficent theorem}. But before we can formulate it we have 
to introduce exact sequences.
\begin{definition}[Exact sequence]
    Let $(G_i)_{i\in \integers}$ be a sequence of groups and 
    $(f_i)_{i \in \integers}$ be a sequence of homomorphisms
    $f_i: G_i \rightarrow G_{i+1}$. Then this sequence of homomorphisms is
    called \textit{exact} if $\text{im}\,f_{i-1} = \text{ker}\,f_i$.
\end{definition}

The universal coefficent theorem in the case of simplicial homology states
that the sequence 
\begin{align}
    0 \rightarrow \text{Ext}(H_{k-1}(K),G) \rightarrow 
    H^k(K;G) \xrightarrow{\beta} \text{Hom}(H_k(K),G) 
    \rightarrow 0 \label{eq:univeral_coefficient_theorem}
\end{align}
is exact. 
$\beta$ is defined via 
\begin{align}
    \beta([F])([c]) \vcentcolon= F(c).
    \label{eq:isomorphism_from_universal_coefficent_theorem}
\end{align}
The definition of Ext can be found in \cite{topology_and_geometry},
but it does not matter for our purpose because from now on we will assume
$G = \real$ and
$\text{Ext}(H_{k-1}(X),\real) = 0$. This follows from the fact that 
$\real$ is a divisible and hence injective abelian group. The definition of
these terms and the connections used can also be found in 
\cite[Sec.\,V.6]{topology_and_geometry}. However, we will not dwelve into the 
algebraic background further. In the case of $G = \real$, 
we can conclude from the exactness of the 
above short sequence that $\text{ker}\,\beta = 0$ and 
$\text{im}\,\beta = \text{Hom}(H_k(X),\real)$. So $\beta$ is an isomorphism.


\subsection{De Rham's theorem} \label{sec:de_rhams_theorem}

It turns out that the cochain cohomology is closely related to the cohomology 
of differential forms (\ref{}). Let us recall Stokes' theorem first which said 
that for a $k$-form $\omega \in \smoothcompforms{k}{M}$ 
for a smooth $k$-dimensional oriented manifold $M$ we have 
\begin{align*}
    \int_M d\omega = \int_{\partial M} \omega.
\end{align*}

The following details are taken from Section V.5 and and V.9 from 
\cite{topology_and_geometry}. We will only focus on the main ideas and avoid 
dwelving into the technical details. The interested reader can find more 
arguments in the given reference.

Let now $\sigma$ be a smooth $k$-simplex i.e. $\sigma: \Delta_k \rightarrow 
M$ is smooth. We now define 
\begin{align*}
    \int_\sigma \omega = \int_{\Delta_k} \sigma^* \omega
\end{align*}
and then we define the integral over a $k$-chain 
$c = \sum_\sigma n_\sigma \sigma$
\begin{align*}
    \int_c \omega \vcentcolon= \sum \limits_\sigma n_\sigma \int_\sigma \omega.
\end{align*}
This motivates us to introduce the homomorphism $I: C^\infty \Lambda^k (M) 
\rightarrow \text{Hom}(C_k;\real)$ defined by 
\begin{align*}
    I(\omega)(c) = \int_c \omega.
\end{align*}
\begin{remark}
    There are some technical details that we will not discuss in details here,
    but that should be mentioned. First, $\Delta_k$ is not a manifold. 
    The $(k-2)$ skeleton are, simply speaking, 
    the simplices of dimension $(k-2)$ i.e. the corners for $k=2$ and the 
    edges for $k=3$. If we remove the $(k-2)$ skeleton 
    then $\Delta_k$ is a manifold 
    with boundary. But since this is a null-set w.r.t. the full simplex and 
    the boundary as well, this does not matter for our arguments. 
    Second, Because we are integrating over the $\Delta_k$ their orientation is 
    important and has to be chosen consistently. We will not present here 
    how this is done and will just assume it from now on.
\end{remark}

Using Stokes's theorem and the fact that the exterior derivative commutes with 
the pullback we observe
\begin{align*}
    I(d\omega)(c) &= \sum\limits_\sigma n_\sigma \int_\sigma d\omega 
    = \sum\limits_\sigma n_\sigma \int_{\Delta_k} \sigma^* d\omega 
    = \sum\limits_\sigma n_\sigma \int_{\Delta_k} d\sigma^* \omega
    = \sum\limits_\sigma n_\sigma \int_{\partial \Delta_k} \sigma^* \omega
    \\ &= \int_{\sum_\sigma n_\sigma \partial \sigma} \omega
    = I(\omega)(\partial c) = \partial \big(I(\omega)\big) (c)
\end{align*}
so we obtain
\begin{align*}
    I(d\omega) = \partial \big(I(\omega)\big).
\end{align*}
We see that $I$ is a cochain map and thus 
induces a homomorphism on cohomology
\begin{align*}
    [I]:H^k_{dR}(M) \rightarrow H^k(M;\real).
\end{align*}

Using the notation and the definition of this map we can now formulate 
de Rham's theorem which will become very important later when proving
existence and uniqueness in Sec.\,\ref{sec:existence_and_uniqueness}.
\begin{theorem}[De Rham's theorem]
    $[I]$ is an isomorphism.
\end{theorem}

\section{Hilbert complexes}

Another crucial tool for the proof will be the \textit{Hodge decomposition} 
in 3D which relies on unbounded operators and Hilbert complexes. These 
will be introduces in this section. This section is essentially a 
recollection of the parts of chapter 3 and 4 of Arnold's book \cite{arnold}
which we will need. We will stay close to this source. At certain parts, 
some additional arguments and steps will be added, but the reference is 
already very detailed so there is not much to add. Throughout this section 
it will be assumed that the reader is familiar with the basic theory of 
Hilbert spaces and bounded linear operators. We will focus on real spaces 
exclusively.

\subsection{Unbounded operators}\label{sec:unbounded_operators}

\begin{definition}[Unbounded operators]
    Let $X$ and $Y$ be Hilbert spaces. Then we call a linear mapping 
    $T: D(T) \rightarrow Y$ with a subspace $D(T) \subseteq Y$ an 
    \textit{unbounded 
    operator} from $X$ to $Y$. We call $D(T)$ the \textit{domain} of $T$.
\end{definition}
We will write sometimes talk about an unbounded operator $T:X \rightarrow Y$ 
which means that $T$ is not necessarily defined on all of $X$. 

Note that this definition generalizes the standard operator. In particular, 
it includes the case when $T$ is in fact bounded which can be 
slightly confusing, but we will stick to this common naming convention. 

The domain is a crucial property of unbounded operators. We will sometimes 
denote the unbounded operator as the tuple $(T,D(T))$.
If $D(T)$ is dense in $X$ we call $T$ \textit{densely defined}. 
We say that two unbounded operators $T$ and $S$ from $X$ to $Y$ are equal 
if $D(T) = D(S)$ and $Tx = Sx$ for all $x\in D(T)$.

The standard
example of an unbounded densely defined operator is the classical gradient with 
the domain $C_0^1(\Omega) \subseteq L^2 (\Omega)$ 
with $\Omega \subseteq \real^n$ i.e. here we have $X=L^2(\Omega)$ and 
$Y=L^2(\Omega;\real^n)$.
In short, $\grad$ is an unbounded operator from $L^2(\Omega)$ to 
$L^2(\Omega;\real^n)$ with domain $C_0^1(\Omega)$.
We could then denote it as $(\grad, C_0^1(\Omega))$. This also shows that 
the choice of domain is not unique. We could have instead chosen e.g. the 
different unbounded operator $(\grad, C_0^\infty (\Omega))$. 
Another example is the weak gradient with domain $H^1(\Omega)$ i.e.
$(\grad, H^1(\Omega))$.

As for bounded operators we define the kernel or null space of an unbounded
operator 
\begin{align*}
    \ker T = \{ x \in D(T) \mid Tx = 0\}
\end{align*}
and the image or range
\begin{align*}
    \Ima T = \{ Tx \mid x \in D(T)\}.
\end{align*}
The only difference is to keep in mind that the unbounded operators are not 
defined on the whole $X$ in general.

Recall that the graph of a function $f: X \rightarrow Y$ is defined 
as $\{ (x,f(x)) \in X \times Y \mid x \in X\}$. 
Analogously, the graph of an unbounded operator $T$ is 
\begin{align*}
    \Gamma(T) \vcentcolon= \{ (x,Tx) \mid x \in D(T) \}
\end{align*}
which is obviously a subspace of $X\times Y$.

We define the \textit{graph inner product} on $D(T)$ as 
\begin{align*}
    \langle x,z \rangle _{D(T)} 
    \vcentcolon= \langle x,z \rangle _X + \langle Tx, Tz \rangle _Y,
    \quad x,z \in D(T).
\end{align*}
It is easy to show that this is indeed an inner product. We will call its 
induced norm the \textit{graph norm}
\begin{align*}
    \lVert x \rVert _{D(T)} = \sqrt{ \lVert x \rVert^2 _X + \lVert Tx \rVert ^2 _Y}
    , \quad x\in D(T).
\end{align*}
Even though this defines a norm, $D(T)$ might not be a Hilbert space 
because it is in general not complete w.r.t. this norm. Consider for example 
the unbounded operator $\grad: L^2(\Omega) \rightarrow L^2(\Omega;\real^n)$ with 
domain $C_0^\infty(\Omega)$ and a $\Omega \subseteq \real^n$.
The graph norm is then
\begin{align*}
    \lVert \phi \rVert _{D(\grad)} 
    = \sqrt{ \lVert \phi \rVert^2 _{L^2(\Omega)} + \lVert \grad \phi \rVert^2 
        _{L^2(\Omega)}}
        , \quad \phi \in C_0^\infty(\Omega)
\end{align*}
which is just the standard $H^1$-norm.
But it is well-known that $C_0^\infty(\Omega)$ is in fact not closed 
w.r.t. this norm and thus not complete 
since the completion of it is the space $H^1_0(\Omega)$ i.e. 
the Sobolev space with zero trace on the boundary. 
Below in Prop.\,\ref{prop:closed_operator_graph_norm} we will provide a
sufficient and necessary condition for the domain to be a Hilbert space 
when the graph norm is used. 

The well-known closed graph theorem for bounded operators says that 
a linear operator from $X$ to $Y$ defined on all of $X$ 
(in contrast to unbounded operators in general) is bounded i.i.f. 
its graph is closed in $X\times Y$ w.r.t. the norm 
$\lVert (x,y) \rVert _{X\times Y} 
= \sqrt{\lVert x \rVert^2 _{X} + \lVert y \rVert^2 _{Y}}$. 
This motivates the following definition.

\begin{definition}[Closed operator]
    We call an unbounded operator $T:X \rightarrow Y$ \textit{closed} if 
    its graph $\Gamma(T)$ is closed w.r.t. the norm 
    $\lVert \cdot \rVert _{X\times Y}$.
\end{definition}
That means if we have a closed operator $T$ and
take a sequence $(x_n)_{n\in \naturalnum} \subseteq D(T)$
s.t. $x_n \xrightarrow{X} x$ and $Tx_n \xrightarrow{Y} y$ for some 
$x \in X$ and $y \in Y$. Then $(x_n,Tx_n) \xrightarrow{X\times Y} (x,y)$ and 
since $T$ is closed
$(x,y) \in \Gamma(T)$ i.e. $x \in D(T)$ and $Tx = y$. This is just 
a rephrasing of the definition essentially so this characterizes closed
operators equivalently.

\begin{proposition}\label{prop:closed_operator_graph_norm}
    An unbounded operator $T$ is closed i.i.f. its domain $D(T)$, endowed with the 
    graph inner product, is a Hilbert space.
\end{proposition}
\begin{proof}
    As mentioned above, the graph inner product is in fact an inner product 
    on $D(T)$. So we have to show completeness.
    Assume that $T$ is closed and take a sequence $(x_n)_{n \in \naturalnum} 
    \subseteq D(T)$ that is Cauchy w.r.t. the graph norm. That implies 
    that $(x_n)$ must be Cauchy w.r.t. the $X$-norm and $(Tx_n)$ must be 
    Cauchy w.r.t. the $Y$-norm. Because $X$ and $Y$ are Hilbert spaces 
    there exists $x \in X$ s.t. $x_n \rightarrow x$ and $y \in Y$ s.t. 
    $Tx_n \rightarrow y$. Because $T$ is closed we know 
    $x \in D(T)$ so $D(T)$ is complete.

    For the other direction, assume $D(T)$ is complete and take a sequence 
    $(x_n)_{n \in \naturalnum} \subseteq D(T)$ s.t. $x_n \rightarrow x \in X$ 
    and $Tx_n \rightarrow y$ for some $y \in Y$. Because both sequences are 
    convergent they are both Cauchy and thus $(x_n)$ is Cauchy w.r.t. the
    graph norm. Due to the completeness of $D(T)$ that implies that $x \in D(T)$
    and $x_n \xrightarrow{D(T)} x$ and 
    \begin{align*}
        \lVert x_n - x \rVert^2 _{D(T)} 
        = \lVert x_n - x \rVert^2 _X + \lVert Tx_n - Tx \rVert^2 _Y 
        \rightarrow 0
    \end{align*}
    so $T x_n \rightarrow T x$ and thus $Tx = y$ which proves that 
    $T$ is closed.
\end{proof}

As an example, take the unbounded operator $(\grad, H^1(\Omega))$
i.e. the weak gradient as an unbounded operator 
from $L^2(\Omega)$ to $L^2(\Omega;\real^n)$ with 
domain $D(\grad) = H^1(\Omega)$. Then we described above that the 
graph norm here is just the $H^1$-norm. It is well-known that 
$H^1(\Omega)$ is a Hilbert space. Therefore the 
Prop.\,\ref{prop:closed_operator_graph_norm} tells us that 
$(\grad, H^1(\Omega))$ is a closed operator in contrast to 
$(\grad, C_0^\infty(\Omega))$ as described above.

The adjoint of bounded operators can be generalized to unbounded operators 
as well. Let us derive this step by step. 

Assume $T: X \rightarrow Y$ is a densely defined unbounded operator. 
Let us fix a $y \in Y$ and 
look at the linear functional $l:D(T) \rightarrow \real$ given by
\begin{align*}
    l(x) = \langle y, Tx \rangle_Y.
\end{align*}
This functional is not necessarily bounded. But if it is i.e. if $l \in D(T)'$ 
then because $D(T)$ is dense in $X$ we can extend it to a
$\bar{l} \in X'$. Let $v \in X$ be its Riesz representative. That means we have
\begin{align*}
    \langle v, x \rangle_X = l(x) = \langle y, Tx \rangle_Y 
        \quad \forall x \in D(T).
\end{align*}
Then when we define $v = T^* y$ and we 
recognize this as the defining property of the adjoint and define 
\begin{align*}
    D(T^*) \vcentcolon= \{ y \in Y \mid \exists c_y \in \real:
        \,\langle y, Tx \rangle_Y \leq c_y \lVert x \rVert _X \forall x \in X\}
\end{align*}

We would like to proof whether $T^*$ is itself densely defined or closed. 
This can be done in an elegant way by invstigating the graphs of $T$ and 
$T^*$. In order to do so, we have the following lemma.
\begin{lemma}\label{lem:rotated_graph}
    Let $T$ be a densely defined unbounded operator from $X$ to $Y$. 
    Define the rotated graph of $T^*$ as
    \begin{align*}
        \tilde{\Gamma}(T^*) \vcentcolon= \{ (-x,y) \mid (y,x) \in \Gamma(T^*) \}
        = \{ (-T^*y, y) \mid y \in D(T^*) \} \subseteq X \times Y.
    \end{align*}
    Then we have 
    \begin{align*}
        & \Gamma(T)^\perp = \tilde{\Gamma}(T^*) \text{ and}
        \\ &\overline{\Gamma(T)} = \tilde{\Gamma}(T^*)^\perp.
    \end{align*}
\end{lemma}
\begin{proof}
    $(x,y) \in \Gamma(T)^\perp$ holds i.i.f. 
    \begin{align*}
        0 = \langle (x,y), (v,Tv) \rangle _{X\times Y}
        = \langle x, v \rangle _X + \langle y, Tv \rangle _Y
            \quad \forall v \in D(T).
    \end{align*}
    i.e. 
    \begin{align*}
        \langle -x, v \rangle _X = \langle y, Tv \rangle _Y,
            \quad \forall v \in D(T).
    \end{align*}
    This is just equivalent to saying that $-x = T^*y$ i.e.
    \begin{align*}
        (x,y) = (-T^*y,y) \in \tilde{\Gamma}(T^*)
    \end{align*}
    which proves the first equality.

    For the second equivalence recall the basic fact from Hilbert space theory
    that for any subspace of a Hilbert space $V$,
    $(V^\perp)^\perp = \overline{V}$. Hence, applying the orthogonal 
    complement to both sides of the first equality gives us the second one.
\end{proof}

\begin{corollary}\label{cor:adjoint_of_densely_defined}
    The adjoint $T^*$ of a densely defined operator $T$ is closed. 
\end{corollary}
\begin{proof}
    Recall another basic fact from Hilbert space theory that the 
    orthogonal complement of a space is always closed. 
    So we know from the first equality that $\tilde{\Gamma}(T^*)$ is closed.
    It is then trivial to see from the definition of $\tilde{\Gamma}(T^*)$
    that $\Gamma(T^*)$ is closed and 
    thus $T^*$ a closed unbounded operator.
\end{proof}

\begin{proposition}\label{prop:adjoint_of_densely_defined_closed}
    Let $T$ be a densely defined and closed unbounded operator.
    Then $T^*$ is also densely defined and closed.
\end{proposition}
\begin{proof}
    We know from the previous corollary that $T^*$ is closed. 
    In order to prove density, once again recall a fact from Hilbert space
    theory that a subspace is dense i.i.f. its orthogonal complement 
    is zero. So take $y \in D(T^*)^\perp$ arbitrary. We now have to show that 
    $y=0$ to complete the proof.
    \begin{align*}
        0 = \langle y, w \rangle_Y 
        = \langle 0, -T^*w \rangle _X + \langle y, w \rangle _Y
        = \langle (0,y), (-T^*w,w) \rangle _{X\times Y} \quad \forall w \in D(T^*)
    \end{align*}
    which just means
    \begin{align*}
        (0,y) \in \tilde{\Gamma}(T^*)^\perp 
        \stackrel{\text{Lemma\,\ref{lem:rotated_graph}} }{=} \overline{\Gamma(T)}
        = \Gamma(T).
    \end{align*}
    In the last line we used the fact, that $T$ is closed. 
    Thus $y = T0 = 0$ which concludes the proof.
\end{proof}

We will now take a closer look at the kernels and images of unbounded operators.
Let us first notice a very clear result. If $T$ is a closed unbounded operator 
then its kernel $\ker T$ is closed. This follows indeed from the definition. 
But this is not true for the image $\Ima T$. Let us take
$(y_n)_{n \in \naturalnum} \subseteq \Ima T$ with $y_n \rightarrow y$.
However if we now take the sequence $(x_n)_{n \in \naturalnum} \subseteq D(T)$
s.t. $Tx_n = y_n$ we do not know if $(x_n)$ converges or 
whether the limit is in $D(T)$ if it does converge. 
A very simple example is the inclusion operator
$\iota: H^1(\Omega) \rightarrow L^2(\Omega)$. This is actually a bounded 
operator and hence closed since 
\begin{align*}
    \lVert \iota f \rVert _{L^2(\Omega)} 
    = \lVert f \rVert _{L^2(\Omega)} 
    \leq \lVert f \rVert _{H^1(\Omega)},
\end{align*}
but its range $H^1(\Omega)$ is not closed in $L^2(\Omega)$.

Let us summarize the following relationships between the images and kernels 
of closed densely defined operators and their adjoints.

\begin{proposition}\label{prop:kernel_image_adjoint}
    Let $T: X \rightarrow Y$ be a closed densely defined operator. Then
    \begin{itemize}
        \item $(\Ima T)^\perp = \ker T^*$
        \item $(\ker T)^\perp = \overline{\Ima(T^*)}$
        \item $(\Ima T^*)^\perp = \ker T$
        \item $(\ker T^*)^\perp = \overline{\Ima(T)}$
    \end{itemize}
\end{proposition}
\begin{proof}
    We will once again rely on Lemma\,\ref{lem:rotated_graph} about the 
    rotated graph. We will start with (iii)
    \begin{align*}
        x \in \ker T \Leftrightarrow (x,0) \in \Gamma(T) 
        \stackrel{\text{$T$ closed}}{=} \overline{\Gamma(T)} 
        = \tilde{\Gamma}(T^*)^\perp 
    \end{align*}
    The last statement is equivalent to saying that for any $y \in D(T^*)$ 
    we have 
    \begin{align*}
        0 = \langle (x,0), (-T^*y,y) \rangle_{X \times Y}
        = \langle x, -T^*y \rangle_X
    \end{align*}
    which just means $x \in (\Ima T^*)^\perp$ and we proved (iii).

    (ii) follows from that immediately by taking the orthogonal complement 
    on both sides.

    From Prop.\,\ref{prop:adjoint_of_densely_defined_closed} 
    we know that $T^*$ is closed and densely defined because $T$
    is. So the completely analogous reasoning with the roles of $T$ and $T^*$
    exchanged gives us (i) and taking the orthogonal complement again 
    proves (iv).
\end{proof}

Let us investigate the situation in 3D with the common differential 
operators $\curl$, $\grad$ and $\diver$ on a domain $\Omega$. Throughout the 
following, all function spaces will always be over an open domain 
$\Omega \subseteq \real^3$ unless specified otherwise.
Take the unbounded operator 
$\diver: L^2(\Omega;\real^3) \rightarrow L^2(\Omega)$ with domain 
$C_0^\infty$ i.e. $(\diver, C_0^\infty)$. 
When we take the adjoint of it then we know for $v \in 
D((\diver, C_0^\infty)^*)$
\begin{align*}
    \int_\Omega \diver ^* v \cdot \mathbf{u} \, dx
    = \int_\Omega v \, \diver \mathbf{u} \, dx \quad \forall 
    \mathbf{u} \in C_0^\infty(\Omega;\real^3)
\end{align*}
Now if we take $\mathbf{u} = (\mathbf{u}_1,0,0)^\top$ then recognize 
\begin{align}
    \int_\Omega (\diver ^* v)_1 \, \mathbf{u}_1 \, dx
    = \int_\Omega v \, \partial_1 \mathbf{u}_1 \, dx \quad 
        \forall \mathbf{u}_1 \in C_0^\infty
    \label{eq:adjoint_gradient_c0inf}
\end{align}
so we recognize that $-(\diver ^* v)_1$ is the weak derivative of w.r.t. the 
first coordinate i.e. $-\partial_1 v$ and analogous for the other coordinates 
so we recognize $\diver^* = -\grad$. We further see that the
domain s.t. (\ref{eq:adjoint_gradient_c0inf}) is fulfilled is $H^1(\Omega)$ 
by definition. That means we showed 
\begin{align*}
    (\diver, C_0^\infty)^* = (-\grad, H^1).     
\end{align*}

Because $C_0^\infty$ is dense in $L^2$ i.e. 
$(\diver, C_0^\infty)$ is densely defined. 
We know from Cor.\,\ref{cor:adjoint_of_densely_defined} 
that its adjoint $(-\grad, H^1)$ is closed and 
we can conclude from Prop.\,\ref{prop:closed_operator_graph_norm} 
that $H^1(\Omega)$ is in fact a Hilbert space 
when using the graph norm which is the $H^1$-norm here.

By interchanging $\diver$ and $\grad$ in the above arguments we can conclude 
\begin{align*}
    (-\grad, C_0^\infty)^* = (\diver, H(\diver))
\end{align*}
where $H(\diver)$ is the domain of the adjoint which is equivalent to saying
that for $\mathbf{u} \in H(\diver)$ there exists a $\tilde{v} \in L^2$ s.t.
\begin{align*}
    \int_\Omega \tilde{v} \phi \, dx = -\int_\Omega \mathbf{v} 
        \cdot \grad \phi \, dx \quad \forall \phi \in C_0^\infty
\end{align*}
where we denote $\tilde{v} = \diver \mathbf{v}$ i.e. the weak divergence.

We know that $H^1$ contains all smooth functions 
$C^\infty(\overline{\Omega})$ which are dense in $L^2$. 
Analogously, it can be shown that $H(\diver)$ includes all smooth 
vector valued functions $C^\infty(\overline{\Omega};\real^3)$. Hence, 
both of $(\grad,H^1)$ and $(\diver,H(\diver))$ are densely defined.

That begs the question what in turn the adjoints of 
$(\grad,H^1)$ and $(\diver, H(\diver))$ are. 
In order to answer it, we take a look at the standard 
integration-by-parts formula assuming $\Omega$ is a Lipschitz domain
\begin{align}
    \int_\Omega u \, \diver \mathbf{w} \, dx 
        + \int_\Omega \grad u \cdot \mathbf{w} \, dx
    = \int_{\partial \Omega} u \, \mathbf{w}\cdot n \, ds
    \label{eq:integration_by_parts}
\end{align}
where $n$ is the outward unit normal of $\Omega$. If we want 
$u \in D(\diver)$ then the boundary integral on the right hand side must 
vanish which would be the case if $u$ is zero on the boundary. 

We can now take two approaches. The first one follows \cite{picard} by 
saying a $u\in H^1$ has \textit{zero boundary conditions} 
i.i.f. the right hand side vanishes for any $\mathbf{w} \in H(\diver)$. 
This has the advantage that this 
definition makes sense on any domain $\Omega$ independent of the regularity of 
the boundary. 

The other approach followed by Arnold defines the trace operators. 
For $H^1$ this is very basic and leads to the classic trace operator 
$\tr : H^1(\Omega) \rightarrow H^{1/2}(\Omega)$ assuming $\Omega$ has a 
Lipschitz boundary. Then we find 
$(\diver, H(\diver))^* = H^1_0(\Omega)$ where $H^1_0(\Omega)$ is the 
space of $H^1$-functions with zero trace. Then we obtain 
\begin{align*}
    (\diver, H(\diver))^* = (-\grad, H^1_0).
\end{align*}

Vice versa, we see that if $u$ is non-zero on the boundary then 
$\mathbf{w}\cdot n$ has to vanish. We can give mean to this for functions 
in $H(\diver)$ by defining a operator $\gamma_n: H(\div) \rightarrow H^{-1/2}$ 
s.t. if $\mathbf{w}$ is differentiable then 
$\gamma_n(\mathbf{w}) = \mathbf{w} \cdot n$. Then we would define 
\begin{align*}
    \mathring{H}(\div) = \{ \mathbf{w} \in H(\diver) \mid \gamma_n\, \mathbf{w} 
        = 0 \}
\end{align*}
and we get
\begin{align*}
    (\grad, H^1)^* = (\diver, \mathring{H}(\diver)).
\end{align*}

Now let us turn our attention to the remaining fundamenta differential operator 
$\curl$. Recall that we have for 
$\mathbf{u}, \mathbf{v} \in C^1(\overline{\Omega})$ the integration-by-parts 
formula
\begin{align*}
    \int_\Omega \mathbf{v} \cdot \curl \mathbf{u} \, dx 
    = \int_\Omega \curl \mathbf{v} \cdot \mathbf{u} \, dx 
        + \int_{\partial \Omega} \mathbf{v} \times n \cdot \mathbf{u} \, ds 
\end{align*}
if $\Omega$ is bounded. Based on this formula
we obtain the weak $\curl$ as
\begin{align*}
    (\curl, H(\curl)) = (\curl, C_0^\infty)^*.
\end{align*}
Then one is able to define an operator $\gamma_\tau: H(\curl) \rightarrow 
H^{-1/2}(\partial \Omega; \real^3)$ s.t. 
$\gamma_\tau \, \mathbf{w} = \mathbf{w}\times n$ for $\mathbf{w} \in 
C^1(\overline{\Omega};\real^3)$ and then define 
$\mathring{H}(\curl) = \{ \mathbf{w} \in H(\curl) 
\mid \gamma_\tau \, \mathbf{w} = 0 \}$. 
It can be shown that $C^\infty(\overline{\Omega})$ is dense in $H(\curl)$.
Then we end up with
\begin{align*}
    (\curl, H(\curl))^* = (\curl, \mathring{H}(\curl)).
\end{align*}

It can be shown that $C^\infty(\overline{\Omega})$ is dense in $H(\curl)$.
From Prop.\,\ref{} we then know that $(\grad, H^1)$, $(\diver, H(\diver))$ 
and $(\curl, H(\curl))$ as well as the corresponding spaces with homogeneous 
boundary condition are closed and densely defined. To summarize:

\begin{theorem}
    Let $\Omega$ be a bounded
    \begin{itemize}
        \item 
    \end{itemize}
\end{theorem}

\subsection{Hilbert complexes}

Now we will combine the idea of cochain complexes from Section 
\ref{sec:singular_homology} 
with unbounded operators. Recall that a cochain complex 
is in full generality a sequence of groups $(G^i)_{i\in \integers}$ 
and group homomorphims $f^i: G^i \rightarrow G^{i+1}$ s.t. 
$f^{i+1} \circ f^{i} = 0$.

\begin{definition}[Hilbert complex]
    A Hilbert complex is a sequence of real Hilbert spaces $(W^k)_{k\in \integers}$
    and a sequence of closed, densely defined 
    unbounded operators $d^k: W^k \rightarrow W^{k+1}$ with domain
    $V^k \subseteq W^k$ s.t. $d^{k+1} \circ d^k = 0$.
\end{definition}
\noindent We denote $\mathfrak{Z}^k  \vcentcolon= \ker d^k$ and $\mathfrak{B}^k 
\vcentcolon= \Ima d^{k-1}$. Then it follows from the definition that
$\mathfrak{B}^k \subseteq \mathfrak{Z}^k$.

We know from \ref{} that unbounded operators are bounded w.r.t. the graph norm
which means here that the restriction of the operators to their domain 
$d^k: V^k \rightarrow V^{k+1}$ are bounded operators when we use the graph norm
on $V^k$. Note that $\mathfrak{B}^{k+1} \subseteq \mathfrak{Z}^{k+1} 
\subseteq V^{k+1}$
so this is well-defined. Because we assume $d^k$ to be 
closed we know from Prop.\,\ref{prop:closed_operator_graph_norm}
that $V^k$ are Hilbert spaces w.r.t. the graph norm $\lVert \cdot \rVert _{V^k}$.
So we see that $d^k$ together with $V^k$ is also a Hilbert complex which 
we call \textit{domain complex}. In this Hilbert complex all operators are 
bounded. Notice because the operators are defined on the whole Hilbert space 
$d^k$ this fits the definition of a cochain complex since vector spaces 
with summation
are groups and the $d^k$ are linear mappings and hence group homomorphisms.

Now let us investigate the adjoints of the operators in a Hilbert complex.
Since we assume the operators to be closed and densely defined the adjoints 
exist and we denote with $d_k^*:W^k \rightarrow W^{k-1}$ the adjoint of $d^k$.
Due to Prop.\,\ref{prop:adjoint_of_densely_defined_closed} we know that the 
adjoints are also closed and densely defined. We denote 
$V_k^* \vcentcolon= D(d_k^*)$, $\mathfrak{Z}^*_k \vcentcolon= \ker d^*_k$ 
and $\mathfrak{B}^*_k \vcentcolon= \Ima d^*_k$. We will frequently leave out 
the indices from now on.

We can now apply Prop.\,\ref{prop:kernel_image_adjoint} to this construction. 
Then we observe 
\begin{align*}
    \mathfrak{B}^\perp &= \mathfrak{Z}^*,
    \\ \mathfrak{Z}^\perp &= \overline{\mathfrak{B}^*},
    \\ \mathfrak{B^*}^\perp &= \mathfrak{Z} \text{ and}
    \\ \mathfrak{Z^*}^\perp &= \overline{\mathfrak{B}^*}.
\end{align*}
Now recall the basic fact from Hilbert space theory that 
in any Hilbert space if we have any two subspaces $V \subseteq W$ then taking the 
orthogonal complements reverses the inclusion i.e.
$V^\perp \supseteq W^\perp$. Then we get 
\begin{align}
    \mathfrak{B}^* \subseteq \overline{\mathfrak{B}^*} 
    = \mathfrak{Z}^\perp  \subseteq \mathfrak{B}^\perp 
    = \mathfrak{Z}^*. \label{eq:image_kernel_of_adjoint_in_hilbert_complex}
\end{align}
So we recognize that $d_k^*:W^k \rightarrow W^{k-1}$ form a structure 
very similar to a Hilbert complex with the only difference being that 
the indices of the spaces decrease. We call this complex the 
\textit{dual complex} of the Hilbert complex.

\begin{definition}
    We call a $v \in V^k \cap V^*_k$ harmonic if $d^k v = 0$ and 
    $d^*_k v = 0$. Denote the space of harmonic elements as 
    $\mathfrak{H}^k$.
\end{definition}
\noindent We can rewrite this as $\mathfrak{H}^k = \mathfrak{Z}^k 
\cap \mathfrak{Z}^*_k$. Using 
(\ref{eq:image_kernel_of_adjoint_in_hilbert_complex}) we can write this as
\begin{align*}
    \mathfrak{H}^k = \mathfrak{Z}^k \cap \mathfrak{B}^{*,\perp}_k
         = \mathfrak{B}^{k,\perp} \cap \mathfrak{Z}^*_k.
\end{align*}
Now we can formulate the most important 
result of this chapter. 

\begin{theorem}[Hodge decomposition]\label{thm:hodge_decomposition}
    Let $d^k: W^k \rightarrow W^{k+1}$ form a Hilbert complex. 
    Then we have
    \begin{align*}
        \mathfrak{Z}^k &= \overline{\mathfrak{B}^k} \stackrel{\perp}{\oplus}
            \mathfrak{H}^k \text{ and}
        \\ \mathfrak{Z}^*_k &= 
            \overline{\mathfrak{B}^*_k} \stackrel{\perp}{\oplus}
            \mathfrak{H}^k.
    \end{align*}
    We obtain the Hodge decomposition of the space $W^k$
    \begin{align*}
        W^k = \overline{\mathfrak{B}^k} \stackrel{\perp}{\oplus}
            \mathfrak{H}^k \stackrel{\perp}{\oplus} \overline{\mathfrak{B}^*_k}.
    \end{align*}
\end{theorem}
\begin{proof}
    Let us first prove $\mathfrak{Z}^k \subseteq 
    \overline{\mathfrak{B}^k} \stackrel{\perp}{\oplus} \mathfrak{H}^k$.
    Take $z \in \mathfrak{Z}^k$ arbitrary. 
    From basic Hilbert theory we know that 
    $W^k = \overline{\mathfrak{B}^k} \stackrel{\perp}{\oplus} 
    \mathfrak{B}^{k,\perp}$. So we find $z = z_1 + z_2$ with
    $z_1 \in \overline{\mathfrak{B}^k}$ and $z_2 \in 
    \mathfrak{B}^{k,\perp}$. 
    Because $\mathfrak{Z}^k$ is closed 
    $z_1 \in \overline{\mathfrak{B}^k} \subseteq \mathfrak{Z}^k$ 
    and thus $z_2 = z - z_1 \in \mathfrak{Z}^k$ as well i.e. $z_2 \in \mathfrak{Z}^k 
    \cap \mathfrak{B}^{k,\perp} = \mathfrak{H}^k$ and so 
    $z \in \overline{\mathfrak{B}^k} \stackrel{\perp}{\oplus}
    \mathfrak{H}^k$. The other inclusion is obvious since 
    $\mathfrak{H} = \mathfrak{B}^{k,\perp} \cap \mathfrak{Z}^k$.
    The proof for the second equality is completely analogous. 

    For the Hodge decomposition, since $\mathfrak{Z}^k$ is closed 
    \begin{align*}
        W^k = \mathfrak{Z}^k \stackrel{\perp}{\oplus} \mathfrak{Z}^{k,\perp}
        =  \overline{\mathfrak{B}^k} \stackrel{\perp}{\oplus}
            \mathfrak{H}^k \stackrel{\perp}{\oplus} \overline{\mathfrak{B}^*_k}.
    \end{align*}
\end{proof}
The Hodge decomposition is a very powerful tool whenever deal with Hilbert
complexes.

\subsubsection{$L^2$ de Rham complex in 3D}
Let us investigate the situation for the differential operators 
$\grad$, $\diver$ and $\curl$. All the necessary ingredients were already 
proven at the end of Sec.\,\ref{sec:unbounded_operators}. 
Let $\Omega$ be a Lipschitz domain of 
$\real^3$. % TBD: Do we really need Lipschitz boundary?

We take $W^0 = W^3 = L^2(\Omega)$ and $W^1 = W^2 = L^2(\Omega;\real^3)$ 
and we set all other $W^k$ to zero in order to obtain a sequence.
Then we choose the operators $d^0 = \grad$, $d^1 = \curl$, $d^2 = \diver$ and
for the domains we choose $V^0 = H^1(\Omega)$, $V^1 = H(\curl;\Omega)$, 
$V^2 = H(\diver;\Omega)$ and $V^3 = L^2(\Omega) = W^3$. 
As before, we will leave out the refernence to the domain $\Omega$ now.
All other 
$d^k$ are just zero. The resulting domain complex is then
\begin{align}
    0 \rightarrow H^1 \xrightarrow{\grad} H(\curl)
        \xrightarrow{\curl} H(\diver) \xrightarrow{\diver} L^2 \rightarrow 0
    \label{eq:primal_de_rham_complex_3d}
\end{align}

All these operators are closed and densely defined. It remains to show that 
$d^{k+1} \circ d^k = 0$. If $k < 0$ or $k>2$ this is clear from the definition. 
Then we have from the definition of these operators 
for any $u \in H^1$ and $\mathbf{v} \in C^\infty_0(\Omega;\real^3)$  
\begin{align*}
    \int_\Omega \curl \grad u \cdot \mathbf{v} \, dx 
    = \int_\Omega \grad u \cdot \curl \mathbf{v} \, dx 
    = \int_\Omega u \, \diver \curl \mathbf{v} \, dx
    = 0
\end{align*}
which implies that $\curl \grad u = 0$. $\diver \curl = 0$ is proven 
completely analogously. So (\ref{eq:primal_de_rham_complex_3d}) is indeed a 
Hilbert complex. 

If $\Omega$ is bounded then the complex is closed i.e. all images 
are closed subspaces which should not be confused with being a closed operator
as explained in the section about unbounded operators. The proof can be found 
in Sec.\,4.3 of the main reference for this section \cite{arnold}.

The resulting dual domain complex is 
\begin{align*}
    0 \leftarrow L^2 \xleftarrow{-\diver} \mathring{H}(\diver)
        \xleftarrow{\curl} \mathring{H}(\curl) 
        \xleftarrow{-\grad} H^1_0 \leftarrow 0.
\end{align*}

For the harmonic elements -- which are scalar and vector fields here -- 
we obtain
\begin{align*}
    \mathfrak{H}^0 &= \{ u \in H^1 \mid \grad u = 0\},
    \\ \mathfrak{H}^1 &= \{ \mathbf{u} \in H(\curl) \cap \mathring{H}(\diver)
        \mid \curl \mathbf{u} = 0, \diver \mathbf{u} = 0\},
    \\ \mathfrak{H}^2 &= \{ \mathbf{u} \in \mathring{H}(\curl) \cap H(\diver)
        \mid \curl \mathbf{u} = 0, \diver \mathbf{u} = 0\} \text{ and}
    \\ \mathfrak{H}^3 &= \{ u \in H^1_0
       \mid \grad u = 0\} = \{0\}.
\end{align*}
For the last equality we used the fact that $\grad u = 0$ implies that 
$u$ is constant almost everywhere with possibly different constants for 
different path components of $\Omega$. But because we have homogeneous boundary 
conditions we get $u=0$. Note that $\mathfrak{H}^1$ and $\mathfrak{H}^2$ 
are very similar. The only difference are the boundary conditions. 
$\mathbf{u} \in \mathfrak{H}^2 \subseteq \mathring{H}(\curl)$ 
means that the generalized tangential 
trace $\gamma_\tau \mathbf{u}$ is zero. If $\mathbf{u}  \in \mathfrak{H}^1 
\subseteq \mathring{H}(\diver)$ 
then the 
generalized normal trace $\gamma_n \mathbf{u}$ vanishes.

This gives us the Hodge decomposition in the 3D case.

\begin{theorem}[Hodge decomposition in 3D]
    Let $\Omega \subseteq \real^3$ be a Lipschitz domain. Then we have the 
    following decompositions of the kernels
    \begin{align*}
        \{ \mathbf{u} \in H(\curl) \mid \curl \mathbf{u} = 0\}
        &= \overline{\grad H^1} \stackrel{\perp}{\oplus} 
            \mathfrak{H}^1
        \\ \{ \mathbf{u} \in H(\diver) \mid \diver \mathbf{u} = 0\}
        &= \overline{\curl H(\curl)} \stackrel{\perp}{\oplus} 
            \mathfrak{H}^2
        \\ \{ \mathbf{u} \in \mathring{H}(\diver) \mid \diver \mathbf{u} = 0\}
        &= \overline{\curl \mathring{H}(\curl)} \stackrel{\perp}{\oplus} 
            \mathfrak{H}^1
        \\ \{ \mathbf{u} \in \mathring{H}(\curl) \mid \curl \mathbf{u} = 0\}
        &= \overline{\diver \mathring{H}(\diver)} \stackrel{\perp}{\oplus} 
            \mathfrak{H}^2.
    \end{align*}
    We can express $L^2$ as
    \begin{align*}
        L^2 &= \overline{\diver \mathring{H}(\diver)} \stackrel{\perp}{\oplus} 
            \{ v \in H^1 \mid \grad v = 0 \}
        \\ &= \overline{\diver H(\diver)}.
    \end{align*}
    and for vector valued functions
    \begin{align*}
        L^2(\Omega;\real^3) &= \overline{\grad H(\grad)} 
            \stackrel{\perp}{\oplus} \mathfrak{H}^1 
            \stackrel{\perp}{\oplus} \overline{\curl \mathring{H}(\curl)} 
        \\ &= \overline{\curl H(\curl)}
            \stackrel{\perp}{\oplus} \mathfrak{H}^2
            \stackrel{\perp}{\oplus} \overline{\grad H^1_0}.
    \end{align*}
\end{theorem}
\begin{proof}
    This is just an application of the general Hodge decomposition 
    Thm.\,\ref{thm:hodge_decomposition} combined with what we derived above.
\end{proof}


\begin{remark}
    Alternatively, we could have chosen the sequence with zero boundary conditions
    as the primal sequence i.e. 
    \begin{align*}
        0 \rightarrow H^1_0 \xrightarrow{\grad} \mathring{H}(\curl)
        \xrightarrow{\curl} \mathring{H}(\diver) 
        \xrightarrow{\diver} L^2 \rightarrow 0
    \end{align*}
    Then we can follow the exact same arguments to get the dual sequence 

    \begin{align*}
        0 \leftarrow L^2 \xleftarrow{-\diver} H(\diver)
            \xleftarrow{\curl} H(\curl) 
            \xleftarrow{-\grad} H^1 \leftarrow 0.
    \end{align*}
\end{remark}


\section{Existence and uniqueness of solutions}\label{sec:existence_and_uniqueness}

In this section, we will apply the developed theory of the preceding chapters
to prove the existence and uniqueness of the magnetostatic problem 
on exterior domains. With exterior domain we mean that our domain $\Omega \subseteq \real^3$
is the complement of a compact set. The main motivation for this problem is 
the special case of $\Omega$ being the complement of a torus. 
This is also the motivation behind the
topological assumption that we will give. It might be useful to keep this
example in mind.

Recall the magnetostatic problem we are studying.

\begin{problem}\label{prob:magnetostatic_problem}
    Find $B \in H_0(\diver;\Omega)$ s.t.
    \begin{align}
        \curl \, B &= 0, \\ 
        \diver \, B  &= 0 \text{ in } \Omega \text{ and }\\
        \int_\gamma B \cdot dl &= C_0.
    \end{align}
\end{problem}

Of course in order for the curve integral constraint to be well-defined 
we need to check the regularity of solutions. Then using the tools we developed
in the previous sections we will proof existence and uniqueness.

\subsection{Regularity of solutions}\label{sec:regularity_of_solutions}

We will rely on standard regularity results about elliptic systems 
of the following form. Take $A_{ij}^{\alpha \beta} \in \real$
for $i$, $j$, $\alpha$, $\beta = 1,2,3$ and 
$A_{ij}^{\alpha \beta} = A_{ji}^{\beta \alpha}$. Then we have systems of the 
form 
\begin{align}
    -\sum\limits_{\alpha, \beta, j} \partial_\alpha 
        (A_{ij}^{\alpha \beta} \partial_\beta B_j)
    = f_i - \sum\limits_\alpha \partial_\alpha F_i^\alpha
    \label{eq:elliptic_system}
\end{align}
with data $f_i, F_i^\alpha \in L^2(\Omega)$. We call this system 
\textit{elliptic} if $A$ satisfies the Legendre condition i.e.
\begin{align}
    \sum_{\alpha,\beta,i,j}A_{ij}^{\alpha \beta} \xi_\alpha^i \xi_\beta^j
    \geq c |\xi|^2, \quad \forall \xi \in \real^{3 \times 3} 
    \label{eq:legendre_condition}
\end{align}
with $c > 0$. $|\xi|$ is here the Frobenius norm, but technically the chosen 
norm is irrelevant due to all norms on $\real^{3 \times 3}$ being equivalent.
We then call $B \in H^1_{loc}(\Omega)^3$ {\color{red} Recall definition 
of $H^k_{loc}$} a weak solution
of (\ref{eq:elliptic_system}) if 
\begin{align}
    \int_\Omega \sum\limits_{\alpha,\beta,i,j} 
        A_{ij}^{\alpha \beta} \partial_\beta B_j \partial_\alpha \varphi_i dx
    = \int_\Omega \left\{ \sum\limits_i f_i \varphi_i + 
        \sum\limits_{\alpha,i} F_i^\alpha \partial_\alpha \varphi_i \right\} dx
    \label{eq:weak_elliptic_system}
\end{align}
for all $\varphi \in C^1_0(\Omega;\real^3)$. This formulation is taken from 
\cite[Sec. 1.3]{lectures_on_elliptic_pdes}. At first we will slightly modify
the notion of weak solution. 

\begin{proposition}\label{prop:weak_solution_smooth_test_functions}
    Assume that we have an elliptic system with constant coefficients i.e. 
    $A$ is constant. Then
    (\ref{eq:weak_elliptic_system}) is fulfilled for all 
    $\varphi \in C^1_0(\Omega;\real^3)$ if and only if it is fulfilled 
    for $\varphi \in C^\infty_0(\Omega;\real^3)$.
\end{proposition}
\begin{proof}
    This follows by a simple density argument. Assume that 
    (\ref{eq:weak_elliptic_system}) is fulfilled for all test functions in 
    $C^\infty_0(\Omega;\real^3)$. Now take $\varphi \in C^1_0(\Omega;\real^3)$
    arbitrary. Because $\varphi \in H_0^1(\Omega)^3$ and 
    $C^\infty_0(\Omega;\real^3)$ is dense in $H_0^1(\Omega)^3$ we can find 
    a sequence $(\varphi^{(l)})_{l \in \naturalnum} \subseteq 
    C^\infty_0(\Omega;\real^3)$ s.t. $\varphi^{(l)} \rightarrow \varphi$
    in $H^1(\Omega)^3$. Thus the partial derivatives converge in $L^2(\Omega)$
    and we get
    \begin{align*}
        &\int_\Omega \sum\limits_{i,j,\alpha,\beta} 
            A_{ij}^{\alpha, \beta} \partial_\beta B_j \partial_\alpha \varphi_i
            dx
        = \sum\limits_{i,j,\alpha,\beta} A_{ij}^{\alpha, \beta}
            \int_\Omega \partial_\beta B_j \lim\limits_{l\rightarrow \infty} 
            \partial_\alpha \varphi^{(l)} dx
        \\ &\stackrel{\text{$L^2$ limit}}{=} 
            \lim\limits_{l\rightarrow \infty} 
            \int_\Omega \left\{ \sum\limits_i f_i \varphi^{(l)}_i + 
            \sum\limits_{\alpha,i} F_i^\alpha \partial_\alpha \varphi^{(l)}_i 
            \right\} dx
        = \int_\Omega \left\{ \sum\limits_i f_i \varphi_i + 
            \sum\limits_{\alpha,i} F_i^\alpha \partial_\alpha \varphi_i 
            \right\} dx.
    \end{align*}
    Since $\varphi \in C_0^1(\Omega;\real^3)$ was arbitrary the first 
    direction of the equivalence is proved. The other direction is trivial.
\end{proof}
So we see that in the case of constant coefficents we can consider 
just smooth compactly supported functions as test functions.

Next, we will state the crucial result about the regularity of elliptic systems
which will give us the desired regularity. This is Theorem 2.13 and Remark 2.16 
in \cite{lectures_on_elliptic_pdes} in slightly less generality.
\begin{theorem}\label{thm:regularity_elliptic_systems}
    Let $\Omega$ be an open domain in $\real^n$. Let $A$ 
    satisfy the Legendre condition (\ref{eq:legendre_condition}). Then for every 
    $B \in H^1_{loc}(\Omega)^3$ weak solution in the sense of
    (\ref{eq:weak_elliptic_system}) with $f \in H^k_{loc}(\Omega)^3$ and 
    $F \in H^{k+1}_{loc}(\Omega;\real^{m\times n})$ 
    we have $B \in H^{k+2}_{loc}(\Omega)^3$. 
\end{theorem}

\begin{corollary}\label{cor:smooth_solution}
    If under the assumptions of the previous theorem we consider the 
    homogeneous problem, i.e.
    \begin{align*}
        \int_\Omega \sum\limits_{\alpha,\beta,i,j} 
        A_{ij}^{\alpha \beta} \partial_\beta B_j \partial_\alpha \varphi_i dx =0
    \end{align*}
    for all $\varphi \in C^\infty_0(\Omega;\real^3)$, then $B\in C^\infty(\Omega)$.
\end{corollary}
\begin{proof}
    Here we have $F= 0$ and $f = 0$. Thus, $f \in H^k_{loc}(\Omega)^3$ 
    for any $k \in \naturalnum$. 
    Take any $Q \subseteq \Omega$ pre-compact. Then we know from 
    Thm.\,\ref{thm:regularity_elliptic_systems}.
    that $B \in H_{loc}^{k+2}(\Omega)^3$ and thus $B \in H^{k+2}(Q)^3$.
    Therefore, we can apply the 
    standard Sobolev embedding theorem locally to get $B \in C^l(Q)$ for any 
    $l \in \naturalnum$ and hence $B \in C^\infty(\Omega)$ since $Q$ pre-compact
    was arbitrary. 
\end{proof}
It should be noted that this does not guarantee us any regularity on the 
boundary. 

Before we can apply this result, we have to check whether a solution of our 
problem $B$ is actually in $H^1_{loc}(\Omega)^3$. 

\begin{theorem}\label{thm:solution_in_H1loc}
    Assume $B \in H(\diver;\Omega) \cap H(\curl;\Omega)$. Then 
    $B \in H^1_{loc}(\Omega)^3$.
\end{theorem}
\noindent Note that we did not assume $B$ to be a solution.
\begin{proof}
    We know that for a function $u \in H_0(\curl;U) \cap H(\diver;U)$ 
    for some smooth domain $U$ we have $u \in H^1(U)^3$ 
    (cf. \cite[Remark 3.48]{monk}). Our $\Omega$ is just assumed to be open 
    so we can not apply this result directly because we have no information
    about the regularity of the boundary $\partial \Omega$.

    Take $Q \subset\subset \Omega$ open and pre-compact. 
    Then we can find an open 
    cover of $\overline{Q}$ with a finite set of open balls $\{K_i\}_{i=1}^N$
    s.t. $K_i \subseteq \Omega$ and 
    \begin{align*}
        \overline{Q} \subseteq \bigcup\limits_{i=1}^N K_i.
    \end{align*}
    As a open cover of a compact set we can find a smooth partition of unity 
    $\{\chi_i\}_{i=1}^N$ subordinate to $\{K_i\}_{i=1}^N$. 
    $(B \chi_i)|_{K_i} \in H_0(\curl;K_i) \cap H(\diver;K_i)$ and thus 
    $(B \chi_i)|_{K_i} \in H^1(K_i)^3$ by the above mentioned result. 
    Also because $B \chi_i$ has compact support in $K_i$ we can extend it by 
    zero to obtain
    $B \chi_i \in H^1(\real^3)^3$ where we abused the notation by denoting 
    the extension the same. Whence,
    \begin{align*}
        B|_Q = \large( \sum\limits_{i=1}^N \chi_i |_Q \large) B|_Q = 
        \sum\limits_{i=1}^N (\chi_i B)|_Q \in H^1(Q)
    \end{align*}
    i.e. $B \in H^1_{loc}(\Omega)^3$.
\end{proof}

The following lemma is a reformulation of the differential operator 
$\grad \diver - \curl \curl$ which will be needed when we write our 
magnetostatic problem in the above standard elliptic form.

\begin{lemma}\label{lem:graddiv_curlcurl_equals_componentwise_laplacian}
    Let $F \in H^2_{loc}(\Omega)^3$. Then 
    \begin{align*}
        \grad \diver F - \curl \curl F 
        = \begin{pmatrix} \Delta F_1 \\ \Delta F_2 
            \\ \Delta F_3  \end{pmatrix}.
    \end{align*}
\end{lemma}
\begin{proof}
    By a simple calculation and changing the order of differentiation
    \begin{align*}
        \grad \diver F = 
            \begin{pmatrix} \partial_1^2 F_1 + \partial_1 \partial_2 F_2
                + \partial_1 \partial_3 F_3
            \\ \partial_1\partial_2 F_2 + \partial_2^2 F_2 + 
                \partial_2\partial_3 F_3
            \\ \partial_1 \partial_3 F_1 + \partial_2\partial_3 F_2
                + \partial_3^2 F_3
            \end{pmatrix}
    \end{align*}
    and 
    \begin{align*}
        &\curl \curl F = \curl \begin{pmatrix} 
            \partial_2 F_3 - \partial_3 F_2 \\ \partial_3 F_1 - \partial_1 F_3 
            \\ \partial_1 F_2 - \partial_2 F_1  \end{pmatrix}
        = \begin{pmatrix} 
            \partial_2 (\partial_1 F_2 - \partial_2 F_1)
                - \partial_3 (\partial_3 F_1 - \partial_1 F_3)
            \\ \partial_3 (\partial_2 F_3 - \partial_3 F_2)
                - \partial_1 (\partial_1 F_2 - \partial_2 F_1)
            \\ \partial_1 (\partial_3 F_1 - \partial_1 F_3)
                - \partial_2 (\partial_2 F_3 - \partial_3 F_2)  
            \end{pmatrix}
        \\ &= \begin{pmatrix}
            \partial_1 \partial_2 F_2 - \partial^2_2 F_1 - \partial_3^2 F_1
            + \partial_1 \partial_3 F_3 
            \\ \partial_2 \partial_3 F_3 - \partial^2_3 F_2 - \partial_1^2 F_2
            + \partial_1 \partial_2 F_3
            \\ \partial_1 \partial_3 F_3 - \partial^2_3 F_2 - \partial_2^2 F_3
            + \partial_2 \partial_3 F_2  
            \end{pmatrix}
    \end{align*}
    and so by subtracting the two expressions
    \begin{align*}
        \grad \diver F - \curl \curl F  
        = \begin{pmatrix}
            \partial_1^2 F_1 + \partial_2^2 F_1 + \partial_3^2 F_1
            \\ \partial_1^2 F_2 + \partial_2^2 F_2 + \partial_3^2 F_3
            \\ \partial_1^2 F_3 + \partial_2^2 F_3 + \partial_3^2 F_3
        \end{pmatrix}
        = \begin{pmatrix}
            \Delta F_1 \\ \Delta F_2 \\ \Delta F_3
        \end{pmatrix}.
    \end{align*}
\end{proof}
We want to rewrite this system in the expression of the elliptic system 
(\ref{eq:elliptic_system}). We can rewrite the Laplacian
\begin{align*}
    - \Delta F_i = - \sum\limits_{\alpha = 1}^3 
        \partial_\alpha \partial_\alpha F_i
    = - \sum\limits_{\alpha,\beta = 1}^3 
    \partial_\alpha \delta_{\alpha,\beta} \partial_\beta F_i
    = - \sum\limits_{\alpha,\beta,j = 1}^3 
    \partial_\alpha \delta_{\alpha,\beta} \delta_{ij} \partial_\beta F_j
\end{align*}
so we get $A_{ij}^{\alpha\beta} = \delta_{ij} \delta_{\alpha \beta}$.
We have to check that the resulting differential operator is indeed
elliptic, but this trivial because for any 
$(\xi_\alpha^i)_{1\leq i,\alpha \leq 3}$
we get 
\begin{align*}
    \sum\limits_{\alpha,\beta,i,j} A_{ij}^{\alpha\beta} \xi_\alpha^i \xi_\beta^j 
    = \sum\limits_{\alpha,\beta,i,j} \delta_{ij} \delta_{\alpha \beta} 
        \xi_\alpha^i \xi_\beta^j 
    = \sum\limits_{\alpha,i} (\xi_\alpha^i)^2 = |\xi|^2
\end{align*}
so  the Legendre condition (\ref{eq:legendre_condition}) 
is fulfilled and the resulting system is elliptic. The weak formulation 
is 
\begin{align*}
    \int_\Omega \sum\limits_{\alpha,\beta,i,j} \delta_{ij} \delta_{\alpha\beta}
        \partial_\beta B_j \partial_\alpha \varphi_i dx 
    = \sum\limits_{i=1}^3 \int_\Omega \nabla B_i \cdot \nabla \varphi_i dx.
\end{align*}
Here we can assume $\varphi \in C_0^\infty (\Omega)^3$
due to Prop.\,\ref{prop:weak_solution_smooth_test_functions}.

\begin{theorem}[Smoothness of solutions]\label{thm:smoothness_of_solutions}
    Let $\Omega \subseteq \real^3$ open and 
    $B \in H(\diver;\Omega) \cup H(\curl;\Omega)$ and 
    \begin{align*}
        \curl B &= 0,
        \\ \diver B &= 0.
    \end{align*}
    Then $B$ is smooth.
\end{theorem}
\begin{proof}
    Take $\varphi \in C_0^\infty(\Omega)^3$. Then 
    \begin{align*}
        0 &= \int_\Omega \diver B \diver \varphi + \curl B \cdot \curl \varphi dx
        = - \int_\Omega B \cdot (\grad \diver \varphi - \curl \curl \varphi) dx
        \\ &\stackrel{Lemma 
            \ref{lem:graddiv_curlcurl_equals_componentwise_laplacian}}{=} 
            - \int_\Omega B \cdot 
            \begin{pmatrix}
                \Delta \varphi_1 \\ \Delta \varphi_2 \\ \Delta \varphi_3
            \end{pmatrix}
        = \sum\limits_{i=1}^3 \int_\Omega \nabla B_i \cdot \nabla \varphi_i dx.
    \end{align*}
    Note that the last integration by parts is well defined because 
    $B \in H^1_{loc}(\Omega)$ according to Thm.\,\ref{thm:solution_in_H1loc}. 
    So $B$ is a weak solution 
    of the elliptic system given by 
    $A_{ij}^{\alpha \beta} = \delta_{ij} \delta_{\alpha\beta}$. Because 
    we look at the homogenous problem our right hand side is obviously smooth 
    and thus $B$ is smooth as well due to Cor.\,\ref{cor:smooth_solution}.
\end{proof}

\begin{remark}
    Obviously, the above arguments can be generalized by using a 
    non-zero right hand side of our problem. Then we will in general 
    not obtain a smooth solution, but for a sufficiently regular right hand 
    side the curve integral would still be well-defined.
    {\color{red} How much regularity? Source?}
\end{remark}



\subsection{Existence and uniqueness}

The curve integral condition is closely linked to the topology of our domain 
which we will have to use in our proof.
This will rely on the tools of homology from Sec.\,\ref{sec:singular_homology}. 
Because of this connection if we want the curve integral
to give us uniqueness of the solution we need to assume certain topological 
properties. In our case, this will be the condition that our first 
homology group is generated by the curve that we are integrating over i.e.
\begin{align*}
    H_1(\Omega) = \integers [\gamma].
\end{align*}

Then we get the following existence and uniqueness result on the 
level of homology.

\begin{proposition}\label{prop:uniqueness_cochain}
    Assume that $H_1(\Omega) = \integers [\gamma]$ i.e. the homology 
    class of the 
    closed $1$-chain $\gamma$ is a generator of the first homology group.
    Then we have the following:
    \begin{enumerate}[(i)]
        \item For any $C_0 \in \real$ there exists a closed $1$-cochain 
            $F \in Z^1(\Omega)$ with $F(\gamma) = C_0$,
        \item any other $G \in Z^1(\Omega)$ with $G(\gamma) = C_0$ 
            is in the same cohomology class i.e. $[F] = [G]$
    \end{enumerate}
    i.e. the cochain is unique up to cohomology.
\end{proposition}
\begin{proof}
    \textbf{Proof of (i)} %TBD: This could be wrong
    Because $[\gamma]$ is a generator of the homology group we  obtain a 
    homomorphism $\hat{F} \in \text{Hom}(H_1(\Omega),\real)$ by fixing
    $\hat{F}([\gamma]) = C_0$. Note that $H^1(\Omega)$ is an abuse of notation 
    because we mean here the first cohomology group of $\Omega$ and not the 
    Sobolev space. In the context of singular homology this will always be the
    case.
    
    This determines the other values.
    Recall the isomorphism $\beta : H^1(\Omega) \rightarrow 
    \text{Hom}(H_1(\Omega);\real)$ from the universal coefficent theorem 
    (\ref{eq:univeral_coefficient_theorem}), $\beta([F]) = \tilde{F}$ 
    where $F$ and $\tilde{F}$ are in the same cohomology class.
    Then we know that there exists
    a $[F] \in H^1(\Omega)$ with $\beta([F]) = \hat{F}$ because $\beta$ is a 
    isomorphism. So we obtain
    \begin{align*}
        F(\gamma) = \beta([F])([\gamma]) = \hat{F}([\gamma]) = C_0.
    \end{align*}

    \textbf{Proof of (ii)} %TBD: This could be wrong
    Take $[c] \in H_1(\Omega)$ arbitrary. 
    Then there exists  $n \in \integers$ s.t.
    $[c] = n [\gamma]$.
    Using $\beta$ from (\ref{eq:univeral_coefficient_theorem})
    We have
    \begin{align*}
        \beta([F])([c]) = \beta([F])(n [\gamma]) 
        = n \beta([F])([\gamma]) = n \, F(\gamma) = n \, G(\gamma) = 
        \beta([G])([c])
    \end{align*}
    and thus $\beta([F]) = \beta([G])$. Because $\beta$ is an isomorphism
    we arrive at $[F] = [G]$.
\end{proof}
This abstract topological result can now be linked to the differential 
forms via the de Rham isomorphism from Sec.\,\ref{sec:de_rhams_theorem}. 
We will formulate it in a way 
that demonstrates the connection of differential forms and cochains.
\begin{corollary}\label{cor:existence_uniqueness_1form}
    Assume $H_1(\Omega) = \integers [\gamma]$ as above. Then
    \begin{enumerate}[(i)]
        \item For any $C_0 \in \real$ there exists a closed smooth $1$-form 
            $\theta \in \mathfrak{Z}^1(\Omega)$ with 
            \begin{align*}
                I(\theta)(\gamma) = \int_\gamma \theta = C_0
            \end{align*}
        \item any other $\eta \in \mathfrak{Z}^1(\Omega)$ with 
            \begin{align*}
                I(\eta)(\gamma) = \int_\gamma \eta = C_0
            \end{align*}
            is in the same cohomology class of $H_{dR}^1(\Omega)$ 
            i.e. $[\eta] = [\theta]$.
    \end{enumerate}
\end{corollary}

% TBD: Define de Rham cohomology
\begin{proof}
    \textbf{Proof of (i)}
    Recall from Sec.\,\ref{sec:de_rhams_theorem} 
    that the integration of differential forms 
    over chains induces an isomorphism on cohomology 
    $[I]: H_{dR}^1(\Omega) \rightarrow H^1(\Omega)$ which we call 
    de Rham isomorphism. We know from 
    Prop.\,\ref{prop:uniqueness_cochain} that there exists $F\in H^1(\Omega)$ 
    s.t. $F(\gamma) = C_0$. The surjectivity of the de Rham isomorphism 
    now gives us $[\theta] \in H^1(\Omega)$ s.t.
    \begin{align*}
        [I(\theta)] = [I]([\theta]) = [F]
    \end{align*}
    i.e.
    \begin{align*}
        I(\theta) = F + \partial^0 J
    \end{align*}
    with $J \in C^0$. Then, 
    \begin{align*}
        I(\theta)(\gamma) = F(\gamma) + \partial^0 J(\gamma) 
        = C_0 + J(\partial_1 \gamma) 
        \stackrel{\text{$\gamma$ closed}}{=} C_0. 
    \end{align*}
    \textbf{Proof of (ii)}
    We have $I(\eta)$ is a $1$-cochain with $I(\eta)(\gamma) = C_0$.
    Thus, we can apply Prop.\,\ref{prop:uniqueness_cochain} to get
    \begin{align*}
        [I](\eta)=[I(\eta)] = [I(\theta)]=[I](\theta).
    \end{align*}
    Because $[I]$ is an isomorphism we can conclude $[\eta] = [\theta]$.
\end{proof}

\begin{theorem}[Existence of solution]\label{thm:existence}
    Let $\Omega \subseteq \real^3$ be such that $\real^3 \setminus \Omega$
    is compact. 
    For the topology, we require that $H_1(\Omega) = \integers [\gamma]$ 
    for a $1$-chain 
    $\gamma$. Assume further that there exists an $\epsilon$-neighborhood 
    \begin{align*}
        \Omega_\epsilon \vcentcolon= \{ x \in \real^3 \mid
            d(x,\Omega) < \epsilon \} 
    \end{align*}
    s.t. $H_1(\Omega_\epsilon) = \integers [\gamma]$ as well.
    Then there exists a solution 
    to Problem \ref{prob:magnetostatic_problem}.
\end{theorem}
Let us say a view words about the topological assumption 
regarding $\Omega_\epsilon$. This just means that we can slightly increase 
the domain without changing the first homology group. As an example, 
think again of a torus in $\real^3$. Assuming the torus has non-empty interior 
we can slightly reduce the poloidal radius without changing the topology of its 
 exterior domain.
\begin{proof}
    At first we want to find a smooth differential $1$-form 
    $\theta \in C^\infty\Lambda^1(\Omega)$ with the desired curve integral. 
    In order to do that we will increase the 
    domain slightly.
    We start by referring to Cor.\,\ref{cor:existence_uniqueness_1form} 
    to get a smooth differential form 
    $\tilde{\theta} \in \Lambda^1(\Omega_\epsilon)$ with 
    \begin{align}
        \int_\gamma \tilde{\theta} = C_0. \label{eq:integral_theta_tilde}
    \end{align}
    We now refer back to Sec.\,\ref{sec:differential_forms} 
    and change back to vector proxies. Let 
    $\tilde{\phi}$ be the vector proxy of $\tilde{\theta}$ 
    i.e. by recalling the musical isomorphism \ref{}
     $\tilde{\theta}^\sharp = \tilde{\phi} \in C^\infty(\tilde{\Omega})^3$.
    Because $\tilde{\theta}$ is closed and (\ref{eq:integral_theta_tilde}) holds
    we obtain the corresponding properties 
    of $\tilde{\phi}$ which are 
    \begin{align*}
        \int_\gamma \tilde{\phi} \cdot dl &= C_0 
        \\ \curl \tilde{\phi} &= 0.
    \end{align*}
    We define $\phi$ by restricting $\tilde{\phi}$ to $\Omega$. 
    Let now $K_R$ be the open ball around the origin with radius $R>0$ large
    enough s.t. $\Omega^c \subseteq K_R$ and $\gamma \subseteq K_R$. 
    We now restrict $\theta$ further to
    $\Omega_R \vcentcolon= \Omega \cap K_R$. We denote the restriction with 
    $\phi_R \vcentcolon= \phi|_{\Omega_R}$. 

    We now need to construct a harmonic vector field with zero tangential trace
    s.t. we can extend it by zero. We do this by using the Hodge 
    decomposition for $1$-forms on $\Omega_R$ in the $3$D case \ref{}.
    We project $\phi_R$ onto the harmonic fields to obtain $B_R$ which has zero 
    tangential trace. So there exists a sequence 
    $(\psi_i)_{i \in \naturalnum} \in H^1(\Omega_R)$ s.t.
    \begin{align*}
        B_R = \phi_R - \lim\limits_{i\rightarrow \infty}\nabla \psi_i
    \end{align*}
    We also know that $B_R$ is smooth because 
    it is curl and divergence free from Thm.\ref{thm:smoothness_of_solutions}. 
    We want to check that the curve
    integral did not change. We know from \ref{} that the 
    image of the exterior derivative is closed on bounded domains. 
    Formulated in vector proxies, this
    means that $\nabla H^1(U)$ is closed in $L^2$ if $U$ is a bounded domain. 
    So we get that 
    \begin{align*}
        \lim\limits_{i\rightarrow \infty}\nabla \psi_i = \nabla \psi_R
    \end{align*}
    with $\psi_R \in H^1(\Omega_R)$. Because $B_R$ and $\phi_R$ are smooth
    $\psi_R$ must be smooth as well and so we have   
    \begin{align*}
        \int_\gamma B_R\cdot dl = \int_\gamma \phi_R\cdot dl.
    \end{align*}
    Now extend $B_R$ by zero onto $\real^3 \setminus K_R$.
    Denote this extension as $\overline{B}_R$.
    Because $B_R$ has tangential trace zero and is curl-free its extension 
    $\overline{B}_R \in H(\curl;\Omega)$ and is also curl-free. 
    Here it is important to remember 
    that $\real^3 \setminus K_R \subseteq \Omega$. 
    That means of course that $\overline{B}_R$ 
    might not be smooth on $\partial K_R$ 
    as it might have a jump. 
    Now we can once again use the Hodge 
    decomposition of two forms. This time on the whole domain $\Omega$ to find 
    a harmonic field $B$ and a sequence $(\rho_i)_{i\in \naturalnum}$
    s.t.
    \begin{align*}
        \overline{B_R} = B 
            +\lim\limits_{i\rightarrow \infty}\nabla \rho_i
    \end{align*}
    since $\curl \overline{B_R} = 0$.
    Notice that because $B$ is a harmonic vector field 
    and because it is the vector 
    proxy of a harmonic $2$-form it already satisfies 
    the Neumann boundary condition and it is divergence as well as curl free.
    That means $B$ is a solution if the curve integral condition is satisfied.
    In order to see this, note that we have on $K_R$
    \begin{align*}
        B_R = B|_{K_R} +\lim\limits_{i\rightarrow \infty}\nabla \rho_i|_{K_R}.
    \end{align*}
    Because the image of the gradient is closed on bounded domains 
    we have $\rho_R \in H^1(K_R)$ s.t.
    \begin{align*}
        B_R = B|_{K_R} + \nabla \rho_R.
    \end{align*}
    With the same argument as above, $\rho_R$ must be smooth and so
    \begin{align*}
        \int_\gamma B \cdot dl =  \int_\gamma B|_{K_R} \cdot dl 
        =  \int_\gamma B_R \cdot dl = C_0
    \end{align*}
    and thus $B$ is indeed a solution.
\end{proof}

In the proof of uniqueness we will use the following lemma. 
\begin{lemma}\label{lem:gradient_sequence}
    Let $\phi \in L^2_{loc}(\Omega_\epsilon)$ 
    with $\nabla \phi \in L^2(\Omega)^3$. Then 
    there exists a sequence $(\phi_i)_{i \in \naturalnum} \subseteq H^1(\Omega)$
    s.t. $\nabla \phi_i \rightarrow \nabla \phi$ in $L^2(\Omega)^3$.
\end{lemma}
\begin{proof}
    Take $K_R$ the open ball around the origin with $R$ large enough 
    s.t. $(K_R)^c \subseteq \Omega$. 
    Define $\Omega_R \vcentcolon= K_R \cap \Omega$. Then 
    $\overline{\Omega}_R \subseteq K_{R+1}$, where $K_{R+1}$ is the open ball 
    around the origin with radius $R+1$, $\Omega_R$ is a Lipschitz 
    domain and $K_{R+1}$ is pre-compact and
    $\phi|_{\Omega_R} \in W^{1,2}(\Omega_R)$. 
    Note that here we need the fact that $\phi \in L^2_{loc}(\Omega_\epsilon)$
    because then $\Omega_R$ is pre-compact in $\Omega_\epsilon$. 
    Therefore we can find an extension
    $E\phi \in W_0^{1,2}(\Omega_{R+1}) \hookrightarrow W^{1,2}(\mathbb{R}^3)$
    (cf. \cite[Sec.\,1.5.1]{mazya}). So we can now define
    \begin{align*}
    \bar{\phi} \vcentcolon=
    \begin{cases}
        \phi & \mbox{in $\Omega$}\\
        E\phi & \mbox{in $\Omega^c$.}\\
    \end{cases}
    \end{align*}
    Then $\bar{\phi} \in L^2_{loc}(\real^3)$ and 
    $\nabla \bar{\phi} \in L^2(\real^3)^3$. 
    Then there exists a sequence 
    $(\phi_l) _{l \in \naturalnum} \subseteq C^\infty_0(\real^3)$ s.t.
    $\nabla \phi_l \rightarrow \nabla \bar{\phi}$ in $L^2(\real^3)^3$ 
    (cf. \cite[Lemma 1.1]{simader}). By restricting $\phi_l$ to $\Omega$ 
    we obtain the result.
\end{proof}


\begin{theorem}
    Let the same assumptions hold as in Thm.\,\ref{thm:existence}.
    Then the solution of the problem is unique.
\end{theorem}

\begin{proof}
    Let $B$ and $\tilde{B}$ both be solutions and denote with $\omega$ 
    and $\tilde{\omega}$ the corresponding $1$-forms i.e. $\omega =
    B^\flat$ and $\tilde{\omega} = \tilde{B}^\flat$. 
    So we have $I(\omega)(\gamma) = I(\tilde{\omega})(\gamma) = C_0$
    since 
    \begin{align*}
        \int_\gamma \omega = \int_\gamma B^\flat = 
        \int_\gamma B \cdot dl = \int_\gamma \tilde{B}\cdot dl 
        = \int_\gamma \tilde{B}^\flat = \int_\gamma \tilde{\omega}
    \end{align*}

    Then we know from Cor.\,\ref{cor:existence_uniqueness_1form} 
    that $\omega$ and $\tilde{\omega}$ are in the 
    same cohomology class in $H^1_{dR}$. So there exists a $0$-form i.e. 
    $\mu \in C^\infty(\Omega)$ s.t. $\omega - \tilde{\omega} = d\mu$.
    By applying $^\sharp$ on both sides
    \begin{align*}
        B - \tilde{B} 
        = \omega^\sharp - \tilde{\omega}^\sharp
        = (d\mu)^\sharp = \grad \mu.
    \end{align*}
    However, $\mu$ need not be in $L^2$ since $\Omega$ is unbounded.
    But we know that $\grad \mu \in L^2(\Omega)^3$ and 
    $\mu \in L^2_{loc}(\Omega)$. 
    Here we can now apply Lemma \ref{lem:gradient_sequence} and conclude
    \begin{align*}
        B - \tilde{B} \in \overline{\grad H^1(\Omega)}.
    \end{align*}
    Now remembering the Hodge decomposition in the 3D case we know 
    \begin{align*}
        B - \tilde{B} \in \overline{\grad H^1(\Omega)}^\perp
    \end{align*}
    as well and thus $B = \tilde{B}$ which concludes the proof of uniqueness.
\end{proof}


% \begin{proof}
%     Let $\omega, \tilde{\omega}$ both be solutions. 
%     Because  $*\omega$ and
%     $*\tilde{\omega}$ are closed the cochains 
%     $c\mapsto \int_c \rop*\omega$ and 
%     $c\mapsto \int_c \rop*\tilde{\omega}$ are closed.
    
%     Due to $\int_\gamma \rop *\omega = \int_\gamma \rop *\tilde{\omega}$ and the 
%     assumption that $[\gamma]$ spans the homology space we have with 
%     Prop.\,\ref{uniqueness_cochain} 
%     $[I(\rop *\omega)] = [I(\rop *\tilde{\omega})]$
%     and because $[I]$ is an isomorphism 
%     $[\rop *\omega] = [\rop *\tilde{\omega}]$. Hence,
%     \begin{align*}
%     [*\tilde{\omega}] = [\rop *\tilde{\omega}] = 
%     [\rop *\omega] = [*\omega].
%     \end{align*}
%     That is equivalent to the
%     existence of some $0$-form $\phi \in H^0(d)$ s.t.
%     $*\omega = *\tilde{\omega} + d\phi$. We continue by applying the Hodge
%     star operator to both sides and use the definition of the codifferential 
%     $\delta$:
%     \begin{align*}
%         \omega = \tilde{\omega} + *d\phi = \tilde{\omega} + *d**\phi 
%         = \tilde{\omega} + (-1)^{(n-k)(k-1)+1}\delta * \phi.
%     \end{align*}
%     Then because $\omega$ and 
%     $\tilde{\omega}$ are harmonic we have 
%     $\omega, \tilde{\omega} \perp \delta H^{3}(\delta)$ and therefore 
%     \begin{align*}
%     \omega = \tilde{\omega}.    
%     \end{align*}
% \end{proof}
% If we now translate this back to standard vector calculus terms we have found 
% the unique solution of the homogeneous magnetostatic on our domain $\Omega$.

% \section{Application: Homogeneous magnetostatic problem on the 
% exterior domain of a torus}

% As an application of this general boundary value problem we will have a look
% at the following magnetostatic problem. Let $\Omega$ be the exterior domain of
% a triangulated torus i.e. $\real^3 \setminus \Omega$ is a torus with 
% triangulated surface. Let $B$ be the magnetic field. We then have the following
% boundary value problem:
% %%%TBD: Include a picture
% It is natural to identify the magnetic field $B$ with a 2-form $\omega$.
% Then the exterior derivative is $d\omega$ corresponds to the divergence,
% the codifferential $\delta$ corresponds to the curl and the normal component
% being zero is corresponds to $\omega \in \mathring{W}^2_2(\Omega)$.\cite{}. 
% The curve integral is an integration over a one-dimensional manifold and
% corresponds therefore to the integration of a one-form. Therefore the
% condition \ref{curve_integral_contition} is can be expressed with the hodge 
% star operator $*$ as
% \begin{align*}
%     \int_\gamma *\omega = C_0.
% \end{align*}


% Now we want to apply our previous results.
% $\Omega$ fulfills all required assumptions for the domain. Because $\gamma$
% goes around the torus once and the homology space $H^1_c$ is one-dimensional
% {\color{red}(TBD: This has to be referenced or proven)}. Therefore because 
% $\gamma$ is not a boundary $[\gamma]$ spans $H^1_c$. Now all assumptions are
% fulfilled and we can apply our result. We will do so on 1-forms and transfer the
% result to 2-forms using the Hodge star operator.

% \subsection*{Existence}
% Let 
% $\tilde{\omega} \in \mathring{W}^1_2(\Omega) $ be the unique solution of our 
% general problem \ref{} and define $\omega \vcentcolon= *\tilde{\omega}$. Then
% we use $**=(-1)^{k(n-k)}\tilde{\omega} = \tilde{\omega}$ \cite[p.66]{arnold} 
% to get 
% \begin{align*}
%     d\omega = ** d*\tilde{\omega} = * (-1)^{n(k-1)+1} \delta \tilde{\omega}
%     = 0
% \end{align*}
% and
% \begin{align*}
%     \delta \omega = (-1)^{n(k-1)+1} *d*\omega = (-1)^{n(k-1)+1}* d\tilde{omega}
%     = 0.
% \end{align*}



%%% TBD: Nowaczyk's thesis is not a master's thesis
\printbibliography
\end{document}