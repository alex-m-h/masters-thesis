\documentclass[../master_thesis.tex]{subfiles}
\begin{document}
\section{Variational formulation of the magnetostatic problem in 2D}

For simplicity we will now turn to the 2D case and we assume that 
our open domain will be bounded and Lipschitz. This involves to introduce 
a different Hilbert complex with other differential operators. Then we 
derive the 2D magnetostatic problem from the three-dimensional one. 
We will assume our domain $\Omega$ to have a "annulus like" form which we 
will clarify in more rigour. In order for the 2D magnetostatic problem to be well-posed 
we require an additional constraint that will again be a curve integral. 
We will investigate an alternative way to represent this curve integral 
which will turn out to be easily suitable to be included in our numerical 
approximation.

\subsection{The $\veccurl$-$\diver$ Hilbert complex}

We start with the introduction of the relevant differential operators and 
the resulting 2D Hilbert complex. We will then explain what domains we will consider 
and state the magnetostatic problem in strong form.

We define the scalar curl for $\mathbf{v} \in C^1(\Omega;\real^2)$ as
\begin{align*}
    \curl \mathbf{v} = \partial_1 v_2 - \partial_2 v_1.
\end{align*}
Additionally, we have the vector-valued curl, denoted in bold, defined 
for $v \in C^1(\Omega)$
\begin{align*}
    \veccurl v = \begin{pmatrix}\partial_2 v \\ -\partial_1 v    \end{pmatrix}.
\end{align*}
The cross product for 2D reads for $\mathbf{a}, \mathbf{b} \in \real^2$,
\begin{align*}
    \mathbf{a} \times \mathbf{b} \vcentcolon= a_1 b_2- a_2 b_1.
\end{align*}

A straightforward calculation shows that the following integration-by-parts formula 
holds for $u \in C^1(\overline{\Omega})$, $\mathbf{v} \in C^1(\overline{\Omega};\real^2)$,
assuming $\Omega$ is Lipschitz and bounded
\begin{align}
    \int_\Omega \veccurl u \cdot \mathbf{v} \,dx 
    = \int_\Omega u \, \curl \mathbf{v} \, dx + \int_{\partial \Omega} u\, \mathbf{v} \times \mathbf{n} \, d\ell
    \label{eq:2D_integration_by_parts_curl}
\end{align}
where $\mathbf{n}$ is the outward unit normal of $\Omega$.
Analogous to what we did in Sec.\,\ref{sec:adjoints_differential_operators_3d} 
we can now extend this definition in the weak sense.
First, notice that $\veccurl u = R_{-\pi/2} \grad u$ and thus $\veccurl$ is well-defined 
on $H^1$. For the scalar curl we define 
\begin{align*}
    H(\curl;\Omega) = \{ \mathbf{v} \in L^2 \mid \exists  w \in L^2: 
        \int_\Omega w \phi \, dx = \int_\Omega \mathbf{v} \cdot \veccurl \phi \, dx 
        \quad \forall \phi \in C_0^\infty \}
\end{align*}
and we call denote $w$ in the definition -- which is uniquely determined -- 
as $\curl \mathbf{v}$, so in short
$(\curl, H(\curl)) = (\veccurl, C_0^\infty)^*$. 
Analogous to Section\,\ref{}, it is then possible to extend the 
tangential trace to an operator $\gamma_\tau$ defined on $H(\curl)$ s.t. 
for any $u\in H^1(\Omega)$, $\mathbf{v} \in H(\curl)$
the integration by parts formula
\begin{align*}
    \langle \veccurl u, \mathbf{v} \rangle = \langle  u, \curl \mathbf{v} \rangle 
        + \langle \gamma_\tau \mathbf{v} , \tr u \rangle_{H^{-1/2}(\partial \Omega)\times H^{1/2}(\partial \Omega)}.
\end{align*}
holds. From now on we will leave out the subindex of the duality inner product. Also analogous to the 3D case,
we can define 
\begin{align*}
    H_0(\curl) \vcentcolon= \{ \mathbf{v} \in H(\curl) \mid \gamma_\tau \mathbf{v} = 0\}
\end{align*}
and can then compute the adjoints -- analogous to what we did in \ref{}
\begin{align*}
    (\curl, H_0(\curl)) & = (\veccurl, H^1)^* 
    \\ (\curl, H(\curl)) & = (\veccurl, H_0^1)^*.
\end{align*}

Notice that $\diver \veccurl = 0$ and so 
we have the following 2D Hilbert complex 
\begin{align*}
    H^1_0 \xrightarrow{\veccurl} H_0(\diver) \xrightarrow{\diver} L^2.
\end{align*}
and the dual complex
\begin{align*}
    L^2 \xleftarrow{\curl} H(\curl) \xleftarrow{-\grad} H^1
\end{align*}
We use the notation introduced in Sec.\,\ref{sec:hilbert_complexes} for general Hilbert complexes i.e.
$V^0 = H^1_0$, $V^1= H_0(\diver)$, $V^*_1 = H(\curl)$ and 
$d^0 = \veccurl$ and $d^1 = \diver$. Also we remind of 
the notation $\mathfrak{B}^k$ for the image of the differential operator, $\mathfrak{B}^*_k$ 
for the image of the adjoint and analogous $\mathfrak{Z}^k$ for the kernel.

\subsection{Strong formulation of the 2D magnetostatic problem}

The 2D magnetostatic problem will be derived from a special case of the 3D problem.
Then the type of domains considered will be clarified and the strong formulation 
stated at the end.

Assume that our current source 
$\mathbf{J}$ is pointing in $z$-direction i.e. $\mathbf{J} = J \mathbf{e}_z$. 
Further assume that there is a $\tilde{\Omega}$ s.t. 
$\Omega = \tilde{\Omega} \times \real$. Due to symmetry we can then assume
further that $B_3$ does not change in $z$-direction which implies that 
\begin{align*}
    0 = \diver \mathbf{B} = \partial_x B_1 + \partial_y B_2 = \diver \tilde{\mathbf{B}}.
\end{align*}
where $\tilde{\mathbf{B}} = (B_1,B_2)^\top$. The third component of the equation
$\curl \mathbf{B} = \mathbf{J}$ from the magnetostatic problem reads 
\begin{align*}
    J = \partial_x B_2 - \partial_y B_1 = \curl \tilde{\mathbf{B}}
\end{align*}
For $\Omega$ the unit outer normal is zero in $z$-direction and thus $\tilde{\mathbf{B}}$ 
satisfies the boundary 
condition
\begin{align*}
    0 = \mathbf{B} \cdot \mathbf{n} = \tilde{\mathbf{B}} \cdot \tilde{\mathbf{n}}
\end{align*}
with $\tilde{\mathbf{n}} = (n_1, n_2)^\top$ being the outer unit normal 
$\tilde{\Omega}$. 

Now we will abuse notation and refer to $\tilde{\mathbf{B}}$ as $\mathbf{B}$, 
$\tilde{\mathbf{n}}$ as $\mathbf{n}$ and $\tilde{\Omega}$ as $\Omega$.
Let $J \in L^2$ be given. Then we see that $\mathbf{B}$ must fulfill the 
following equations
\begin{align*}
    \curl \mathbf{B} &= J,
    \\ \diver \mathbf{B} &= 0.
\end{align*}
Depending on the domain, this problem is in general not well-posed -- just as the problem in 3D -- 
and requires an additional constraint. Let us now make certain restrictions 
on what type of domain we will consider. 

From now on, we assume that the space of harmonic forms $\mathfrak{H}^1$ has dimension 
one and that our domain is encompassed by two disjoint closed curves (cf. Fig.\ref{})
i.e. we have curves $\partial \Omega_{in}$ and $\partial \Omega_{out}$ s.t. 
$\partial \Omega_{in} \dot\cup \partial\Omega_{out}$ is the boundary of $\Omega$. 
Let now $\Gamma$ be s.t. it is a closed curve in $\Omega$ that goes around the 
hole in the middle i.e. the area surrounded by $\Gamma$ contains $\partial \Omega_{in}$.
Denote its parametrization with $\bm{\gamma}:[0,|\Gamma|] \rightarrow \Omega$ s.t. 
$|\bm{\gamma}'(t)| = 1$ and assume that $\bm{\gamma}$ is bijective i.e. the curve does not 
intersect itself. We assume that $\Gamma$ has positive distance from 
$\partial \Omega_{in}$. We do not assume anything like that for the exterior boundary 
i.e. $\Gamma$ can touch or be identical to $\partial \Omega_{out}$. 
We then denote the area that is enclosed by $\Gamma$ and
$\partial\Omega_{in}$ as $\Omega_\Gamma$. 

\begin{figure}
    \centering
    \resizebox{8cm}{8cm}{
    \begin{tikzpicture}
    \draw[fill=lightgray] (0,0) circle [radius=5];
    \draw[fill=white] (0,0) circle [radius=2];
    \draw[dashed, -{Latex[length=3mm,width=3mm]}] (4,0) 
         arc [start angle=0, end angle=180, radius=4] node[midway, below]{\large$\Gamma$} ;
    \draw[dashed, -{Latex[length=3mm,width=3mm]}] (-4,0) arc [start angle=180, end angle=360, radius=4] ;
    \node[above] at (0,5) {\large$\partial \Omega_{out}$};
    \node[below] at (0,2) {\large$\partial \Omega_{in}$};
    \node at (135:3) {\huge$\Omega_\Gamma$};
\end{tikzpicture}
}
\caption{Does this really work?} \label{fig:annulus_domain}
\end{figure}

From now on, our domain $\Omega$ is always assumed to be of that kind. We will 
later make further restrictions on what types of domain we will consider that 
will be suitable for discretization (see \ref{}).


We add the curve integral along $\Gamma$, which we 
assume to be well-defined, as an additional constraint.
So in total, we obtain the following problem.
\begin{problem}[2D magnetostatic problem]\label{prob:2d_magnetostatic_problem}
    Given $J \in L^2$ and $C_0 \in \real$, find $\mathbf{B} \in H_0(\diver) \cap H(\curl)$ s.t.
    \begin{align*}
        \curl \mathbf{B} &= J, 
        \\ \diver \mathbf{B} = 0,
        \\ \int_\Gamma \mathbf{B} \cdot \, dl = C_0
    \end{align*}
\end{problem}

Another option for the additional constraint would be an orthogonality constraint as discussed 
in \cite[Sec.\,3.5]{multipatch_paper}.

\subsection{Mixed formulation}
In order to solve this problem numerically using finite elements we have to 
choose a suitable variational formulation of the problem. This variational formulation 
will be stated -- without the curve integral constraint -- and then we will show 
the equivalence with the strong formulation.

Ignoring the curve integral 
at first, we will use the following. We choose a non-zero harmonic form 
$\mathbf{p} \in \mathfrak{H}^1$ and have 
$J \in L^2$ . Then the problem is: Find $\sigma \in H^1_0$, 
$B \in H_0(\diver)$ and $\lambda \in \real$ s.t.
\begin{align}
    \langle \sigma, \tau \rangle - \langle \mathbf{B}, \veccurl \tau \rangle 
        &=  -\langle J, \tau \rangle \quad \forall \tau \in H^1_0, \label{eq:first_eq_mixed_formulation}
    \\ \langle \veccurl\sigma, \mathbf{v} \rangle + \langle \diver \mathbf{B}, \diver \mathbf{v} \rangle 
        + \lambda \langle \mathbf{p}, \mathbf{v} \rangle 
        &= 0 \quad \forall \mathbf{v} \in H_0(\diver) \label{eq:second_eq_mixed_formulation}
\end{align} 
As before, the inner product without subscript denotes the $L^2$ inner product and 
$\lVert \cdot \rVert$ the $L^2$ norm.
Here the curve integral condition is missing. It is difficult to include the curve integral 
condition directly when solving this system numerically. So we will reformulate it below 
in Sec.\,\ref{sec:curve_integral_constraint}.

Even though this formulation appears more complicated in comparison to the first two equations of 
the 2D magnetostatic problem (Problem\,\ref{prob:2d_magnetostatic_problem}), 
it will turn out to be well-suited for finite element approximations.
But it begs the question if the two formulations are equivalent. We will first 
investigate the formulation without curve integral

\begin{proposition}
    For any $J \in L^2$, (\ref{eq:first_eq_mixed_formulation}) and 
    (\ref{eq:second_eq_mixed_formulation}) hold i.i.f. 
    $\sigma = 0$, $\lambda=0$, $\curl \mathbf{B} = J$ and 
    $\diver \mathbf{B} = 0$
    i.e. $\mathbf{B}$ solves the 2D magnetostatic problem (Problem\,\ref{prob:2d_magnetostatic_problem})  
    without the additional curve integral
    constraint.
\end{proposition}
\begin{proof}
    Assume $(\sigma,\mathbf{B},\lambda)$ is a solution of (\ref{eq:first_eq_mixed_formulation}) and 
    (\ref{eq:second_eq_mixed_formulation}). Then the first equation is
    \begin{align*}
        \langle \sigma + J, \tau \rangle  
        &=  \langle \mathbf{B}, \veccurl\tau \rangle  \quad \forall \tau \in H^1_0
    \end{align*}
    which is equivalent to $\mathbf{B} \in H(\curl)$ and $J + \sigma = \curl \mathbf{B}$.

    Now assume additionally, that  
    (\ref{eq:second_eq_mixed_formulation}) holds. Then by choosing $\mathbf{v} = \mathbf{p} \in \mathfrak{H}^1$,
    we get $\diver \mathbf{p} = 0$ from the definition of the harmonic forms 
    and $\mathfrak{H}^1 \perp \veccurl H^1_0$ from the Hodge decomposition and thus
    \begin{align*}
        \langle \veccurl \sigma, \mathbf{p} \rangle + \langle \diver \mathbf{B}, \diver\mathbf{p}\rangle 
            + \lambda\langle \mathbf{p}, \mathbf{p} \rangle
        = \lambda \langle \mathbf{p}, \mathbf{p}\rangle = 0
    \end{align*}
    and so $\lambda = 0$. Then we can choose $\mathbf{v} = \veccurl \sigma$ to get 
    \begin{align*}
        \langle \veccurl \sigma, \veccurl \sigma \rangle + \langle \diver \mathbf{B}, \diver \veccurl \sigma \rangle 
            + \lambda \langle \mathbf{p}, \veccurl \sigma \rangle
        = \lVert \veccurl \sigma \rVert^2 = 0.
    \end{align*}
    Because $\sigma \in H^1_0$ this gives us $\sigma = 0$. Also we have then 
    $J = \curl \mathbf{B}$. At last we choose $\mathbf{v} = \mathbf{B}$ which gives us 
    $\diver \mathbf{B} = 0$ and thus we proved the first direction. 

    The other implication is clear i.e. if $\mathbf{B} \in H(\curl) \cap H_0(\diver)$
    with $\curl \mathbf{B} = J$ and $\diver \mathbf{B} = 0$ then the variational 
    formulation clearly holds.
    \end{proof}
Notice that the variable $\lambda$ is not necessary for this variational formulation, 
but we will need it later, since we will add another equation representing the 
curve integral constraint and hence we need another variable to have the same 
number of unknowns and equations.
If we now add the same additional constraint to both formulations of the problem 
then they will remain equivalent.


\subsection{Curve integral constraint}\label{sec:curve_integral_constraint}

We still need to find a good way to include the curve integral constraint from 
Problem\,\ref{prob:2d_magnetostatic_problem} in our formulation. Instead of incorporating 
it directly, we will substitute it with another equation. We will first derive this 
equation as an immediate consequence of the integration by parts formula 
(\ref{eq:2D_integration_by_parts_curl}) and then state the 
final variational formulation of the 2D magnetostatic problem which we 
will investigate in the coming sections.

Because $\mathbf{n}$ is the unit outward normal 
of $\Omega_\Gamma$ and $\bm{\gamma}$ the parametrization of $\Gamma$ that $\mathbf{n} \perp \bm{\gamma}'$
and
\begin{align*}
    \mathbf{B}\times \mathbf{n} 
    = (B_1 n_2 - B_2 n_1) = \mathbf{B} \cdot \begin{pmatrix}n_2 \\ -n_1 \end{pmatrix}
    = -\mathbf{B} \cdot \mathbf{R}_{\pi/2}\mathbf{n}.
\end{align*}
$\mathbf{R}_{\pi/2} \mathbf{n}$ is either $\bm{\gamma}'$ or $-\bm{\gamma}'$. Assume w.l.o.g.
that $\mathbf{R}_{\pi/2} \mathbf{n} = \bm{\gamma}'$ and thus 
\begin{align*}
    \mathbf{B} \times \mathbf{n} = -\mathbf{B} \cdot \bm{\gamma}'
\end{align*}
and so the curve integral becomes

\begin{align*}
    \int_\Gamma \mathbf{B}\cdot dl= \int_0^{|\Gamma|} \mathbf{B}(\bm{\gamma}(t)) \cdot \bm{\gamma}'(t) \, dt 
    = \int_0^{|\Gamma|} \mathbf{n}(\bm{\gamma}(t)) \times \mathbf{B}(\bm{\gamma}(t)) \, dt 
    = -\int_\Gamma  \mathbf{B}\times \mathbf{n} d\ell.
\end{align*}
Choose $\psi \in H^1$ s.t. $\psi = 0$ on $\partial \Omega_{in}$, $\psi = 1$ on 
$\partial \Omega_{out}$ and $\psi \equiv 1$ in $\Omega \setminus \Omega_\Gamma$
Then we observe 
\begin{align*}
    \int_\Omega \veccurl \psi \cdot \mathbf{B} \, dx = 
    \int_{\Omega_\Gamma} \veccurl \psi \cdot \mathbf{B} \, dx = 
    \int_{\Omega_\Gamma} \psi \, J \, dx + \int_{\partial\Omega} \mathbf{B} \times \mathbf{n}\, dl
    = \int_{\Omega_\Gamma} \psi \, J \, dx - \int_\Gamma \mathbf{B}\cdot dl
\end{align*}
So if the curve integral 
\begin{align*}
    \int_\Gamma \mathbf{B} \cdot dl = C_0
\end{align*}
is given and we can compute $\int_{\Omega_\Gamma} \psi \, J \, dx$
we can add the equation
\begin{align}
    \langle \veccurl \psi, \mathbf{B} \rangle = C_1 \label{eq:variational_curve_integral}
\end{align}
with 
\begin{align*}
    C_1 \vcentcolon= \int_{\Omega_\Gamma} \psi \, J \, dx - C_0
\end{align*}
to our system.

From the above derivations it is also clear that for $\mathbf{B} \in C^1(\overline{\Omega};\real^2)$ 
\begin{align*}
    \int_\Gamma \mathbf{B} \cdot dl = C_0 
    \Leftrightarrow \langle \veccurl \psi, \mathbf{B} \rangle = C_1.
\end{align*}
This is the motivation why it makes sense to add the right equation to our system instead
of the curve integral since it is much easier 
to enforce numerically.

In order to get a variational 
formulation to study theoretically,
 we multiply (\ref{eq:variational_curve_integral}) with an arbitrary $\mu \in \real$. 
In conclusion, we have the following variational problem:

\begin{problem}\label{prob:magnetostatic_problem_variational}
    Let $J \in L^2$, $\mathbf{p} \in \mathfrak{H}^1 \setminus \{0\}$. 
    Find $\sigma \in H^1_0$, $\mathbf{B} \in H_0(\diver)$, $\lambda \in \real$ s.t.
    \begin{align}
        \langle \sigma, \tau \rangle - \langle \mathbf{B}, \veccurl\tau \rangle 
        &=  -\langle J, \tau \rangle &&\quad \forall \tau \in H^1_0, \label{eq:first_eq_mixed_formulation_curve_integral}
        \\ \langle \veccurl\sigma, \mathbf{v} \rangle + \langle \diver \mathbf{B}, \diver \mathbf{v} \rangle 
        + \langle \lambda \mathbf{p}, \mathbf{v} \rangle 
        &= 0 &&\quad \forall \mathbf{v} \in H_0(\diver), \label{eq:second_eq_mixed_formulation_curve_integral}
        \\ \mu \langle \bm{\curl} \psi, \mathbf{B} \rangle &= \mu C_1 &&\quad \forall \mu \in \real.
    \end{align}
\end{problem}
which gives us the variational formulation of the magnetostatic problem with curve integral 
constraint (Problem\,\ref{prob:2d_magnetostatic_problem}). 
We will study the well-posedness of this formulation next. 

\subsection{Well-posedness of the magnetostatic system}

The well-posedness is based on the well-known Banach-Nečas-Babuška (BNB) theorem 
concerning general variational problems of the following form: Find $x \in X$ 
s.t. 
\begin{align}
    a(x,y) = \ell(y) \quad \forall y \in Y \label{eq:general_variational_problem}
\end{align}
where $X$ and $Y$ are Banach spaces, $a$ is a bilinear form 
and $\ell \in Y'$. The BNB-theorem then answers the question of well-posedness 
i.e. if there exists a unique solution and if we can find a stability estimate.
This formulation is from \cite[Sec.\,25.3]{ern_guermond} in the real case.

\begin{theorem}[BNB]\label{thm:BNB}
    Let $X$ be a Banach space and $Y$ be a reflexive Banach space. Let $a:X\times Y \rightarrow \real$ be a 
    bounded bilinear form and $\ell \in Y'$. Then a problem of the form 
    (\ref{eq:general_variational_problem}) is well-posed i.i.f. the following two criteria are fulfilled
    \begin{align}
        &\text{\normalfont(1)}\quad\inf_{x \in X} \sup_{y\in Y} \frac{|a(x,y)|}{\lVert x \rVert _X \lVert y \rVert _Y} 
            =\vcentcolon \gamma > 0\label{eq:BNB1} 
        \\&\text{\normalfont(2)}\quad \text{for any $y \in Y$ if $a(x,y) = 0$ for every $x \in X$, then $y=0$.}\label{eq:BNB2}
    \end{align}    
    We obtain the stability estimate for a solution $x$
    \begin{align*}
        \lVert x \rVert _X \leq \frac{1}{\gamma} \lVert \ell\rVert _{Y'}.
    \end{align*}
\end{theorem}
Note that (\ref{eq:BNB1}) is equivalent to the fact that for any $x \in X \setminus\{0\}$ 
there exists $y \in Y\setminus\{0\}$ s.t. $a(x,y) \geq \gamma \lVert x \rVert _X \lVert y \rVert _Y$.  

Since we are dealing with Hilbert spaces only we can utilize the following proposition to prove it 
(see \cite[Rem.\,25.14]{ern_guermond}).
\begin{proposition}[$T$-coercivity]\label{prop:T_coercivity}
    Let $X$ and $Y$ be Hilbert spaces. Then {\normalfont (\ref{eq:BNB1})} and {\normalfont (\ref{eq:BNB2})} hold, if
    there exists a bounded bijective operator $T:X \rightarrow Y$ s.t.
    \begin{align}
        a(x,Tx) \geq \eta \lVert x \rVert _X^2 \quad \forall x \in X. \label{eq:T_coercivity_bound}
    \end{align}
    Then $\gamma$ from {\normalfont (\ref{eq:BNB1})} can be chosen as $\eta/\lVert T \rVert  _{\mathcal{L}(X,Y)}$.
\end{proposition}
\begin{proof}
    For any $x \in X$, by taking $y = Tx \in Y$ and using the boundedness of 
    $T$ we have 
    \begin{align*}
        a(x,T(x)) \geq \eta \lVert x \rVert ^2 \geq \frac{\eta}{\lVert T \rVert  _{\mathcal{L}(X,Y)}}
            \lVert x \rVert _X \lVert y \rVert _Y
    \end{align*}
    and thus (\ref{eq:BNB1}) holds with $\gamma =  \frac{\eta}{\lVert T \rVert  _{\mathcal{L}(X,Y)}}$.

    For (\ref{eq:BNB2}) assume that we have $y \in Y$ s.t. $a(x,y) = 0$ for all 
    $x \in X$. 
    \begin{align*}
        0 = a(T^{-1}y,T T^{-1}y) \geq \eta \lVert T^{-1}y \rVert^2 _X
    \end{align*}
    so $T^{-1}y = 0$ and thus $y = 0$.
\end{proof}

\begin{remark}
    The other direction is also true i.e. if (\ref{eq:BNB1}) and (\ref{eq:BNB2}) 
    are fulfilled we can construct a $T$ with the desired properties.
\end{remark}

Note also that when we have found $T$ s.t. (\ref{eq:T_coercivity_bound}) holds 
then it must be injective. This is because if $Tx = 0$ for any 
$x \in X$ then $x=0$ follows from the $T$-coercivity.

The next step is to put our formulation of
Problem \ref{prob:magnetostatic_problem_variational} into 
this general framework. To this end, 
we define $X \vcentcolon= H^1_0 \times H_0(\diver) \times \real$
and for $(\sigma, \mathbf{B},\lambda) \in X$
\begin{align*}
    \lVert (\sigma, \mathbf{B}, \lambda) \rVert _X 
    \vcentcolon= \sqrt{\lVert \sigma \rVert^2_{H^1} + \lVert \mathbf{B} \rVert^2_{H(\diver)}
    + \lambda^2}    
\end{align*}
and the 
bilinear form $a:X\times X \rightarrow \real$
\begin{align}
    a(\sigma,\mathbf{B}, \lambda;\tau,\mathbf{v},\mu) 
    =   \langle \sigma, \tau \rangle - \langle \mathbf{B}, \veccurl\tau \rangle
        + \langle \veccurl\sigma, \mathbf{v} \rangle + \langle \diver \mathbf{B}, \diver \mathbf{v} \rangle 
        + \langle \lambda \mathbf{p}, \mathbf{v} \rangle - \mu \langle \veccurl \psi, \mathbf{B} \rangle.
        \label{eq:definition_bilinear_form}
\end{align}
and 
\begin{align*}
    \ell(\tau,\mathbf{v},\mu) = -\langle J, \tau \rangle - \mu C_1.
\end{align*}
Then Problem\,\ref{prob:magnetostatic_problem_variational}
is equivalent to the following: Find $(\sigma,\mathbf{B},\lambda) \in 
X$ s.t.
\begin{align*}
    a(\sigma,\mathbf{B},\lambda;\tau,\mathbf{v},\mu) = \ell(\tau,\mathbf{v},\mu)
        \quad \forall (\tau,\mathbf{v},\mu) \in X.
\end{align*}
Note that the bilinear form $a$ is not symmetric. 

We need to show some things about $\veccurl \psi$.
\begin{proposition}
    Under the given assumptions on $\psi$, $\veccurl\psi \in H_0(\diver)$.
\end{proposition}
\begin{proof}
    We need to show $0 = \gamma_n \veccurl \psi$. Recall that the definition of 
    \begin{align*}
        \langle \gamma_n \veccurl \psi , \tr u \rangle 
        = \int_\Omega \veccurl \psi \cdot \grad u \, dx 
            + \int_\Omega \diver \veccurl \psi \, u \, dx 
    \end{align*}
    where the last term vanishes. Take now $\phi \in C^1(\overline{\Omega})$ 
    arbitrary. Then we take $\phi_1 \in C^1(\overline{\Omega})$ s.t. $\phi_1 = \phi$ in 
    a neighborhood of $\partial \Omega_{in}$ and zero near $\partial \Omega_{out}$. 
    Then $\phi_2 \in C^1(\overline{\Omega})$ the other way around. Here we used the fact that 
    the two parts of the boundary are disjoint and have positive distance from one another.
    Then also $\tr \phi = \tr \phi_1 + \tr \phi_2$.
    We use the integration by parts formula \ref{}, $\diver \veccurl = 0$ and the 
    integration-by-parts formula for the curl
    \begin{align*}
        &\langle \gamma_n \veccurl \psi , \tr \phi \rangle 
        = \langle \gamma_n \veccurl \psi , \tr \phi_1 \rangle + \langle \gamma_n \veccurl \psi , \tr \phi_2 \rangle
        \\ &= \int_\Omega \veccurl \psi \cdot \grad \phi_1 \, dx + \int_\Omega \veccurl \psi \cdot \grad \phi_2 \, dx
        \\ &= \int_\Omega \psi \cdot \curl \grad \phi_1 \, dx + \langle \gamma_\tau \grad \phi_1, \psi \rangle
            + \int_\Omega \psi \cdot \curl \grad \phi_2 \, dx + \langle \gamma_\tau \grad \phi_2, \psi \rangle.
    \end{align*}
    Now remember that because $\phi_j \in C^1(\overline{\Omega})$, 
    $\langle \gamma_\tau \grad \phi_j, \psi \rangle 
    = \langle \grad \phi_j \times \mathbf{n}, \psi \rangle_{L^2(\partial \Omega)}$. So 
    \begin{align*}
        \langle \gamma_\tau \grad \phi_1, \psi \rangle 
        = \langle \grad \phi_1 \times \mathbf{n}, \psi \rangle_{L^2(\partial \Omega)} = 0
    \end{align*}
    because $\phi_1$ is zero near $\partial \Omega_{out}$ and $\psi$ is zero on 
    $\partial \Omega_{in}$. For the remaining term, 
    \begin{align*}
        \langle \gamma_\tau \grad \phi_2, \psi \rangle
        = \int_{\partial\Omega_{out}} \psi \grad \phi_1 \times \mathbf{n}d\ell 
        = \int_{\partial\Omega_{out}} \grad \phi_1 \times \mathbf{n} d\ell 
        = - \int_{\partial\Omega_{out}} \grad \phi_1 \cdot d\ell
    \end{align*}
    using a counter clockwise parametrization of $\partial\Omega_{out}$ 
    for a parametrization $\mathbf{s}$
    i.e. $\grad \phi_1 \times \mathbf{n} = -\grad \phi_1 \cdot \mathbf{R}_{\pi/2}\mathbf{s}'$
    and then we know from basic vector calculus because $\partial\Omega_{out}$ is closed
    \begin{align*}
        \int_{\partial\Omega_{out}} \grad \phi_1 \cdot d\ell = 0.
    \end{align*}
    and so in conclusion, $\gamma_n \veccurl \psi = 0$.
\end{proof}

Usually the last equation in Problem\,\ref{prob:magnetostatic_problem_variational} 
is used to determine the harmonic part of the 
solution. This implies that we would like $\veccurl \psi$ to have 
non-vanishing harmonic part. This is indeed true.
\begin{proposition}
    Let $Q_\mathfrak{H}^1: L^2 \rightarrow \mathfrak{H}^1$ be the orthogonal
    projection onto the harmonic forms. Then with $\psi$ defined as above 
    we have $Q_\mathfrak{H}^1\veccurl \psi \neq 0$.
\end{proposition}
\begin{proof}
    Since $\diver \veccurl \psi = 0$ we know that 
    \begin{align*}
        \veccurl \psi \in \mathfrak{Z}^1 = \mathfrak{B}^1 \stackrel{\perp}{\oplus} \mathfrak{H}^1
    \end{align*}
    using the Hodge decomposition (cf. Thm.\,\ref{thm:hodge_decomposition}). 
    Assume for contradiction that $\veccurl \psi \in \mathfrak{B}^1$ i.e. there exists 
    $\psi_0 \in H^1_0$ s.t. $\veccurl \psi_0 = \veccurl \psi$. 
    Since $\veccurl$ is just the rotated gradient we would get that 
    $\grad (\psi - \psi_0) = 0$ and thus $\psi - \psi_0$ is constant almost 
    everywhere. But this is a contradiction since $\tr \psi_0$ is zero on $\partial\Omega_{in}$ 
    and $\partial \Omega_{out}$, but $\tr \psi = 0$ on $\partial\Omega_{in}$ and 
    $\tr \psi = 1$ on $\partial\Omega_{in}$. 
    Thus $\veccurl \psi \notin \mathfrak{B}^1$ and the claim follows.
\end{proof}
Now we can apply the Hodge decomposition of the $\ker \diver$ on
$\veccurl \psi$ and obtain the following
\begin{corollary}
    Let $\mathbf{p}\in \mathfrak{H}^1 \setminus \{ 0 \}$. Then there exists 
    $\psi_0 \in H^1_0$ and $c_\psi \in \real \setminus \{ 0 \}$ s.t. 
    \begin{align*}
        \veccurl \psi = \veccurl \psi_0 + c_\psi \mathbf{p}.
    \end{align*}
\end{corollary}
Because we can choose $\mathbf{p}$ we can assume w.l.o.g. that $c_\psi > 0$ and 
we will do so from now on.

As stated in the proof of the Poincare inequality \ref{} 
the $\veccurl| _{\mathfrak{Z}^\perp}: \mathfrak{Z}^\perp \rightarrow \mathfrak{B}^1$
is bijective and since it is bounded w.r.t. the $V$-norm -- which is the 
$H^1$-norm here -- due to Banach inverse theorem it is invertible and we denote this 
inverse $\veccurl^{-1}$. This is a slight abuse of notation since it is not really 
the inverse of the full $\veccurl$.

Let $Q_\mathfrak{B}$ be the $L^2$-orthogonal projection onto $\mathfrak{B}^j$, 
we then denote $\mathbf{v}_\mathfrak{B} = Q_\mathfrak{B} \mathbf{v}$ for any $\mathbf{v} \in L^2$ 
and analogous for 
$\mathfrak{H}^j$ and $\mathfrak{B}^*_j$.
In order to prove the $T$-coercivity, we need the following lemma.
\begin{lemma}\label{lem:T_for_T_coercivity_surjective}
    Take $\veccurl \psi = \veccurl \psi_0 + c_\psi \mathbf{p}$ with $c_\psi > 0$
    ,$\mathbf{p} \in \mathfrak{H}^1$ and $\lVert \mathbf{p}\rVert =1$.
    Define $T:X \rightarrow X$ as 
    \begin{align*}
        T(\sigma, \mathbf{B},\lambda)
        = (\sigma - \frac{1}{c_P^2}\veccurl^{-1}\mathbf{B}_\mathfrak{B}, \veccurl \sigma + \mathbf{B} + \lambda \beta \mathbf{p},
            \alpha \langle \mathbf{p}, \mathbf{B} \rangle  
            + \frac{\lambda}{c_\psi}).
    \end{align*}
    with $\alpha < 0$ and $\beta>0$.
    Then $T$ is bounded and surjective. 
\end{lemma}
\begin{proof}
    The boundedness is clear since all operators used in the definition 
    are bounded w.r.t. the norms of their domains. From the Poincaré inequality we know that 
    $\lVert \veccurl^{-1} \mathbf{B}_\mathfrak{B} \rVert \leq c_P \lVert \mathbf{B}_\mathfrak{B} \rVert$
    and so 
    \begin{align*}
        &\lVert T(\sigma,\mathbf{B},\lambda) \rVert^2 _X 
        = \lVert \sigma - \frac{1}{c_P^2}\veccurl^{-1}\mathbf{B}_\mathfrak{B} \rVert^2 _{H^1}
            + \lVert \veccurl \sigma + \mathbf{B} + \lambda \beta \mathbf{p} \rVert^2 _{H(\diver)}
             + \left( \alpha \langle \mathbf{p}, \mathbf{B} \rangle  + \frac{\lambda}{c_\psi} \right)^2
        \\ &\leq 2 \lVert \sigma \rVert ^2 _{H^1} 
            +  \frac{2}{c_P^4} \lVert \veccurl^{-1}\mathbf{B}_\mathfrak{B} \rVert ^2 _{H^1}
            + 3 \lVert \veccurl \sigma  \rVert^2 
            + 3 \lVert \mathbf{B} \rVert^2 _{H(\diver)}
            + 3 \lambda^2 \beta^2 + 2 \alpha^2 \lVert \mathbf{B}_\mathfrak{H}\rVert^2 
            + \frac{2}{c_\psi^2} \lambda^2
        \\ &\leq 2 \lVert \sigma \rVert ^2 _{H^1} 
            + \frac{2}{c_P^2} \lVert \mathbf{B}_\mathfrak{B} \rVert ^2 
            + 3 \lVert \veccurl \sigma  \rVert^2 
            + 3 \lVert \mathbf{B} \rVert^2 _{H(\diver)}
            + 3 \lambda^2 \beta^2 + 2 \alpha^2 \lVert \mathbf{B}\rVert^2 _{H(\diver)}
            + \frac{2}{c_\psi^2} \lambda^2
        \\ &\leq C_T \left( \lVert \sigma \rVert ^2 _{H^1} + \lVert \mathbf{B} \rVert^2 _{H(\diver)} 
            + \lambda^2 \right)
    \end{align*}
    with 
    \begin{align}
        C_T \vcentcolon= \max \left\{ 5, \frac{2}{c_P^2} + 3 + 2\alpha^2, 3 \beta^2 + \frac{2}{c_\psi^2} \right\}.
        \label{eq:bound_on_norm_of_T}
    \end{align}
    So $T$ is bounded and $\lVert T \rVert _{\mathcal{L}(X,X)} \leq \sqrt{C_T}.$

    In order to prove surjectivity, we will split up $\mathbf{v} = \mathbf{v}_\mathfrak{B}
    + \mathbf{v}_\mathfrak{H} + \mathbf{v}_\mathfrak{B^*}$ using the Hodge decomposition.
    Take $(\tau, \mathbf{v},\mu) \in X$ arbitrary and 
    choose 
    \begin{align*}
        \sigma = (1+\frac{1}{c_P^2})^{-1} (\tau + \frac{1}{c_P^2} \veccurl^{-1} \mathbf{v}_\mathfrak{B}) 
        \text{ and }\mathbf{B}_\mathfrak{B} = \mathbf{v}_\mathfrak{B} - \veccurl \sigma.
    \end{align*}
    So 
    \begin{align*}
        \sigma -  \frac{1}{c_P^2} \veccurl^{-1}\mathbf{B}_\mathfrak{B} 
        = \sigma -  \frac{1}{c_P^2} (\veccurl^{-1} \mathbf{v}_\mathfrak{B} - \sigma)
        = (1+\frac{1}{c_P^2})\sigma - \frac{1}{c_P^2} \veccurl^{-1} \mathbf{v}_\mathfrak{B}
        = \tau.
    \end{align*}
    We simply choose $\mathbf{B}_\mathfrak{B^*} = \mathbf{v}_\mathfrak{B^*}$.
    For the harmonic part take $\kappa_v$ s.t. $\mathbf{v}_\mathfrak{H} = \kappa_v \mathbf{p}$.
    Let us look at the system 
    \begin{align*}
        \begin{pmatrix}
            1 & \beta 
            \\ \alpha & 1/c_\psi
        \end{pmatrix}
        \begin{pmatrix}
            \kappa_B 
            \\ \lambda 
        \end{pmatrix}
        = 
        \begin{pmatrix}
            \kappa_v 
            \\ \mu
        \end{pmatrix}
    \end{align*}
    Now since $c_\psi > 0$ and $\alpha < 0$, $\beta > 0$ we get 
    $1/c_\psi - \alpha \beta \neq 0$ and the system has a solution. 
    Choose $\mathbf{B}_\mathfrak{H} = \kappa_B \mathbf{p}$.
    Then we see 
    \begin{align*}
        \mathbf{v}_\mathfrak{H} = \kappa_v \mathbf{p} = \mathbf{p}(\kappa_B + \beta \lambda) 
        =  \mathbf{B}_\mathfrak{H} + \beta \lambda \mathbf{p}
    \end{align*}
    and 
    \begin{align*}
        \mu = \alpha \kappa_B + \frac{\lambda}{c_\psi}
        = \alpha \kappa_B \lVert \mathbf{p} \rVert^2 + \frac{\lambda}{c_\psi}
        = \alpha \langle \mathbf{B}, \mathbf{p} \rangle + \frac{\lambda}{c_\psi}.
    \end{align*}
    By combining all that we arrive at 
    $T(\sigma,\mathbf{B}, \lambda) = (\tau, \mathbf{v}, \mu)$.
\end{proof}

We assume from now on that we have always chosen $\mathbf{p}$ in a way s.t. 
$c_\psi$ -- as defined in the previous lemma -- is positive and $\mathbf{p}$ has 
norm one. This comes down to choosing $\mathbf{p}$ with the correct sign and normalizing it. 
Now we can use the T-coercivity (Prop.\,\ref{prop:T_coercivity}) to prove the inf-sup condition and thus 
well-posedness of our formulation.

\begin{theorem}
    Let $\veccurl \psi_0 + c_\psi \mathbf{p} = \veccurl \psi$ and assume we have chosen the sign of 
    $\mathbf{p}$ s.t. $c_\psi > 0$. Then take $c_1 >0 $ s.t. 
    $\lVert \veccurl \psi_0 \rVert \leq c_1$ (e.g. $c_1 = \lVert \veccurl \psi_0 \rVert + 1$ would be a valid choice). Define 
    $\beta = \frac{3 c_1^2 c_P^2}{c_\psi^2}$ and $\alpha = -\frac{c_\psi}{4 c_1^2 c_P^2}$. 
    Then the bilinear form $a$ defined at (\ref{eq:definition_bilinear_form}) 
    satisfies the inf-sup condition i.e. (\ref{eq:BNB1}) and (\ref{eq:BNB2})
    with $\gamma \geq \eta/\sqrt{C_T}$ with $C_T$ from (\ref{eq:bound_on_norm_of_T})
    and 
    \begin{align*}
        \eta \vcentcolon= \min \left\{ \frac{1}{2},  \frac{1}{4 c_P^2}, \frac{c_1^2 c_P^2}{c_\psi^2},
        \frac{c_\psi^2}{8 c_1^2 c_P^2}\right\}.
    \end{align*}
\end{theorem}
\begin{proof}
    We will use T-coercivity to prove it. Choose $(\sigma, \mathbf{B},\lambda) \in X$ 
    arbitrary and define $\rho \vcentcolon= \veccurl^{-1} \mathbf{B}_{\mathfrak{B}}$.
    We take $T$ as in (\ref{lem:T_for_T_coercivity_surjective}),
    \begin{align*}
        T(\sigma, \mathbf{B},\lambda)
        = (\sigma - \frac{1}{c_P^2}\rho, \veccurl \sigma + \mathbf{B} + \beta \lambda\mathbf{p},
            \alpha \langle \mathbf{p},\mathbf{B} \rangle  + \frac{\lambda}{c_\psi} )
    \end{align*}
    Then $T$ is surjective due to Lemma \ref{lem:T_for_T_coercivity_surjective}. 
    Note 
    \begin{align*}
        \langle \mathbf{B}, \mathbf{p} \rangle ^ 2
        = \lVert \mathbf{B}_\mathfrak{H} \rVert^2  
            \langle \frac{\mathbf{B}_\mathfrak{H}}{\lVert \mathbf{B}_\mathfrak{H} \rVert}, \mathbf{p} \rangle ^ 2
        = \lVert \mathbf{B}_\mathfrak{H} \rVert^2
    \end{align*}
    where we used in the last equality that $\frac{\mathbf{B}_\mathfrak{H}}{\lVert \mathbf{B}_\mathfrak{H} \rVert}$
    is either $+\mathbf{p}$ or $-\mathbf{p}$ because $\mathfrak{H}^1$ is assumed to be one-dimensional.
    We split up $\veccurl\psi = \veccurl\psi_0 + c_\psi \mathbf{p}$ to get 
    \begin{align*}
        &a(\sigma, \mathbf{B},\lambda;T(\sigma, \mathbf{B},\lambda))
        \\ &=\langle \sigma, \sigma - \frac{1}{c_P^2} \rho \rangle 
            - \langle \mathbf{B}, \veccurl \sigma - \frac{1}{c_P^2}\veccurl \rho \rangle
            + \langle \veccurl \sigma , \veccurl \sigma + \mathbf{B} + \beta \lambda \diver \mathbf{p} \rangle
        \\ &\quad + \langle \diver \mathbf{B}, \diver \veccurl \sigma 
            + \diver \mathbf{B} + \beta \lambda \diver \mathbf{p}\rangle
        \\ &\quad + \langle \lambda \mathbf{p}, \veccurl \sigma + \mathbf{B} + \beta \lambda \mathbf{p}\rangle
            - (\alpha \langle \mathbf{B}, \mathbf{p} \rangle + \frac{\lambda}{c_\psi})
            \langle \mathbf{B} , \veccurl\psi \rangle
        \\ &= \lVert \sigma \rVert^2 - \frac{1}{c_P^2} \langle \sigma , \rho \rangle 
            + \frac{1}{c_P^2} \lVert \mathbf{B}_\mathfrak{B} \rVert^2 + \lVert  \veccurl \sigma \rVert^2
            + \lVert \diver \mathbf{B} \rVert ^2 + \lambda ^2 \beta - \alpha c_\psi \lVert \mathbf{B}_\mathfrak{H} \rVert^2
        \\ &\quad- \alpha \langle \mathbf{p}, \mathbf{B}_\mathfrak{H} \rangle \langle \mathbf{B}_\mathfrak{B}, \veccurl \psi_0 \rangle
            - \frac{\lambda}{c_\psi} \langle \mathbf{B}_\mathfrak{B} , \veccurl \psi_0 \rangle
    \end{align*}
    Due to the Poincaré inequality
    \begin{align*}
        \lVert \rho \rVert \leq \lVert \rho \rVert _{H^1} 
        \stackrel{\text{Poincaré}}{\leq} c_P \lVert \veccurl \rho \rVert 
        = c_P \lVert \mathbf{B}_\mathfrak{B} \rVert.
    \end{align*}
    Using $\epsilon$-Young combined with Cauchy-Schwarz inequality several times 
    we obtain the lower bound.
    \begin{align*}        
        &\lVert \sigma \rVert^2 - 
            \left( \frac{1}{2} \lVert \sigma \rVert^2 
            + \frac{\lVert \mathbf{B}_\mathfrak{B} \rVert^2}{2 c_P^2}  \right)
            + \frac{1}{c_P^2} \lVert \mathbf{B}_\mathfrak{B} \rVert^2
            + \lVert  \veccurl \sigma \rVert^2 + \lVert \diver \mathbf{B} \rVert ^2
        \\ &\quad+ \lambda ^2 \beta - \alpha c_\psi \lVert \mathbf{B}_\mathfrak{H} \rVert^2
            - \left( \frac{\epsilon_1 \alpha^2 \lVert \mathbf{B}_\mathfrak{H} \rVert^2}{2} 
            + \frac{\lVert \mathbf{B}_\mathfrak{B} \rVert^2 \lVert  \veccurl \psi_0 \rVert^2}{2 \epsilon_1} \right)
            - \left( \frac{\lambda^2}{2 \epsilon_2 c_\psi^2} 
            + \frac{\epsilon_2 \lVert \mathbf{B}_\mathfrak{B} \rVert^2 \lVert  \veccurl \psi_0 \rVert^2}{2} \right)
    \end{align*}
    Choose $\epsilon_1 = 4 c_1^2 c_P^2$ to get 
    \begin{align*}
        &\frac{1}{2} \lVert \sigma \rVert^2 + \frac{1}{2 c_P^2} \lVert \mathbf{B}_\mathfrak{B} \rVert^2
        + \lVert  \veccurl \sigma \rVert^2 + \lVert \diver \mathbf{B} \rVert ^2
        + \lambda ^2 \left( \beta - \frac{1}{2 \epsilon_2 c_\psi^2} \right) 
        \\ &\quad+ \lVert \mathbf{B}_\mathfrak{H} \rVert^2 
        \left( - \alpha c_\psi - \frac{4 c_1^2 c_P^2 \alpha^2}{2} \right)
        - \lVert \mathbf{B}_\mathfrak{B} \rVert^2 \frac{\lVert  \veccurl \psi_0 \rVert^2}{8c_1^2 c_P^2}
        - \lVert \mathbf{B}_\mathfrak{B} \rVert^2 \frac{ \epsilon_2 \lVert  \veccurl \psi_0 \rVert^2 }{2}
    \end{align*}
    Now choose $\epsilon_2 = \frac{1}{4 c_1^2 c_P^2}$, plug in the definition of $\alpha$
    and use $\lVert \veccurl \psi_0 \rVert \leq c_1$ 
    to get the next lower bound
    \begin{align*}
        &\frac{1}{2} \lVert \sigma \rVert^2 + \lVert \mathbf{B}_\mathfrak{B} \rVert^2 
        \left( \frac{1}{2 c_P^2} - \frac{1}{8 c_P^2} 
        - \frac{\lVert  \veccurl \psi_0 \rVert^2}{8 c_1^2 c_P^2} \right)
        + \lVert  \veccurl \sigma \rVert^2 + \lVert \diver \mathbf{B} \rVert ^2
        + \lambda ^2 \left( \beta - \frac{4 c_1^2 c_P^2}{2 c_\psi^2} \right)
        \\ &\quad+ \lVert \mathbf{B}_\mathfrak{H} \rVert^2  \left( \frac{c_\psi^2}{4 c_1^2 c_P^2 }
        - \frac{ c_1^2 c_P^2 c_\psi^2}{8 c_1^4 c_P^4} \right)
    \end{align*}
    and finally by using the Poincaré inequality $\lVert \mathbf{B}_{\mathfrak{B}^*} \rVert 
    \leq c_P \lVert \diver \mathbf{B} \rVert$
    and $\beta = \frac{3 c_1^2 c_P^2}{c_\psi^2}$ we obtain the next bound
    \begin{align*}
        &\frac{1}{2} \lVert \sigma \rVert^2 + \frac{1}{4 c_P^2}\lVert \mathbf{B}_\mathfrak{B} \rVert^2 
            + \lVert  \veccurl \sigma \rVert^2
            + \frac{1}{2 c_P^2 } \lVert\mathbf{B}_{\mathfrak{B}^*}\rVert ^2
            + \frac{1}{2} \lVert \diver \mathbf{B} \rVert ^2
            + \frac{c_1^2 c_P^2}{c_\psi^2}\lambda^2
            + \frac{c_\psi^2}{8 c_1^2 c_P^2} \lVert \mathbf{B}_\mathfrak{H} \rVert^2.
        \\ &\geq \eta \lVert (\sigma,\mathbf{B},\lambda) \rVert^2_X 
    \end{align*}
    where we chose 
    \begin{align*}
        \eta \vcentcolon= \min \left\{ \frac{1}{2},  \frac{1}{4 c_P^2}, \frac{c_1^2 c_P^2}{c_\psi^2},
        \frac{c_\psi^2}{8 c_1^2 c_P^2}\right\} 
    \end{align*}
    to obtain the $T$-coercivity.
We can then choose $\gamma$ from (\ref{eq:BNB1}) as $\eta/\lVert T \rVert _{\mathcal{L}(X,X)}$
and then use $C_T$ from (\ref{eq:bound_on_norm_of_T}) to get a lower bound
\begin{align*}
    \gamma \geq \frac{\eta}{\sqrt{C_T}}. 
\end{align*}
\end{proof}

\begin{corollary}[Well-posedness]
    The variational formulation of the magnetostatic problem 
    {\normalfont (Problem\,\ref{prob:magnetostatic_problem_variational})} is well-posed. 
    For a solution $(\sigma, \mathbf{B},\lambda) \in X$
    we have the stability estimate 
    \begin{align*}
        \lVert \mathbf{B} \rVert _{H(\diver)} 
        \leq \frac{\lVert J \rVert + |C_1|}{\gamma}.
    \end{align*}
\end{corollary}
\begin{proof}
    Recall that when $(\sigma, \mathbf{B},\lambda)$ is a solution 
    then $\sigma = 0$ and $\lambda = 0$.
    The statement follows immediately from the previous theorem and 
    Thm.\,\ref{thm:BNB} and the fact that 
    \begin{align*}
        | \ell(\tau,\mathbf{v},\mu) |
        = | - \langle J, \tau \rangle - C_1 \mu | 
        \leq (\lVert J \rVert + | C_1 |) \lVert (\tau,\mathbf{v},\mu) \rVert _X
    \end{align*}
    and thus $\lVert \ell \rVert _{X'} \leq \lVert J \rVert + | C_1 |$.
\end{proof}

\begin{remark}
    Note that $1/c_\psi$ terms arise
    in the stability constant $1/\gamma$. This is not surprising since the term 
    $\langle \veccurl \psi, \mathbf{B} \rangle$ will not enforce the harmonic 
    part if the harmonic part of $\veccurl \psi$ would be zero because 
    $\mathbf{B}_\mathfrak{H}$ will disappear from the formulation. So we 
    expect stability issues if the harmonic part is too small.
    This also forces us to choose $\psi$ with this in mind to obtain a 
    stable system.
\end{remark}

\section{Discrete Hilbert complex}

In order to approximate the Hodge Laplacian problem we want to use finite elements.
We want to use them in a way that we can rebuild the structure of the Hilbert complex 
in our discretization. This section follows Sec. 5.2 in Arnold's book \cite{arnold}.

Let us at first stick to the general situation. We assume that we have a Hilbert complex 
$(W^k,d^k)$ with its corresponding domain complex 
$(V^k,d^k)$ and dual complex $(V^*_k,d^*_k)$ for $k \in \integers$. For this chapter 
we will only need a short subsequence 
\begin{align*}
    V^{k-1} \rightarrow V^k \rightarrow V^{k+1}
\end{align*}
for some fixed $k$ and $j$ will be the index to refer to them i.e. 
$j \in \{k-1,k,k+1\}$.

Let us assume the we have finite dimensional subspaces $V_h^j \subseteq V^j$. 
Then we define completely analogous to the continuous case,
\begin{align*}
    \mathfrak{Z}_h^k &\vcentcolon= \{ v \in V_h^k \mid d v = 0 \} = \ker d \cap V^k_h
    \\ \mathfrak{B}^k_h &\vcentcolon= \{ dv \mid v \in V_h^{k-1} \}.
\end{align*}
We can now also define the discrete harmonic forms. Now the situation is slightly 
different however. We will not use the continuous adjoint $d^*_k$ to define it.
Instead,
\begin{align*}
    \mathfrak{H}_h^k \vcentcolon= \{ v \in \mathfrak{Z}_h^k \mid v \perp \mathfrak{B}^k_h \}
        = \mathfrak{Z}_h^k \cap \mathfrak{B}_h^{k,\perp}.
\end{align*}
Notice that we have $\mathfrak{Z}_h^k \subseteq \mathfrak{Z}^k$ and 
$\mathfrak{B}_h^k \subseteq \mathfrak{b}^k$, but due to 
$\mathfrak{B}_h^{k,\perp} \supseteq \mathfrak{B}^{k,\perp}$ we have in general
\begin{align*}
    \mathfrak{H}^k_h = \mathfrak{Z}_h^k \cap \mathfrak{B}_h^{k,\perp} 
    \not\subseteq    \mathfrak{Z}^k \cap \mathfrak{B}^{k,\perp} = \mathfrak{H}^k.
\end{align*}

We will later investigate the difference between the space of discrete and 
harmonic forms.
There are three crucial properties that are necessary for stability and convergence 
of the method. The first one is the common and reasonable assumption that 
-- as usual in finite element theory -- we want that the discrete spaces $V_h^k$
approximate the continuous ones $V^j$. This can be generally summarized that 
\begin{align*}
    \lim_{h \rightarrow 0} \inf_{v_h \in V_h^j} \lVert w - v_h \rVert = 0, \quad \forall w \in V^j.
\end{align*}
This is usually satisfied if we use established finite elements for a given space 
e.g. if we take Lagragian FE if $V = H^1$ or Raviart-Thomas if $V=H(\diver)$ \cite{}.

The next property is more restrictive. We require that $dV_h^{k-1} \subseteq V_h^k$ 
and $dV_h^j \subseteq V_h^{j+1}$. This shows that the we cannot simply use arbitrary 
discrete subspaces independent from one another. We say the spaces have to be 
compatible \cite{}. This property has a very nice
consequence. 
It shows that 
\begin{align*}
    V_h^{k-1} \xrightarrow{d^{k-1}} V_h^k \xrightarrow{d^k} V_h^{k+1}
\end{align*}
is itself a Hilbert complex and we can apply the general theory from 
Sec. \ref{sec:hilbert_complexes} directly to it. Let us do that.

Denote the restriction of $d^j$ to $V_h^j$ as $d_h^j$. Then as a linear map 
between finite spaces the adjoint -- denoted as $d_{j,h}^*: V_h^j \rightarrow V_h^{j-1}$ -- 
is everywhere defined. It is important to notice that in contrast to $d_h$ 
the adjoint $d^*_jh$ is not the restriction of the adjoint the continuous adjoint $d^*_j$.
In general, $V_h \not\subseteq V^*$ and so the continuous adjoint might not be 
well-defined for a given $v_h \in V_h$. 

So we obtain the Hilbert complex
\begin{align*}
    V_h^{k-1} \xrightarrow{d^{k-1}} V_h^{k} \xrightarrow{d^{k}} V_h^{k+1}
\end{align*}
and its dual complex
\begin{align*}
    V_h^{k-1} \xleftarrow{d^*_{k,h}} V_h^{k} \xleftarrow{d^*_{k+1,h}} V_h^{k+1}
\end{align*}
From the general Hilbert complex theory (Thm.\,\ref{thm:hodge_decomposition})
we thus obtain the \textit{discrete Hodge decomposition}
\begin{align*}
    V_h^j = \mathfrak{B}^j_h \stackrel{\perp}{\oplus} \mathfrak{H}^j_h \stackrel{\perp}{\oplus}
        \mathfrak{B}^*_{jh}.
\end{align*}
So we achieved our goal of getting a structure like in the continuous case 
for our discrete approximation. Especially the question how well the discrete harmonic 
forms approximate the contiinous one will be looked at more closely.


The third crucial assumption is the existence of \textit{bounded cochain projections} 
$\Pi^j_h : V^j \rightarrow V^j_h$. 
This is a projection that is a cochain map in the sense of cochain complexes \ref{} i.e. 
the following diagram commutes:
\begin{tikzcd}
    V^{k-1} \arrow[d, "\Pi^{k-1}_h"] \arrow[r, "d^{k-1}"] 
        & V^{k} \arrow[d, "\Pi^{k}_h"] \arrow[r, "d^{k}"] & V^{k+1} \arrow[d, "\Pi^{k+1}_h"]
    \\ V^{k-1}_h \arrow[r, "d_h^{k-1}"] & V^{k}_h  \arrow[r, "d_h^{k}"]& V^{k+1}_h 
\end{tikzcd}    
$\pi_h$ are either bounded in the $V$ or in the $W$-norm where  
$W$-boundedness implies $V$ boundedness. 
The cochain projection will play an important 
role in the stablity of the discrete system.

The fact that $\Pi_h$ is a $V$-bounded projection immediately allows a quasi 
optimal estimate of the form. For any $v \in V^k$,  we can take 
$w_h \in V^k_h$ arbitrary s.t.
\begin{align*}
    \lVert v - \Pi^k_h v \rVert _V
    &=  \lVert v - w_h  + \Pi^k_h  (w_h - v) \rVert _V
    \\ &\leq (\lVert I - \Pi^k_h\rVert _\mathcal{L}(V,V))\lVert v - w_h \rVert _V.
\end{align*}
Since we $w_h$ was arbitrary we can take the infimum over $V_h^k$ and obtain 
an quasi optimal estimate. Due to 
$\lVert I - \Pi^k_h\rVert _\mathcal{L}(V,V) = \lVert \Pi^k_h\rVert _\mathcal{L}(V,V)$
we can also change the factor in front.

Let us now answer the question about the difference between discrete and continous 
harmonic forms. In order to do that we need some way to measure the "difference" 
between two subspaces.

\begin{definition}[Gap between subspaces]
    For a Banach space $W$ with subspaces $Z_1$ and $Z_2$. 
    Let $S_1$ and $S_2$ be the unit spheres in $Z_1$ and $Z_2$ respectively i.e.
    $S_1 = \{ z\in Z_1 \mid \lVert z \rVert _W = 1 \}$ and analogous for $S_2$.
    Then we define 
    the gap between these subspaces as 
    \begin{align*}
        \gap(Z_1, Z_2) = \max\{ \sup_{z_1 \in S_1} \text{dist}{z_1, Z_2}, \sup_{z_2 \in S_2} \text{dist}{z_2, Z_1} \}
    \end{align*}
\end{definition}
This definition is from \cite[p.198]{kato perturbation theory} and defines a metric on the set of closed subspaces
of $W$ (see \ref[Remark p.198]{})
If $W$ is a Hilbert space -- as it is throughout this section -- and $Z_1$ and $Z_2$ are closed then
the $\gap(Z_1, Z_2) = \lVert P_{Z_1} - P_{Z_2} \rVert$ i.e. the difference in operator norm of the 
orthogonal projections onto $Z_1$ and $Z_2$. This gives us a measure of distance between 
spaces which we can now apply to the question of the difference of the difference between 
discrete and continous harmonic forms.

\begin{proposition}[Gap between harmonic forms]
    Assume that the discrete complex \ref{} admits a $V$-bounded cochain projection
    $\pi_h$. Then
    \begin{align*}
        \lVert (I - P_{\mathfrak{H}^k_h}) q \rVert _V \leq \lVert (I - \pi_h^k) q \rVert _V, 
            \forall q \in \mathfrak{H}^k 
        \\ \lVert (I - P_{\mathfrak{H}^k}) q_h \rVert _V 
        \leq \lVert (I - \pi_h^k)P_{\mathfrak{H}^k} q \rVert _V, \forall q \in \mathfrak{H}^k, 
                \forall q_h \in \mathfrak{H}^k_h 
    \end{align*}
    and then 
    \begin{align*}
        \gap (\mathfrak{H}, \mathfrak{H}_h) 
        \leq \sup_{q \in \mathfrak{H}, \lVert q \rVert = 1} \lVert (I - \pi_h^k) q \rVert _V
    \end{align*}
\end{proposition}
\begin{proof}
    See \cite[Thm.\,5.2]{arnold}. 
\end{proof}
{\color{red} Do not forget the continuous poincare inequality} This then implies 
that there is a quasi optimal kind of bound of the gap. The following proposition 
clarifies how close a discrete harmonic form can be chosen.

\begin{proposition}
    Take $p \in \mathfrak{H}^k$ with $\lVert p \rVert = 1$. Then we can 
    choose $p_h \in \mathfrak{H}^k$ s.t. we can find a $C>0$ with 
    \begin{align*}
        \lVert p - p_h \rVert = \lVert p - p_h \rVert _V 
        \leq \lVert I - \pi_h^k\rVert _V \inf_{v_h \in V_h} \lVert p - v_h \rVert _V.
    \end{align*}
\end{proposition}
\begin{proof}
    Notice that since $\mathfrak{H}^k \subseteq \mathfrak{Z}^k$ we always have
    $\lVert q \rVert _V = \lVert q \rVert$ for all $q \in \mathfrak{H}^k$. The same is 
    true for $\mathfrak{H}_h$
    Denote $S_h \vcentcolon= \{ q_h \in \mathfrak{H}^k_h \mid \lVert q_h \rVert = 1 \}$.
    Since $S_h$ is closed we can find $p_h \in S_h$ s.t. 
    \begin{align*}
        \lVert p_h - p \rVert = \inf \lVert q_h - p \rVert
    \end{align*}
    The right hand side can be estimated using \ref{} and then the 
    quasi optimal bound for the projection \ref{}
    \begin{align*}
        \inf \lVert q_h - p \rVert _V \leq \lVert P_{\mathfrak{H}_h}p - p \rVert _V
        \leq \lVert \Pi_h^k p - p \rVert _V 
        \leq \lVert I - \Pi_h^k\rVert _{\mathcal{L}(V,V)}
            \inf_{v_h \in V_h} \lVert p - v_h \rVert _V
    \end{align*}
    which gives us the estimate.
\end{proof}

\begin{theorem}[Dimension of $\mathfrak{H}^k_h$]
    Assume that we have a finite-dimensional subcomplex as described at 
    with a $V$-bounded cochain projection. Assume further, that 
    \begin{align}
        \lVert q - \Pi_h^k q \rVert < \lVert q \rVert, \quad \forall q \in \mathfrak{H}^k\setminus \{0\}.
        \label{eq:assumption_same_dimension}
    \end{align}
    Then $\dim \mathfrak{H}^k = \dim \mathfrak{H}^k:h$.
\end{theorem}
\begin{proof}
    See \cite[Thm\,5.1]{arnold} and the explanation after the proof.
\end{proof}
Due to the quasi-optimal bound (\ref{}) and the $V$-boundedness of the projection 
the additional assumption 
is fulfilled for any reasonable approximation i.e. if the relative approximation error 
\begin{align*}
    \frac{1}{\lVert q \rVert} \inf_{v_h \in V_h} \lVert q - v_h \rVert
\end{align*}
is smaller than one.

\begin{proposition}[Discrete Poincare inequality]
    Assume that we have a $V$-bounded cochain projection $\pi_h$ for 
    the discrete Hilbert complex \ref{}. Then 
    \begin{align*}
        \lVert v \rVert _V \leq c_P \lVert \pi_h \rVert _V \lVert dv \rVert, 
            \quad \forall v \in \mathfrak{Z}_h^{k\perp}\cap V_h
    \end{align*}
    with $c_P$ being the Poincare constant from \ref{}.
\end{proposition}
\begin{proof}
    This indeed is a direct consequence of the existence of bounded cochain projections.
    Take $v_h \in \mathfrak{Z}_h^{k\perp}\cap V_h$ arbitrary. 
    Since $d (\mathfrak{Z}^{k,\perp} \cap V^k) = \mathfrak{B} \supseteq \mathfrak{B}_h$ we find 
    $z\in \mathfrak{Z}^{k\perp}\cap V_h$ s.t. $dz = dv$. We can apply now the continuous 
    Poincare inequality \ref{} to get $\lVert z \rVert _V \leq c_P \lVert dz \rVert _V = c_P \lVert dv_h \rVert _V$.
    Now we can combine the different assumptions about the discrete Hilbert complex teo get 
    $v_h - \pi_h z \in V_h^k$. Now we can use the fact that $\pi_h$ is a cochain map 
    and the fact that $\pi_h$ is a projection:
    \begin{align*}
        d\pi^k_h z = \pi^{k+1}_h dz = \pi^{k+1}_h dv_h = dv_h
    \end{align*}
    For the last equality we used also the fact that we have a discrete complex i.e. $d^k V^k_h \subseteq V^{k+1}_h$.
    That shows that $d(v_h - \pi_h z) = 0$ i.e. $(v_h - \pi_h z) \in \mathfrak{Z}_h^k$.
    Because $v_h \in \mathfrak{Z}_h^{k,\perp}$ by assumption we have 
    \begin{align*}
        0 = \langle v, v_h - \pi_h z \rangle = \langle v, v_h - \pi_h z \rangle + \langle dv, d(v_h - \pi_h z) \rangle
            = \langle v, v_h - \pi_h z \rangle _V
    \end{align*}
    so $v_h - \pi_h z$ is $V$ orthogonal to $v_h$. So 
    \begin{align*}
        \lVert v_h \rVert _V^2 = \langle v_h, \pi_h^k z \rangle _V + \langle v_h, v_h - \pi_h^k z\rangle _V 
        = \langle v_h, \pi_h^k z \rangle _V \leq \lVert \pi_h \rVert _V \lVert dv \rVert
        \stackrel{Poincare ineq.}{\leq} c_P \lVert \pi_h \rVert _V \lVert dv \rVert _V
    \end{align*}
\end{proof}

Now we obtained all the tools that we used for the proof of well-posedness and stability 
in the discrete setting. That means we can prove the well
So we get the inf sup condition with $c_{P,h} = c_P \lVert \pi_h \rVert _V$ instead of $c_P$ 
and obtain well-posedness.

\subsection{Discretized magnetostatic problem}

Let us apply this discretized Hilbert complex to the 2D Hilbert complex \ref{}
to get $V^0_h \subseteq H^1_0$, $V^1_h \subseteq H_0(\diver)$ and $V^2_h \subseteq L^2$
with 
\begin{align*}
    V^0_h \xrightarrow{\veccurl} V^1_h \xrightarrow{\diver} V^2_h
\end{align*}
and the dual complex 
\begin{align*}
    V^0_h \xleftarrow{\widetilde{\curl}_h} V^1_h \xleftarrow{-\widetilde{\grad}_h} V^2_h
\end{align*}
where $\widetilde{\curl}_h$ is the adjoint of $\veccurl_h$ and corresponds thus to
weak form of $\curl$ and the same for $\widetilde{\grad}_h$.
Analogous to the continuous case we assume that $\dim \mathfrak{H}_h^1 = 1$ 
which is not unreasonable thanks to \ref{} for $h>0$ small enough.
The discretized version of the magnetostatic problem \ref{} then states: 
Find $\mathbf{B}_h \in V_h^1$ s.t.
\begin{align*}
    \weakcurl_h \mathbf{B}_h = J \text{ and }
    \diver \mathbf{B}_h = 0
\end{align*}
plus the additional curve integral constraint.
Note that the divergence is enforced strongly while the curl is only enforced weakly.
As explained in \ref{} we will add the curve integral constraint as in \ref{}.
This gives us the following discrete formulation. Choose $\mathbf{p}_h \in \mathfrak{H}^1\setminus\{0\}$ 
s.t. $\lVert \mathfrak{p}_h \rVert = 1$. 
Find 
$\sigma_h \in V_h^0$, $\mathbf{B} \in V_h^1$ and $\lambda \in \real$ s.t.

\begin{align*}
    \langle \sigma_h, \tau_h \rangle - \langle \mathbf{B}_h, \mathbf{\curl}\tau_h \rangle 
    &=  -\langle J, \tau_h \rangle \quad \forall \tau_h \in V_h^0, 
    \\ \langle \mathbf{\curl}\sigma_h, \mathbf{v}_h \rangle + \langle \diver \mathbf{B}_h, \diver \mathbf{v}_h \rangle 
    + \langle \lambda \mathbf{p}_h, \mathbf{v}_h \rangle 
    &= 0 \quad \forall \mathbf{v}_h \in V^1_h, 
    \\ \mu \langle \bm{\curl} \psi, \mathbf{B}_h \rangle &= \mu C_1 \quad \forall \mu \in \real.
\end{align*}
Here we assume for simplicity that $\veccurl \psi \in V_h^1$. Since 
we can choose $\psi$ this is not unreasonable. In practice, $\mathbf{p}_h$ 
is computed numerically before assembling the system. 


We define $X_h \vcentcolon= V_h^0 \times V_h^1 \times \real$. 
Note that this trial and test space is indeed conforming i.e. $X_h \subseteq X$, 
but we choose a discrete harmonic form 
with $\mathbf{p}_h \in \mathfrak{H}^1_h$ so $a_h:X_h \times X_h \rightarrow \real$
\begin{align*}
    &a_h(\sigma_h,\mathbf{B}_h,\lambda;\tau_h,\mathbf{v}_h,\mu)
    \\ \quad&= \langle \sigma_h, \tau_h \rangle - \langle u_h, \mathbf{\curl}\tau_h \rangle
    + \langle \mathbf{\curl}\sigma_h, \mathbf{v}_h \rangle + \langle \diver \mathbf{B}_h, \diver \mathbf{v}_h \rangle 
    + \langle \lambda \mathbf{p}_h, \mathbf{v}_h \rangle - \mu \langle \mathbf{\curl} \psi, \mathbf{B}_h \rangle.
\end{align*}
so the resulting bilinear forms are different since we have $\mathbf{p}_h$ 
instead of $\mathbf{p}$. So we can write the discrete problem in 
standard form: Find $\sigma_h,\mathbf{B}_h,\lambda \in X_h$ s.t.
\begin{align*}
    a_h(\sigma_h,\mathbf{B}_h,\lambda;\tau_h,\mathbf{v}_h,\mu) = \ell(\tau_h,\mathbf{v}_h,\mu).
\end{align*}
For simplicity we assume for the theoretical considerations that we can 
compute all inner products exactly and that $C_1$ from \ref{} is 
given exactly as well. That also means that the right hand side $\ell$ is the 
same for the continous and discrete problem.

Because we have transfered the continous structures to the discrete case 
we can apply the same arguments as in \ref{}.
Thus we obtain a inf-sup condition with a $\gamma_h$ that depends 
on $c_{P,h}$ instead of $c_P$. This provides us with the well-posedness 
of the discrete formulation \ref{} and gives us the stability estimate
\begin{align*}
    \lVert \mathbf{B}_h \rVert_{H(\diver)} \rVert \leq \frac{\lVert J \rVert + |C_1|}{\gamma_h}.
\end{align*}

{\color{red} Why can $\gamma_h$ not go to zero?} In the situation that we are 
in we (i.e. conforming subspace but a different bilinear form) we can formulate the following result

\begin{lemma}
    Let $x \in X$ be a solution of \ref{} and $x_h \in X_h$ be a solution of \ref{}.
    Assume that a inf-sup condition holds for the discrete problem with constant 
    $\gamma_h$.
    Define $\delta_h(x) \in Y'$ as 
    \begin{align*}
        \langle \delta(x), y \rangle_{Y'\times Y} 
        \vcentcolon= a(x,y) - a_h(x,y).
    \end{align*}
    Then
    \begin{align*}
        \lVert x - x_h \rVert _X 
        \leq \left( 1 + \frac{\lVert a_h \rVert}{\gamma} \right) 
            \inf_{z_h \in X_h} \lVert x - z_h\rVert _X + \frac{\lVert \delta(x) \rVert_{Y'}}{\gamma_h}.
    \end{align*}
\end{lemma}
\begin{proof}
    Take $z_h \in X_h$ arbitrary. Then with the triangular inequality
    \begin{align}
        \lVert x - x_h \rVert \leq \lVert x - z_h \rVert _X + \lVert x_h - z_h \rVert _X. \label{eq:a_priori:triangular}
    \end{align}
    We now have to bound the last term on the right hand side.
    Assume w.l.o.g. that $x_h - z_h$ is not zero. Then from the inf-sup condition 
    we can find $y_h \in X_h \setminus \{0\}$ s.t. 
    \begin{align*}
        &\gamma_h \lVert x_h - z_h \rVert _X \lVert y_h \rVert _X
        \leq a_h(x_h-z_h, y_h) 
        \\ &= a_h(x-z_h, y_h) + a_h(x_h, y_h) - a(x, y_h) + a(x, y_h) - a_h(x, y_h) 
        \\ &= a_h(x-z_h, y_h) + \langle \delta_h(x), y_h \rangle_{Y'\times Y} 
        \\ &\leq \lVert a_h \rVert _X \lVert x- z_h \rVert _X \lVert y_h \rVert _X
            \lVert \delta_h(x) \rVert _{X'}  \lVert y_h \rVert _X
    \end{align*}
    In the third step, we used the fact that $x$ and $x_h$ are solutions.
    So we can bound $\lVert x_h - z_h \rVert _X$ by 
    \begin{align*}
        \lVert x_h - z_h \rVert _X
        \leq \lVert a_h \rVert _X \lVert x- z_h \rVert _X 
            \lVert \delta_h(x) \rVert _{X'}  
    \end{align*}
    and plugging this in (\ref{eq:a_priori:triangular}) and taking the infimum 
    over $z_h \in X_h$ we get 
    \begin{align*}
        \lVert x - x_h \rVert 
        \leq \left( 1 + \frac{\lVert a_h \rVert}{\gamma_h} \right) \inf _{z_h \in V_h}\lVert x - z_h \rVert _X 
            + \frac{1}{\gamma_h}\lVert \delta_h(x) \rVert _{X'}.
    \end{align*}
\end{proof}

We now have to apply this lemma to the magnetostatic formulation.

\begin{theorem}[Quasi optimal a-priori estimate]
    Let $(\sigma,\mathbf{B},\lambda) \in X$ the exact solution of \ref{} and 
    $(\sigma_h,\mathbf{B}_h,\lambda_h) \in X_h$ the solution of the discrete 
    system \ref{}. Then 
    \begin{align*}
        \lVert \mathbf{B} - \mathbf{B}_h \rVert _{H(\diver)} 
        \leq \left( 1 + \frac{\lVert a_h \rVert}{\gamma_h} \right)
            \inf_{\mathbf{z}_h \in V_h^1} \lVert \mathbf{B} - \mathbf{z}_h \rVert _{H(\diver)} 
            % + \frac{\lambda}{\gamma_h} C \inf_{\mathbf{v}_h \in V_h^1} \lVert p - \mathbf{v}_h \rVert _{H(\diver)}.
    \end{align*}
\end{theorem}
\begin{proof}
    At first recall that if $(\sigma,\mathbf{B},\lambda)$ is solution then 
    $\sigma = 0$ and $\lambda = 0$ . 
    So $\lVert (\sigma,\mathbf{B},\lambda) \rVert _X = \lVert \mathbf{B} \rVert _{H(\diver)}$
    and analogous for the $(\sigma_h,\mathbf{B}_h,\lambda_h)$.
    Also recognize then for any $y = (\tau,\mathbf{v}, \mu) \in X$
    \begin{align*}
        \langle \delta_h(x), y \rangle = \lambda \langle \mathbf{p}, \mathbf{v} \rangle 
        - \lambda \langle \mathbf{p}_h, \mathbf{v} \rangle = 0.
    \end{align*}
    Thus the estimate follows immediately from Lemma \ref{}.
\end{proof}

\section{Implementation in 2D}

\subsection{Splines}

For the discretization we will use the push forward of tensor product splines 
on a rectangular reference domain $\hat{\Omega}$. We use geometric degrees of freedom
which we will introduce below \ref{}. This section is a recollection 
 of \cite[Sec. 4.2]{broken FEEC framework on mapped multipatch} 
since we use the same method as presented in this paper also to fix notation. 

We will use two different types knot sequences, non-periodic and periodic ones. 
We choose a knot sequence $\{ \xi_i \}_{i=0}^{n+p}$ with 
$\xi_0 \leq \xi_1 \leq ... \xi_{n+p}$. We choose two types of sequences.

Let us define $x_0 < x_1 < ... < x_N$ as the physical knots which 
is our actual grid. We will stick to the equidistant case. Let $h$ be 
$x_{i+1} - x_i$.

Define $n = N + p$.
For the non-periodic case we choose an \textit{open} knot sequence by 
$\xi_0 = ... = \xi_p = x_0$, $\xi_{p+l} = x_l$ for $l = 0,1,...,N$ and 
$\xi_{n} = \xi_{n+1} = ... = \xi_{n+p} = x_N$
\begin{align*}
    \xi_0 = ... = \xi_p < \xi_{p+1} < ... \xi_{n} = \xi_{n+1} = ... = \xi_{n+p}    
\end{align*}
and for the periodic case 
$\xi_0 = x_0-ph, \xi_1 = x_0-(p-1)h, ..., \xi_p = x_0$,
$\xi_{p+l} = x_l$ and $\xi_{n+l} = x_N + lh$ for $l = 0, ..., p$. 

Note that all the knot multiplicities in the interior are one and thus our spline 
space has maximal regularity. We then define 
$\mathcal{N}_i^q$ be the normalized B-spline \cite[Ref. 46, Def.4.19]{multipatch paper}.
We then define the spline spce $\mathbb{S}_q = \mathbb{S}_q(\bm{\xi}) = 
span{\mathcal{N}_i^q \mid i = 0, ..., n-1}$. Since we have maximal regularity 
we get that 
\begin{align*}
    \{ v \in C^{q-1} \mid v |_{\xi_{q+j, q+j+1}} \in \mathbb{P}_q \}.
\end{align*}
$\mathcal{N}_0^{p-1} $ vanishes.


We now can take tensor product of spline spaces. We use the notation 
with $\mathbf{q} \in \{p-1,p\}^2$ and we define with $\mathbf{i} \in [N_0 ] \times [ N_1 ]$
\begin{align*}
    \mathcal{N}_\mathbf{i}^\mathbf{q} \mathcal{N}_{i_1}^{q_1} \mathcal{N}_{i_2}^{q_2}.
\end{align*}
We write this as $\mathbb{S}_\mathbf{q} = \mathbb{S}_{q_1} \otimes \mathbb{S}_{q_2}$ 
The spline spaces used in the tensor product can also be periodic or only one of them 
can be periodic.
On $\hat{\Omega}$ we obtain the following discrete Hilbert complex 
\begin{align*}
    \mathbb{S}_{p,p} \xrightarrow{\veccurl} \mathbb{S}_{p-1,p} \xrightarrow{\diver} \mathbb{S}_{p-1,p-1}
\end{align*}
and we denote $\hat{V}^0 = \mathbb{S}_{p,p}$, $\hat{V}^1 = \mathbb{S}_{p-1,p}$ 
and $\hat{V}^2 = \mathbb{S}_{p-1,p-1}$. 

It is well-known that if we have a function $\mathbf{v}$ that is piecewise smooth 
then $\mathbf{v} \in H(\diver)$ i.i.f. the normal trace across element interfaces
agrees almost everywhere. Analogously for $\tau \in H^1$ i.i.f. the values agree 
on the interfaces almost everywhere. Since we always have $p \geq 2$ we thus know that 
all our tensor splines are at least continuous globally and thus we get 
$\hat{V}_h^j \subseteq \hat{V}^j$ for $j=0,1,2$ as desired. 



\subsection{Basis and degrees of freedom}

Let us now investigate the degrees of freedom. At first, we will work on only on the 
reference domain and then use a pullback and pushforward to transfer that to the physical domain.
We will use geometric degrees of 
freedom i.e. each degree of freedom can be associated with some geometrical element of our 
domain. We define Greville points by 
\begin{align*}
    \zeta_i \vcentcolon= \frac{\xi_{i+1} + ... + \xi_{i+p}}{p}
\end{align*}
i.e. the knot averages for $i=0,...,n-1$. Then the spline interpolation at these 
points is well-defined (see \cite{I think that was in the isogeometric analysis book}).
Note that in the case periodic some Greville points lie outside of 
the grid. But since the function is periodic it can simply be extended periodically 
and then interpolated at these points. 

This gives us the following geometric elements nodes, edges and cells
\begin{align*}
    \hat{\mathtt{n}}_\mathbf{i} \vcentcolon= (\zeta_{i_1}, \zeta_{i_2}) for \mathbf{i} \in \mathcal{M}^0
    \\ \hat{\mathtt{e}}_{d,\mathbf{i}} 
        \vcentcolon= [\hat{\mathtt{n}}_\mathbf{i}, \hat{\mathtt{n}}_{\mathbf{i} + \mathbf{e}_d}] 
        for (d, \mathbf{i}) \in \mathcal{M}^1
    \\ \hat{\mathtt{c}}_\mathbf{i} \vcentcolon= [\hat{\mathtt{e}}_{1,\mathbf{i}}, \hat{\mathtt{e}}_{1,\mathbf{i}}]
        = [\zeta_{i_1}, \zeta_{i_1+1}] \times [\zeta_{i_2}, \zeta_{i_2+1}] 
        for \mathbf{i} \in \mathcal{M}^2 
\end{align*}
with $[\cdot]$ being the convex hull. As before, $\mathbf{e}_d$ for $d = 1,2$ is the 
standard basis vector of $\real^2$. 
We define for a $m \in \naturalnum$, $[m] \vcentcolon= \{ 0, 1, ..., m\}$.
The set of multiindices are defined as
\begin{align*}
    \mathcal{M}^0 \vcentcolon= [n-1]^2
    \\ \mathcal{M}^1 \vcentcolon= \{ (d, \mathbf{i}=) \mid \mathbf{i} \in \mathcal{M}^0, d\in \{1,2\} \}
    \\ \mathcal{M}^2 \vcentcolon= [n-2]^2
\end{align*}
{\color{red} Does this stuff go through for periodic case?}

Now that we have defined the geometric elements we define the corresponding 
degrees of freedom as 
\begin{align*}
    \hat{\sigma_\mathbf{i}^0(v) } \vcentcolon= v(\hat{\mathtt{n}}_\mathbf{i}) for \mathbf{i} \in \mathcal{M}^0
    % \\ \hat{\sigma_{\mathbf{d,i}^1(\mathbf{v})} } 
    %     \vcentcolon= \int_\hat{\mathtt{e}}_{d,\mathbf{i}} \mathbf{v} \cdot \mathbf{e}^\perp_d 
    %     for (d, \mathbf{i}) \in \hat{\mathcal{M}}^1
    \\ \hat{\sigma}_{\mathbf{i}}^2(v) 
        \vcentcolon= \int_{\hat{c}_{\mathbf{i}}} v 
        for (\mathbf{i}) \in \mathcal{M}^2
\end{align*}
We $\mathbf{e}_d^\perp$ as $R_{\pi/2}\mathbf{e}_d$ i.e. the rotation by $\pi /2$ in counter clockwise 
direction i.e. $\mathbf{e}^\perp_1= \mathbf{e}_2$ and $\mathbf{e}^\perp_2= -\mathbf{e}_1$.  
Something about orientation


These degrees of freedome are unisolvent (explanation) i.e. 
with some ordering $\mu_0, \mu_1, ...$ of the indices of $\mathcal{M}^l$
define 
\begin{align*}
    \bm{\sigma}^l \vcentcolon= (\sigma^l_{\mu_0}, \sigma^l_{\mu_1}, ..., \sigma^l_{\mu_{|\mathcal{M}^l|}})^\top
    : V^l_h \rightarrow \real^{|\mathcal{M}^l}
\end{align*}
which is bijective.
And we can thus define our basis functions 
$\hat{\Lambda}^l_\mu$, $\mu \in \mathcal{M}^l$ as the basis which is dual to the 
degrees of freedom in the sense 
\begin{align*}
    \hat{\sigma}_\mu^l(\hat{\Lambda}^l_\nu) = \delta_{\mu,\nu} \quad for \mu, \nu \in \mathcal{M}^l.
\end{align*}

The question is now  on what function spaces these degrees of freedom are defined. We note first that 
the standard choice as described above with $\hat{V}^0 = H^1_0(\hat{\Omega})$ 
$\hat{V}^1 = H_0(\diver)$ and $\hat{V}^2 = L^2(\hat{\Omega})$ can not work 
because the evaluation at point values is not well-defined for $H^1$ in 2D since 
they can not be embedded into the continuous functions. Thus, 
we need to choose function spaces with higher regularity or integrability.

Let us define the spaces
\begin{align*}
    W^1_{1,2}(\hat{\Omega}) &\vcentcolon= \{ v \in L^1(\hat{\Omega}) \mid \partial_1 \partial_2 v
        \in L^1(\hat{\Omega}) \}
    \\  W^1_d(\hat{\Omega}) &\vcentcolon= \{ v \in L^1(\hat{\Omega}) \mid \partial_d v
        \in L^1(\hat{\Omega}) \}
\end{align*}
{\color{red} Why do we set the sequence to the spaces with $L^1$ sub instead of the intersection?}


This now gives us the discrete setting on the reference domain $\hat{\Omega}$ the idea 
is now to define the basis functions on the physical domain $\Omega$ by a 
push forward of the basis functions on the reference domain. 
The pushforward is the inverse of the pullback introduce in Sec.\,\ref{}.
Here it is in the 2D setting, but it works completely analogous as 
introduced there.

We will stick to the single patch case meaning that there is a diffeomorphism 
$\mathbf{F}: \hat{\Omega} \rightarrow \Omega$. Then we define 
the pullbacks 
\begin{align*}
    &\mathcal{P}_F^0: v \mapsto \hat{v} \vcentcolon= v \circ \mathbf{F}
    \\ &\mathcal{P}_F^1: \mathbf{v} \mapsto \hat{\mathbf{v}} 
        \vcentcolon= \det D\mathbf{F} \,D\mathbf{F}^{-1} (\mathbf{v} \circ \mathbf{F})
    \\ &\mathcal{P}_\mathbf{F}^2: v \mapsto \hat{v} \vcentcolon= (\det DF) (v\circ \mathbf{F})
\end{align*}
which map functions on the physical domain $\Omega$ to functions on the reference domain 
$\hat{\Omega}$. Then we have the commuting properties
\begin{align*}
    \widehat{\veccurl} \mathcal{P}_F^0 v &= \mathcal{P}_F^1 \veccurl v
    \\ \widehat{\diver} \mathcal{P}_F^1 \mathbf{v} &= \mathcal{P}_F^1 \diver v
\end{align*}

These are easy to prove by adapting the arguments of Sec.\,\ref{} i.e. we 
can use the corresponding operators on differential forms.

Using the pullbacks we define the pushforwards as 
$\mathcal{F}^l \vcentcolon= (\mathcal{P}_F^l)^{-1}$ and then 
we get the basis functions on the physical domain
\begin{align*}
    \Lambda^l_{\mu} \vcentcolon= \mathcal{F}^l \hat{\Lambda}^l_{\mu}
\end{align*}
and then 
\begin{align*}
    V_h^l \vcentcolon= \text{span} \{ \Lambda^l_{\mu} \mid \mu \in \mathcal{M}^l \}
\end{align*}
are our discrete spaces. {\color{red} Approximation properties???}

Using the geometric degrees from \ref{} we can now construct the corresponding 
by 
\begin{align*}
    \sigma^l_\mu \vcentcolon= \hat{\sigma}_\mu^l \circ \mathcal{P}_F^l
\end{align*}
Then we have by construction that 
$\sigma^l_\mu(\Lambda^l_{\nu}) = \delta_{\mu,\nu}$. 

We can thus define the projection operators 
\begin{align*}
    \pi_h^l: U^l \rightarrow V_h^l, v \mapsto \sum_{\mu \in \mathcal{M}^l} \sigma^l_\mu \Lambda^l_\mu.
\end{align*}

Then these degrees of freedom commute with the corresponding differential operators 
as desired from \ref{} i.e. the diagram
\begin{tikzcd}
    H_0^1 \arrow[d, "\Pi^{0}_h"] \arrow[r, "\veccurl"] 
        & H_0(\diver) \arrow[d, "\Pi^1_h"] \arrow[r, "\diver"] & L^2 \arrow[d, "\Pi^2_h"]
    \\ V^{0}_h \arrow[r, "\veccurl"] & V^{1}_h  \arrow[r, "\diver"]& V^2_h
\end{tikzcd}    


and is thus a cochain projection. 
They also correspond to geometric elements. 
$\sigma^0$ corresponds to point values in the physical domain, 
$\sigma^1$ to the fluxes through the image of edges and 
$\sigma^2$ to the integral over the mapped cells.

\begin{remark}
    The cochain projections we use here are in fact not $V$-bounded i.e. 
    neither $\Pi_h^0$ is bounded $H^1$ nor $\Pi_h^1$ in $H(\diver)$. 
    This is a drawback of the geometric projections and means that -- 
    strictly speaking -- we can not apply the theoretical results to them. 
    We will use them anyway for the practical implementation 
    since they are easier to implement than other 
    options e.g. quasi-interpolants (see \cite{} ).
\end{remark}

\subsection{Building the discrete system}

This very simple geometric interpretation gives us the ability to enforce 
the boundary condition directly by setting the corresponding degrees of freedom 
to zero. 

For $V_h^0 \subseteq H^1_0$ we want the trace on the boundary to vanish which 
means that we set the values at the boundary nodes to zero. Thus, 
for $\mathtt{n}_\mathbf{i}$ on the boundary we want 
$\sigma^0_{\mathbf{i}}(v) = 0$. 

For $V_h^1 \subseteq H_0(\diver)$ we want to have the normal trace zero. 
So when $\mathtt{e}_{d,\mathbf{i}}(\mathbf{v})$ is boundary edge we require
This is then achieved when $\sigma^1_{d,\mathbf{i}} (\mathbf{v}) = 0$.

We now define the spaces $\bar{V}_h^l$ which are the correspoding spaces 
without any boundary conditions. Then we define the 
projections $P_h^l: \bar{V}_h^l \rightarrow \bar{V}_h^l$ which set 
the boundary degrees of freedom to zero. They have a very simple 
matrix representation $\mathbb{P}_h^l$ 
$(\mathbb{P}_h^l)_{\mu, \nu} = 1 $ i.i.f. $\mu = \nu$ and $\mu$ does not 
correspond to a geometric element on the boundary. They are easily constructed 
by taking the identity matrix and setting the diagonal entries to zero that 
belong to boundary degrees of freedom.

We now reformulate the discrete system using these projections. We apply them 
to all functions involved and then penalize the boundary.
With boundary penalities the discrete system is: Find $\sigma_h \in \bar{V}_h^0$, 
$\mathbf{B}_h \in \bar{V}^1_h$ and $\lambda \in \real$ s.t.
\begin{align*}
    \langle (I-P^0_h)\sigma_h, (I-P^0_h)\tau_h \rangle + \langle P^0_h \sigma_h, P^0_h\tau_h \rangle 
        - \langle P^1_h \mathbf{B}_h, \mathbf{\curl}P^0_h\tau_h \rangle 
    &=  -\langle J, P^0_h \tau_h \rangle \quad \forall \tau_h \in \bar{V}_h^0, 
    \\ \langle \mathbf{\curl}P^0_h \sigma_h, P^1_h\mathbf{v}_h \rangle 
        + \langle (I-P^1_h)\mathbf{B}_h, (I-P^1_h)\mathbf{v}_h \rangle
    \\ \quad    + \langle \diver P^1_h\mathbf{B}_h, \diver P^1_h\mathbf{v}_h \rangle 
        + \langle \lambda \mathbf{p}_h, P^1_h\mathbf{v}_h \rangle 
    &= 0 \quad \forall \mathbf{v}_h \in \bar{V}^1_h, 
    \\ \mu \langle \bm{\curl} \psi, P^1_h \mathbf{B}_h \rangle &= \mu C_1 \quad \forall \mu \in \real.
\end{align*}
Since we apply the projection everywhere it is then easy to show that 
$\sigma_h \in \bar{V}_h^0$, 
$\mathbf{B}_h \in \bar{V}^1_h$ and $\lambda \in \real$ solve \ref{} 
i.i.f. $\sigma_h \in V_h^0$, $\mathbf{B}_h \in V^1_h$ 
and it solves the system with homogeneous discrete spaces \ref{}. 
So the two formulations are equivalent.

In the matrix formulation. Define $\mathbb{M}^l$ as the mass matrix 
of $V_h^l$ i.e. $\mathbb{M}_{ij} = \langle \Lambda^l_i , \Lambda^l_j \rangle$ 
where we used some flattening of the multiindices in $\mathcal{M}^l$. 
We also define the matrix $\mathbb{D}$ the matrix representation of the 
divergence applied to $V^1_h$ i.e. $\diver|_{V^1_h}: V^1_h \rightarrow V^2_h$.
Analogously $\mathbb{C}$ is the matrix representation of $\veccurl$. Then 
we have, as mentioned before, the matrix representation of the boundary projections 
$\mathbb{P}^l$. Overall we can rewrite the linear system like this. 
We denote the vector of coefficients of a function in bold with an underline e.g. 
$\underline{\bm{\sigma} }$ is the vector of coefficients of $\sigma$ in 
the basis $\Lambda^0_\mu$ $\mu \in \mathcal{M}^0$ 
and $\underline{\mathbf{B}}$ is are the coefficients of $\mathbf{B}$ in the basis 
$\Lambda^1_\mu$ $\mu \in \mathcal{M}^1$.
using some flattening again.

\begin{align*}
    \underline{\bm{\tau}}^\top (I-\mathbb{P}^0_h)\top \mathbb{M}^0 
        (I-\mathbb{P}^0_h)\underline{\bm{\sigma}} 
        + \underline{\bm{\tau}}^\top \mathbb{P}^0_h \mathbb{M}^0 \mathbb{P}^0_h \underline{\bm{\sigma }}
        + \underline{\bm{\tau}}^\top \mathbb{P}^0_h \mathbb{C} ^\top \mathbb{M}^1 \mathbb{P}^1_h 
        \underline{\mathbf{B}} &= \underline{\bm{\tau}}^\top \underline{\tilde{\mathbf{J}}} \quad \forall \underline{\bm{\tau}} \in \real^{N_0}
    \\ \underline{\mathbf{v}}^\top \mathbb{P}^1_h \mathbb{M}^1 \mathbb{C} \mathbb{P}^0_h \underline{\bm{\sigma }}
        + \underline{\mathbf{v}}^\top (\mathbb{P}^1)^\top \mathbb{D}^\top \mathbb{M}^1 
        \mathbb{D} \mathbb{P}^1 \underline{\mathbf{B}} + \underline{\mathbf{v}}^\top (\mathbb{P}^1_h)^\top \mathbb{M}^1
        \underline{\mathbf{v}}^\top (\mathbb{P}^1) \mathbb{M}^1 \underline{\mathbf{p}} &= 0 
        \quad \forall \underline{\mathbf{v}} \in \real^{N_1}
    \\ \underline{\bm{\psi}}^\top \mathbb{C}^\top \mathbb{M}^1 \mathbb{P}^1_h \underline{\mathbf{B}} = C_1
\end{align*}
where $\underline{\tilde{J}}_i = \langle J, \Lambda^0_i \rangle$
which gives us the final system to be solved 
\begin{align*}
    (I-\mathbb{P}^0_h)\top \mathbb{M}^0 
        (I-\mathbb{P}^0_h)\underline{\bm{\sigma}} 
        +  \mathbb{P}^0_h \mathbb{M}^0 \mathbb{P}^0_h \underline{\bm{\sigma }}
        +  \mathbb{P}^0_h \mathbb{C} ^\top \mathbb{M}^1 \mathbb{P}^1_h 
        \underline{\mathbf{B}} &=  \underline{\tilde{\mathbf{J}}} 
    \\ \mathbb{P}^1_h \mathbb{M}^1 \mathbb{C} \mathbb{P}^0_h \underline{\bm{\sigma }}
        + (\mathbb{P}^1)^\top \mathbb{D}^\top \mathbb{M}^1 
        \mathbb{D} \mathbb{P}^1 \underline{\mathbf{B}} + (\mathbb{P}^1_h)^\top \mathbb{M}^1
        (\mathbb{P}^1) \mathbb{M}^1 \underline{\mathbf{p}} &= 0 
    \\ \underline{\bm{\psi}}^\top \mathbb{C}^\top \mathbb{M}^1 \mathbb{P}^1_h \underline{\mathbf{B}} = C_1
\end{align*}

Now we will explain how the discrete harmonic form is computed.
Notice first that for any linear operator $\phi$ between finite dimensional inner product spaces 
$V$ and $W$ with matrix representation $A$ we get the matrix representation of 
adjoint $\phi^*$ has matrix representation $G_V^{-1} A^\top G_W$ where 
$G_V$ and $G_W$ are the gramian matrices of the chosen bases in $V$ and $W$ 
respectively.

We compute $\mathbf{p}_h$ as an element of the kernel of the 
discrete Hodge Laplacian operator $-\widetilde{\grad}_h \diver 
+ \veccurl \widetilde{\curl}_h$ which has matrix 
representation $(\mathbb{M}^1)^{-1} \mathbb{D}^\top \mathbb{M}^1 \mathbb{D} 
+ \mathbb{C} (\mathbb{M}^0)^{-1}\mathbb{C}^\top \mathbb{M}^1$. 

\begin{remark}
    For implementational purposes, these dual basis functions are not necessarily the 
    best option. For the computation of mass matrices etc. 
    it is more convenient to use the normalized B-splines directly due to their 
    local support and fast computation.
    We will not 
    go to deep into the details of implementation however. More details about the 
    use of B-splines and the connection with the basis $\Lambda^l_\mu$ can be found 
    in \cite[Sec.\,4.8]{multipatch_paper} 
\end{remark}

\section{Numerical examples}

As a first simple numerical example we consider a standard example from 
magnetostatics which is the magnetic field induced by an infinitely long, 
wire with radius zero. The \textit{Biot-Savart law} can be used to compute it. 
Let the wire be equal to the $z$-axis and $I$ be the electrical current 
flowing through it. $\bm{\ell}(s) = s \mathbf{e}_3$, $\mathbf{x} = x_1 \mathbf{e}_1 +  x_2 \mathbf{e}_2$

\begin{align*}
    \mathbf{B}(\mathbf{x}) = \frac{\mu_0 I}{4\pi} \int_\infty^\infty  
        \frac{\ell' \times (x - \ell(s))}{|x - \ell(s)|^3} \, ds
    = \frac{\mu_0 I}{4\pi |x|^2}  \begin{pmatrix}-x_2 \\ x_1 \\ 0 \end{pmatrix}
\end{align*}
for convenience we pick now $I = \frac{2 \pi}{\mu}$ to get 
\begin{align*}
    \mathbf{B}(x) = \frac{2}{|x|^2} \begin{pmatrix}-x_2 \\ x_1 \\ 0 \end{pmatrix}.
\end{align*}

We choose as our domain of computation $\Omega$ as the annulus with 
inner radius $1$ and outer radius $2$.
We choose as our curve $\Gamma$ the parametrization of the circle with radius 
$1.5$ in anticlockwise direction. We obtain the curve integral 
\begin{align*}
    C_0 = \int_\Gamma \mathbf{B}\cdot d\ell = 4\pi
\end{align*}
$J= 0$ on our domain and hence $C_1 = C_0$. 

The reference domain $\hat{\Omega} = [0,1] \times [0, 2\pi]$ and the mapping 
\begin{align*}
    F(\hat{x}) = \begin{pmatrix}
            (\hat{x}_1 + 1)\cos(\hat{x}_2 ) 
            \\ (\hat{x}_1 + 1)\sin(\hat{x}_2 ) 
    \end{pmatrix}.
\end{align*}
Then we choose $\psi$ as a simple interpolation i.e. in logical coordinates 
% $\hat{\psi} = 
$\begin{cases}
    2 \hat{x}_1 & \text{ for $\hat{x}_1 \leq 0.5$}
    \\ 1 & \text{ else}.
\end{cases}$
This fulfills all the criteria we had for $\psi$ for this given $\Gamma$. 

We give as another example by choosing now the different mapping 
\begin{align*}
    F(\hat{x}) = \begin{pmatrix}
        (\cos^2(\hat{x}_2 ) + 1 )(\hat{x}_1 + 1)\cos(\hat{x}_2 ) 
        \\ (\cos^2(\hat{x}_2 ) + 1 ) (\hat{x}_1 + 1)\sin(\hat{x}_2 ) 
    \end{pmatrix}.
\end{align*}
which results in a kind of "distorted annulus"(see \ref{}). Note that now for this domain we do not have 
$\mathbf{B}\cdot \mathbf{n}$ anymore. Thus we have to deal with the boundary conditions 
by using a lifting approach. This means we take an interpolation of the boundary conditions 
$\mathbf{B}_{h,g}$ which we compute before and then split
$\mathbf{B}_{h} = \mathbf{B}_{h,0} + \mathbf{B}_{h,g}$ and put the terms 
with $\mathbf{B}_{h,g}$ on the right hand side. 

As an example with a non-vanishing $J$ will use a manufactured solution. 
Let $\mathbf{B}(x) = (|x|^2 -2) (-x_2,x_1)^\top$. It is easy to see that 
$\mathbf{B}\cdot \mathbf{n} = 0$. 
Then the resulting 
\begin{align*}
    J(x) = 4 |x|^2 - 12 |x| + 8.
\end{align*}
We will pose this problem on the annulus domain from before, but we will use two 
different choices for $\Gamma$. 
$\Gamma_1$ will be the same $\Gamma$ as before, but $\Gamma_2$ will 
be the parametrization of the bouter boundary of $\Omega$ i.e. 
it is equal to $\partial\Omega_{out}$ (cf Fig.\ref{}).

For $\Gamma_1$ we will choose $\psi$ as before. For $\Gamma_2$ we will choose 
$\psi$ as the solution of the Laplace problem with boundary condition 
$\psi=0$ on $\partial\Omega_{in}$ and $\psi=0$ on $\partial\Omega_{out}$.

\end{document}